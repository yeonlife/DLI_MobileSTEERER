{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyMkK/VZRgzcyY8dP+Qckyx/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ue1ilO6RcjhQ","executionInfo":{"status":"ok","timestamp":1734443426172,"user_tz":-540,"elapsed":22458,"user":{"displayName":"박수연 (GREAT)","userId":"09302565313834136190"}},"outputId":"b8f2d415-4d0f-4620-a95f-32bbb4b21f1a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/STEERER/STEERER"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"roEiKyBVc9AS","executionInfo":{"status":"ok","timestamp":1734443491803,"user_tz":-540,"elapsed":464,"user":{"displayName":"박수연 (GREAT)","userId":"09302565313834136190"}},"outputId":"e1522b0a-110d-4d1c-b492-40dbdcab23a6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/STEERER/STEERER\n"]}]},{"cell_type":"code","source":["! pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"PZyVfJRIcsCC","executionInfo":{"status":"ok","timestamp":1734443511448,"user_tz":-540,"elapsed":17376,"user":{"displayName":"박수연 (GREAT)","userId":"09302565313834136190"}},"outputId":"454e69e9-d9e4-4472-ca18-ac9123d5960d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mmcv==1.6.0 (from -r requirements.txt (line 1))\n","  Downloading mmcv-1.6.0.tar.gz (554 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/554.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m554.9/554.9 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.66.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.13.1)\n","Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.0.12)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.8.0)\n","Collecting dict_recursive_update (from -r requirements.txt (line 6))\n","  Downloading dict_recursive_update-1.0.1-py2.py3-none-any.whl.metadata (2.7 kB)\n","Collecting yacs>=0.1.5 (from -r requirements.txt (line 7))\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Collecting tensorboardX==2.6.2 (from -r requirements.txt (line 8))\n","  Downloading tensorboardX-2.6.2-py2.py3-none-any.whl.metadata (5.7 kB)\n","Collecting fvcore (from -r requirements.txt (line 9))\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting addict (from mmcv==1.6.0->-r requirements.txt (line 1))\n","  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv==1.6.0->-r requirements.txt (line 1)) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv==1.6.0->-r requirements.txt (line 1)) (24.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv==1.6.0->-r requirements.txt (line 1)) (11.0.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv==1.6.0->-r requirements.txt (line 1)) (6.0.2)\n","Collecting yapf (from mmcv==1.6.0->-r requirements.txt (line 1))\n","  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from tensorboardX==2.6.2->-r requirements.txt (line 8)) (4.25.5)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 4)) (2.5.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 4)) (0.20.1+cu121)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 4)) (0.26.5)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 4)) (0.4.5)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore->-r requirements.txt (line 9)) (2.5.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore->-r requirements.txt (line 9)) (0.9.0)\n","Collecting iopath>=0.1.7 (from fvcore->-r requirements.txt (line 9))\n","  Downloading iopath-0.1.10.tar.gz (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from iopath>=0.1.7->fvcore->-r requirements.txt (line 9)) (4.12.2)\n","Collecting portalocker (from iopath>=0.1.7->fvcore->-r requirements.txt (line 9))\n","  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (2024.10.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (2.32.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->timm->-r requirements.txt (line 4)) (1.3.0)\n","Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv==1.6.0->-r requirements.txt (line 1)) (4.3.6)\n","Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv==1.6.0->-r requirements.txt (line 1)) (2.2.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm->-r requirements.txt (line 4)) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 4)) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 4)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 4)) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 4)) (2024.8.30)\n","\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'tensorboardx' candidate (version 2.6.2 at https://files.pythonhosted.org/packages/44/7b/eee50dcadcee4c674353ca207fdcd53a5b1f382021af1ed1797f9c0c45d2/tensorboardX-2.6.2-py2.py3-none-any.whl (from https://pypi.org/simple/tensorboardx/))\n","Reason for being yanked: protobuf requirement is still needed: tensorboardX/issues/716\u001b[0m\u001b[33m\n","\u001b[0mDownloading tensorboardX-2.6.2-py2.py3-none-any.whl (101 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dict_recursive_update-1.0.1-py2.py3-none-any.whl (4.4 kB)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Downloading yapf-0.43.0-py3-none-any.whl (256 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n","Building wheels for collected packages: mmcv, fvcore, iopath\n","  Building wheel for mmcv (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mmcv: filename=mmcv-1.6.0-py2.py3-none-any.whl size=847982 sha256=6b5b48f22a00b5ac2b6e0a7cda447a7e419a0711c63a73d08142523ef2e73aa6\n","  Stored in directory: /root/.cache/pip/wheels/02/e2/7c/97f72e34ee40d71cdd28b94c9fdfec7bcc453651ad6e65c96d\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=a7f0487ad6b18783303bc5d827804f3a5f06453c9c5d05df68f7800f58b686ef\n","  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31528 sha256=b33898f9a2e7cfaf9928fd5ad164f7f4e2b192e330ddc2aaa91f7327287f4aa5\n","  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n","Successfully built mmcv fvcore iopath\n","Installing collected packages: dict_recursive_update, addict, yapf, yacs, tensorboardX, portalocker, mmcv, iopath, fvcore\n","Successfully installed addict-2.4.0 dict_recursive_update-1.0.1 fvcore-0.1.5.post20221221 iopath-0.1.10 mmcv-1.6.0 portalocker-3.0.0 tensorboardX-2.6.2 yacs-0.1.8 yapf-0.43.0\n"]}]},{"cell_type":"code","source":["! pip install torchinfo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TuBMNDAJ5fcM","executionInfo":{"status":"ok","timestamp":1734443672142,"user_tz":-540,"elapsed":3096,"user":{"displayName":"박수연 (GREAT)","userId":"09302565313834136190"}},"outputId":"5972b2b8-a835-4797-daf2-3f378b38a6aa"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n","Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.8.0\n"]}]},{"cell_type":"code","source":["! python tools/train_cc.py --cfg=configs/QNRF_HR.py --launcher=\"pytorch\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NVnrCQzt43YE","executionInfo":{"status":"ok","timestamp":1734445351375,"user_tz":-540,"elapsed":157137,"user":{"displayName":"박수연 (GREAT)","userId":"09302565313834136190"}},"outputId":"91e86afb-fd21-4493-9453-5133b3aa77c3"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n","  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n","=> creating exp/QNRF/MocHRBackbone_hrnet48/QNRF_HR_2024-12-17-14-19\n","GPU idx:0\n","=> init weights from normal distribution\n","/content/drive/MyDrive/STEERER/STEERER/./lib/models/backbones/hrnet/seg_hrnet_hloc.py:464: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  pretrained_dict = torch.load(pretrained)\n","=> loading pretrained model ../PretrainedModels/QNRF_mae_77.8_mse_138.0.pth\n","Missing keys: ['stage4.2.branches.1.0.bn2.weight', 'stage4.0.branches.2.2.bn2.running_var', 'stage4.0.fuse_layers.1.0.0.0.weight', 'stage3.3.branches.1.1.bn1.num_batches_tracked', 'stage3.1.branches.2.3.conv2.weight', 'stage4.1.fuse_layers.2.0.1.1.num_batches_tracked', 'stage4.0.fuse_layers.3.1.1.1.running_var', 'layer1.2.bn1.num_batches_tracked', 'stage4.1.branches.1.0.bn2.num_batches_tracked', 'stage3.2.branches.0.0.bn1.num_batches_tracked', 'stage3.3.branches.1.3.bn1.num_batches_tracked', 'stage4.1.branches.2.0.bn2.num_batches_tracked', 'stage4.0.fuse_layers.2.0.0.0.weight', 'transition2.2.0.1.running_var', 'stage3.0.branches.2.0.bn2.num_batches_tracked', 'layer1.2.bn2.bias', 'stage4.0.branches.2.0.bn1.weight', 'stage4.1.fuse_layers.3.2.0.1.weight', 'stage3.1.branches.1.3.bn2.weight', 'stage3.0.branches.0.3.bn2.running_mean', 'stage4.2.branches.3.0.conv2.weight', 'stage2.0.branches.1.1.conv1.weight', 'stage4.1.fuse_layers.0.3.1.weight', 'stage4.1.branches.2.0.bn1.weight', 'stage3.2.branches.0.0.bn2.num_batches_tracked', 'stage2.0.branches.1.1.bn1.bias', 'stage3.0.fuse_layers.2.0.0.0.weight', 'stage3.3.branches.2.2.bn2.weight', 'stage3.0.branches.2.2.bn1.running_var', 'stage3.3.fuse_layers.1.0.0.1.weight', 'stage3.2.branches.0.1.conv2.weight', 'stage3.0.branches.2.0.bn1.num_batches_tracked', 'layer1.2.bn2.running_var', 'stage4.1.branches.3.1.bn1.num_batches_tracked', 'stage4.0.branches.0.2.bn1.bias', 'stage3.1.branches.0.1.bn2.weight', 'stage3.2.branches.1.0.bn1.bias', 'stage4.2.branches.2.3.bn1.bias', 'stage4.0.branches.0.2.bn2.weight', 'stage3.1.branches.0.2.bn2.bias', 'stage4.1.branches.3.1.bn2.weight', 'stage3.1.branches.0.0.conv1.weight', 'stage3.0.branches.1.2.bn1.num_batches_tracked', 'stage3.1.fuse_layers.2.0.1.1.weight', 'stage3.1.branches.1.3.bn2.running_var', 'stage4.0.branches.3.1.bn1.weight', 'stage4.2.branches.1.3.bn1.weight', 'stage3.0.branches.2.1.bn1.bias', 'stage3.2.branches.1.3.bn2.weight', 'stage3.3.branches.0.1.bn2.running_var', 'stage4.0.fuse_layers.1.2.1.num_batches_tracked', 'stage4.1.branches.1.3.bn1.bias', 'stage3.0.branches.2.1.bn2.running_mean', 'stage3.0.branches.1.1.bn2.weight', 'stage3.1.fuse_layers.2.1.0.1.num_batches_tracked', 'stage4.0.fuse_layers.1.0.0.1.running_mean', 'stage4.1.branches.1.0.bn2.bias', 'stage3.3.branches.0.1.bn2.bias', 'stage3.3.branches.2.0.bn1.running_var', 'stage3.2.branches.2.1.conv2.weight', 'stage4.2.branches.1.2.bn2.weight', 'stage3.2.branches.2.3.bn1.running_var', 'stage3.3.fuse_layers.2.0.0.1.running_var', 'stage3.1.branches.0.3.bn1.running_mean', 'layer1.0.bn3.bias', 'stage4.0.fuse_layers.2.1.0.1.weight', 'stage4.0.branches.1.0.bn2.num_batches_tracked', 'stage3.3.branches.2.1.bn1.bias', 'stage4.1.fuse_layers.0.2.0.weight', 'stage4.1.branches.0.1.bn2.running_var', 'stage4.1.branches.2.0.bn2.running_var', 'stage3.3.branches.0.2.bn2.running_var', 'stage4.2.branches.3.1.bn2.weight', 'stage3.2.branches.2.2.bn1.weight', 'stage4.0.branches.1.0.conv2.weight', 'stage3.3.branches.0.3.bn1.num_batches_tracked', 'stage3.2.branches.1.3.conv2.weight', 'stage3.3.fuse_layers.0.1.1.bias', 'stage4.0.branches.0.1.bn1.num_batches_tracked', 'stage4.2.branches.1.1.bn1.running_mean', 'stage4.1.branches.1.3.bn2.weight', 'stage3.2.branches.0.1.bn1.bias', 'stage4.2.branches.3.0.bn2.num_batches_tracked', 'stage4.0.branches.2.3.bn2.running_var', 'stage3.2.branches.1.1.bn1.num_batches_tracked', 'stage4.2.branches.1.3.bn2.running_var', 'stage4.0.fuse_layers.1.2.1.running_mean', 'stage3.3.fuse_layers.2.0.0.1.running_mean', 'stage4.1.branches.1.1.bn1.running_var', 'stage3.3.branches.0.3.bn2.weight', 'stage2.0.branches.1.1.conv2.weight', 'stage4.1.branches.1.3.bn2.running_var', 'stage4.0.branches.2.2.bn2.num_batches_tracked', 'stage3.0.fuse_layers.2.1.0.1.running_var', 'stage3.2.fuse_layers.2.0.0.1.weight', 'stage3.1.branches.2.1.conv1.weight', 'stage3.3.branches.1.1.bn1.running_mean', 'stage3.3.branches.1.3.conv1.weight', 'stage3.0.fuse_layers.0.2.1.running_var', 'stage4.2.branches.0.2.conv1.weight', 'stage4.0.branches.0.0.conv1.weight', 'stage3.0.branches.0.1.bn2.running_var', 'stage3.3.fuse_layers.0.2.0.weight', 'stage4.2.branches.1.2.conv1.weight', 'stage4.0.fuse_layers.2.1.0.1.num_batches_tracked', 'stage4.1.branches.0.0.conv2.weight', 'stage3.1.branches.1.2.bn1.bias', 'stage3.1.branches.2.1.bn1.running_mean', 'stage3.2.branches.0.3.bn1.bias', 'stage4.0.fuse_layers.3.0.0.1.weight', 'stage4.2.branches.0.1.bn1.bias', 'stage3.0.fuse_layers.2.0.1.1.running_mean', 'stage3.2.fuse_layers.2.0.1.1.weight', 'stage3.3.branches.1.1.bn1.bias', 'stage4.1.branches.1.1.bn1.bias', 'stage4.0.fuse_layers.1.3.1.num_batches_tracked', 'stage4.0.branches.0.1.bn2.weight', 'layer1.2.bn3.weight', 'stage4.1.branches.0.0.conv1.weight', 'stage4.0.branches.0.2.bn2.running_var', 'stage4.1.branches.3.2.bn1.bias', 'stage4.0.branches.2.2.bn2.running_mean', 'stage4.0.branches.3.3.bn1.bias', 'stage3.0.branches.1.1.bn1.num_batches_tracked', 'layer1.2.bn3.num_batches_tracked', 'stage4.0.fuse_layers.3.1.1.1.bias', 'stage4.0.fuse_layers.3.1.1.1.running_mean', 'stage2.0.branches.1.0.bn2.running_var', 'stage4.1.fuse_layers.3.0.1.1.running_var', 'stage4.1.fuse_layers.3.0.1.1.weight', 'stage3.3.branches.0.1.bn1.running_var', 'stage4.0.branches.2.3.bn1.num_batches_tracked', 'stage4.0.fuse_layers.2.0.0.1.num_batches_tracked', 'stage3.3.fuse_layers.1.2.0.weight', 'stage4.1.fuse_layers.1.2.0.weight', 'stage4.2.branches.1.2.bn2.running_var', 'stage4.1.branches.1.2.conv2.weight', 'stage3.0.branches.0.0.bn2.bias', 'bn1.num_batches_tracked', 'stage3.3.fuse_layers.2.1.0.1.running_var', 'stage3.3.fuse_layers.1.2.1.weight', 'stage4.0.branches.3.3.bn1.running_var', 'stage4.2.branches.1.0.bn1.num_batches_tracked', 'stage3.3.fuse_layers.2.0.1.1.weight', 'stage3.3.branches.2.3.bn1.bias', 'stage4.1.branches.3.1.bn2.running_mean', 'layer1.0.bn2.bias', 'stage3.1.branches.0.0.conv2.weight', 'stage4.2.branches.3.0.bn1.running_mean', 'stage4.0.branches.3.1.bn1.num_batches_tracked', 'stage3.2.fuse_layers.0.1.1.weight', 'stage3.3.branches.0.2.bn1.num_batches_tracked', 'stage3.1.branches.1.0.bn1.num_batches_tracked', 'stage3.0.branches.1.2.bn2.running_mean', 'stage3.3.branches.1.3.bn1.weight', 'stage3.0.branches.2.2.conv2.weight', 'stage4.0.fuse_layers.0.3.1.bias', 'stage3.0.branches.1.2.bn1.running_var', 'stage3.1.branches.1.0.bn2.num_batches_tracked', 'stage4.0.branches.0.2.conv2.weight', 'layer1.0.downsample.1.bias', 'layer1.2.bn2.weight', 'stage3.3.branches.1.0.bn1.running_mean', 'stage4.0.fuse_layers.0.2.0.weight', 'stage3.3.branches.2.0.bn1.weight', 'stage4.2.branches.3.1.bn2.num_batches_tracked', 'stage3.2.fuse_layers.0.2.1.running_var', 'stage3.2.branches.2.1.bn2.weight', 'stage3.1.branches.1.0.bn1.running_var', 'stage3.3.fuse_layers.0.1.1.running_var', 'layer1.1.bn2.running_mean', 'stage4.2.branches.2.3.conv2.weight', 'stage4.2.branches.2.3.bn1.num_batches_tracked', 'stage4.0.branches.2.0.bn1.running_var', 'stage3.0.branches.2.0.bn2.running_var', 'stage3.3.branches.0.0.conv1.weight', 'stage3.1.branches.1.0.bn2.bias', 'stage4.1.branches.2.2.bn1.running_var', 'stage3.0.fuse_layers.1.2.0.weight', 'stage4.2.branches.2.3.bn1.weight', 'stage4.0.fuse_layers.2.3.1.bias', 'stage4.2.branches.2.1.bn1.num_batches_tracked', 'stage4.2.branches.2.3.bn2.running_mean', 'stage3.0.branches.0.1.bn2.num_batches_tracked', 'stage4.2.branches.2.0.bn1.bias', 'transition3.3.0.1.running_mean', 'stage4.1.fuse_layers.3.1.1.1.bias', 'stage3.2.fuse_layers.1.2.1.bias', 'stage3.3.branches.0.3.bn1.bias', 'stage4.2.branches.3.2.bn1.weight', 'stage2.0.fuse_layers.1.0.0.1.weight', 'stage3.0.fuse_layers.1.0.0.1.bias', 'stage4.0.fuse_layers.1.3.1.running_var', 'stage4.0.fuse_layers.0.1.1.weight', 'stage4.0.branches.2.1.conv1.weight', 'bn1.weight', 'stage3.0.branches.1.1.conv2.weight', 'stage3.3.fuse_layers.2.1.0.1.running_mean', 'stage4.1.fuse_layers.3.0.1.1.num_batches_tracked', 'layer1.3.bn3.running_var', 'stage3.0.branches.0.3.conv1.weight', 'stage3.3.branches.2.1.bn1.running_var', 'layer1.3.bn2.running_var', 'stage2.0.fuse_layers.1.0.0.1.num_batches_tracked', 'layer1.3.bn1.running_var', 'stage3.3.branches.1.1.conv1.weight', 'layer1.3.bn1.num_batches_tracked', 'stage3.3.branches.0.0.bn2.running_mean', 'layer1.2.bn1.running_var', 'stage3.0.fuse_layers.2.0.0.1.bias', 'stage3.1.branches.0.0.bn2.bias', 'stage3.1.branches.2.3.bn2.running_var', 'stage3.1.branches.1.0.conv2.weight', 'stage4.2.branches.2.0.conv2.weight', 'stage4.0.branches.2.2.conv2.weight', 'stage3.2.branches.1.2.conv2.weight', 'stage4.0.branches.1.1.bn1.bias', 'stage3.1.branches.0.3.bn1.bias', 'stage4.1.fuse_layers.0.3.1.num_batches_tracked', 'stage2.0.branches.0.3.bn1.running_mean', 'stage3.2.fuse_layers.2.1.0.0.weight', 'stage3.2.branches.2.0.bn1.num_batches_tracked', 'stage3.2.fuse_layers.0.2.1.weight', 'stage3.1.fuse_layers.0.1.1.num_batches_tracked', 'stage3.2.branches.0.2.bn1.bias', 'stage4.0.fuse_layers.2.3.0.weight', 'transition2.2.0.1.running_mean', 'layer1.3.bn3.weight', 'stage3.0.branches.2.1.conv2.weight', 'stage4.1.branches.2.1.bn2.running_mean', 'stage4.2.branches.0.1.bn2.running_var', 'stage4.0.fuse_layers.1.3.1.running_mean', 'stage3.2.branches.0.2.conv2.weight', 'stage4.1.branches.0.2.bn1.running_mean', 'stage4.2.branches.1.3.bn1.running_var', 'stage4.0.fuse_layers.3.0.1.1.weight', 'stage3.3.branches.0.3.conv1.weight', 'stage2.0.branches.0.2.bn1.running_var', 'stage2.0.branches.1.0.bn1.bias', 'stage4.0.branches.2.1.bn2.running_mean', 'stage4.1.branches.2.1.bn1.running_mean', 'stage4.0.branches.1.1.conv1.weight', 'stage3.0.branches.2.0.bn1.running_var', 'stage4.2.branches.3.1.bn2.running_var', 'stage3.2.branches.2.1.bn2.bias', 'stage3.0.branches.1.3.bn1.running_mean', 'stage4.0.branches.0.2.bn1.num_batches_tracked', 'stage4.2.branches.2.2.bn1.running_var', 'stage2.0.branches.0.0.bn2.running_var', 'stage4.2.branches.2.2.bn1.running_mean', 'stage4.0.branches.0.3.bn2.bias', 'stage4.0.branches.2.1.bn1.weight', 'stage3.2.branches.0.0.bn1.bias', 'stage4.1.fuse_layers.1.3.1.bias', 'stage3.2.fuse_layers.2.1.0.1.running_var', 'stage2.0.branches.1.3.bn2.num_batches_tracked', 'stage4.2.branches.3.3.bn2.weight', 'stage3.0.branches.1.3.bn2.num_batches_tracked', 'transition1.1.0.1.num_batches_tracked', 'stage3.1.fuse_layers.2.0.1.1.bias', 'stage4.0.fuse_layers.1.2.0.weight', 'stage3.1.fuse_layers.0.2.1.bias', 'stage2.0.branches.1.1.bn2.num_batches_tracked', 'stage3.2.branches.2.0.bn1.weight', 'stage3.2.branches.2.3.bn2.bias', 'stage3.1.branches.1.2.bn1.running_var', 'stage3.1.fuse_layers.1.2.1.weight', 'stage4.0.fuse_layers.3.1.0.1.num_batches_tracked', 'stage3.2.fuse_layers.2.1.0.1.weight', 'stage2.0.branches.0.2.bn1.weight', 'stage3.0.branches.0.3.bn1.running_var', 'stage4.2.branches.3.2.bn2.running_var', 'stage3.3.fuse_layers.0.2.1.running_mean', 'stage3.0.branches.1.0.bn1.weight', 'stage4.2.branches.0.3.bn2.running_mean', 'stage3.2.fuse_layers.1.0.0.1.running_var', 'stage4.2.branches.3.2.bn1.num_batches_tracked', 'stage4.0.branches.3.0.bn2.num_batches_tracked', 'stage3.1.branches.0.2.bn2.running_mean', 'stage4.2.branches.1.3.bn1.bias', 'stage3.2.branches.1.3.bn2.num_batches_tracked', 'stage3.1.fuse_layers.2.1.0.1.weight', 'stage3.3.branches.2.0.bn1.running_mean', 'stage4.0.branches.1.1.bn1.weight', 'stage4.0.branches.0.1.bn2.running_mean', 'stage4.0.fuse_layers.2.1.0.1.running_mean', 'layer1.3.conv3.weight', 'stage4.0.branches.2.0.bn1.running_mean', 'stage3.2.branches.0.2.conv1.weight', 'stage4.1.fuse_layers.2.0.0.1.running_var', 'stage3.0.branches.0.0.bn2.running_var', 'stage3.1.fuse_layers.1.0.0.0.weight', 'stage4.0.branches.1.2.bn2.weight', 'stage4.0.fuse_layers.1.3.1.weight', 'stage4.0.fuse_layers.0.3.1.weight', 'stage4.1.branches.0.2.bn1.bias', 'stage3.0.fuse_layers.2.1.0.1.bias', 'stage3.1.branches.1.3.bn2.running_mean', 'layer1.1.bn3.num_batches_tracked', 'stage3.1.branches.1.1.bn2.running_mean', 'stage2.0.branches.1.2.bn1.bias', 'stage4.0.branches.2.3.bn1.running_var', 'stage3.1.branches.1.3.bn1.num_batches_tracked', 'stage2.0.branches.0.3.bn1.bias', 'stage4.1.branches.1.3.bn2.running_mean', 'stage3.2.branches.1.1.bn1.running_mean', 'stage3.2.branches.1.1.bn1.bias', 'stage3.3.branches.0.3.conv2.weight', 'stage4.1.fuse_layers.3.0.2.0.weight', 'stage3.1.branches.0.1.bn2.running_var', 'stage4.0.branches.3.1.bn1.running_var', 'stage3.2.fuse_layers.0.1.1.num_batches_tracked', 'stage4.0.branches.3.0.bn2.running_mean', 'stage4.0.fuse_layers.1.0.0.1.num_batches_tracked', 'stage2.0.branches.0.2.bn1.bias', 'stage2.0.fuse_layers.0.1.1.running_mean', 'stage4.1.branches.1.3.conv1.weight', 'stage4.2.branches.1.1.bn1.bias', 'stage3.3.branches.0.2.bn1.bias', 'stage2.0.branches.1.0.bn1.num_batches_tracked', 'stage2.0.branches.0.0.conv2.weight', 'stage3.2.branches.0.3.bn1.running_var', 'stage4.0.branches.1.2.bn1.running_mean', 'stage4.0.branches.3.1.bn2.weight', 'stage3.1.branches.1.1.bn2.weight', 'stage4.1.branches.0.1.bn1.num_batches_tracked', 'stage3.3.branches.0.2.bn2.bias', 'stage4.1.branches.0.1.bn1.running_var', 'stage3.2.branches.1.1.conv2.weight', 'stage4.1.branches.3.0.conv2.weight', 'stage3.1.branches.0.3.bn2.running_mean', 'stage4.0.fuse_layers.2.3.1.running_mean', 'stage4.0.branches.3.0.bn2.running_var', 'stage4.2.branches.0.1.bn2.bias', 'stage4.1.branches.1.2.bn2.running_var', 'stage4.1.fuse_layers.3.1.0.1.bias', 'stage3.0.branches.0.0.bn1.running_var', 'stage4.2.branches.0.0.bn2.num_batches_tracked', 'stage3.2.branches.2.1.bn2.running_var', 'stage3.2.fuse_layers.1.2.1.weight', 'stage4.0.branches.2.3.bn1.weight', 'stage4.0.branches.0.0.bn1.weight', 'stage4.1.fuse_layers.0.3.0.weight', 'stage2.0.branches.0.1.bn1.running_var', 'stage3.2.branches.2.0.bn2.num_batches_tracked', 'stage4.1.branches.2.3.bn2.running_mean', 'stage3.1.branches.1.0.bn2.weight', 'stage3.1.branches.0.0.bn2.weight', 'stage2.0.branches.1.2.bn1.num_batches_tracked', 'stage3.1.branches.1.2.conv2.weight', 'stage4.1.branches.3.0.bn2.weight', 'stage3.0.branches.2.1.bn2.num_batches_tracked', 'stage4.0.fuse_layers.2.1.0.1.bias', 'stage4.0.branches.3.1.conv2.weight', 'stage3.3.fuse_layers.1.0.0.1.running_var', 'layer1.2.conv3.weight', 'stage4.0.fuse_layers.3.0.0.1.num_batches_tracked', 'stage4.0.branches.2.2.bn1.weight', 'stage4.1.fuse_layers.2.1.0.1.weight', 'stage4.0.fuse_layers.3.2.0.1.num_batches_tracked', 'stage4.2.branches.3.3.bn2.bias', 'stage3.3.branches.1.3.bn1.running_var', 'stage4.2.branches.3.0.bn1.num_batches_tracked', 'stage2.0.branches.1.1.bn2.bias', 'stage3.2.fuse_layers.2.1.0.1.running_mean', 'stage4.0.branches.1.2.bn1.running_var', 'stage3.1.fuse_layers.0.1.0.weight', 'stage4.2.branches.2.3.conv1.weight', 'stage2.0.branches.1.1.bn2.weight', 'stage2.0.branches.0.2.bn1.running_mean', 'stage4.2.branches.1.2.bn2.running_mean', 'stage3.3.branches.1.1.conv2.weight', 'stage3.0.branches.1.3.bn1.running_var', 'stage3.3.branches.1.1.bn2.running_var', 'stage3.0.fuse_layers.2.0.0.1.num_batches_tracked', 'stage4.1.branches.0.2.conv1.weight', 'stage4.1.branches.0.0.bn1.num_batches_tracked', 'stage4.1.branches.3.0.bn1.num_batches_tracked', 'stage3.3.branches.2.3.conv1.weight', 'stage3.0.fuse_layers.1.2.1.running_mean', 'stage4.0.branches.3.1.bn2.bias', 'stage3.1.fuse_layers.2.0.1.1.running_mean', 'stage4.0.fuse_layers.3.0.0.0.weight', 'stage3.2.branches.2.0.conv2.weight', 'stage3.3.branches.2.3.bn1.num_batches_tracked', 'stage3.0.branches.2.3.bn2.bias', 'stage4.1.fuse_layers.2.3.0.weight', 'stage2.0.branches.1.0.conv1.weight', 'stage4.0.fuse_layers.3.2.0.1.bias', 'stage3.3.branches.1.2.bn2.weight', 'stage3.2.branches.0.1.bn2.num_batches_tracked', 'stage4.1.branches.0.1.bn2.running_mean', 'stage4.2.branches.1.0.bn2.running_var', 'stage4.1.branches.1.0.bn1.bias', 'stage4.0.branches.2.0.conv2.weight', 'stage4.1.branches.1.3.bn1.num_batches_tracked', 'stage3.3.branches.1.2.bn1.bias', 'stage4.1.branches.2.1.bn2.num_batches_tracked', 'stage4.1.branches.3.3.bn1.running_var', 'layer1.0.bn1.running_mean', 'stage3.0.branches.1.1.bn2.running_var', 'stage4.0.branches.1.3.bn1.running_var', 'stage3.0.branches.1.3.bn1.weight', 'stage4.2.branches.2.0.bn1.running_var', 'conv1.weight', 'stage3.0.branches.0.2.bn2.weight', 'stage4.1.branches.3.0.bn1.running_var', 'stage3.2.branches.0.3.bn1.weight', 'stage4.1.branches.0.1.bn2.weight', 'stage4.1.branches.1.0.bn1.running_mean', 'stage3.0.branches.1.0.bn2.running_var', 'stage2.0.branches.0.2.bn2.running_var', 'stage3.1.branches.0.3.bn2.weight', 'stage4.2.branches.1.2.conv2.weight', 'stage4.0.branches.1.3.bn2.running_var', 'stage3.2.fuse_layers.1.2.1.running_var', 'stage3.3.branches.1.3.bn2.num_batches_tracked', 'stage4.2.branches.0.1.conv1.weight', 'stage3.1.branches.1.1.bn2.running_var', 'stage4.2.branches.0.2.bn2.running_mean', 'stage2.0.branches.1.2.bn1.running_var', 'stage4.1.branches.3.2.bn1.num_batches_tracked', 'stage3.2.branches.1.1.bn1.weight', 'stage4.1.fuse_layers.2.3.1.bias', 'stage4.2.branches.3.3.bn1.num_batches_tracked', 'stage3.1.branches.2.3.bn1.weight', 'stage3.3.branches.2.3.bn2.weight', 'stage3.3.branches.2.0.bn1.num_batches_tracked', 'stage3.3.fuse_layers.0.2.1.running_var', 'stage3.0.branches.1.3.conv1.weight', 'stage4.1.branches.1.3.bn1.running_var', 'stage3.1.branches.1.2.bn1.weight', 'layer1.1.bn1.running_var', 'stage4.1.branches.1.1.bn2.running_mean', 'stage3.2.fuse_layers.1.0.0.0.weight', 'stage4.1.branches.2.2.bn1.weight', 'stage3.2.branches.0.1.bn1.weight', 'stage3.3.branches.1.3.bn2.running_mean', 'stage4.0.branches.0.1.bn2.num_batches_tracked', 'stage4.0.branches.1.1.bn2.running_mean', 'stage3.1.fuse_layers.1.2.1.running_mean', 'stage4.1.branches.0.2.bn1.num_batches_tracked', 'stage4.0.branches.1.1.bn1.num_batches_tracked', 'stage3.3.fuse_layers.1.2.1.bias', 'stage4.2.branches.2.2.bn1.weight', 'stage3.1.branches.1.1.bn1.bias', 'stage3.0.branches.0.1.conv2.weight', 'stage3.3.branches.1.0.bn1.running_var', 'stage4.2.branches.1.0.conv2.weight', 'stage4.2.branches.1.1.bn1.running_var', 'stage4.2.branches.3.3.bn1.running_var', 'stage4.0.branches.2.0.bn2.num_batches_tracked', 'stage2.0.branches.1.3.bn2.running_var', 'stage2.0.branches.1.1.bn1.running_mean', 'stage3.3.branches.1.2.conv2.weight', 'stage3.2.branches.1.2.bn1.running_mean', 'stage3.1.branches.2.2.bn1.num_batches_tracked', 'stage4.2.branches.3.2.conv1.weight', 'stage4.2.branches.3.3.bn1.weight', 'stage3.0.fuse_layers.2.0.1.1.running_var', 'stage4.1.branches.2.2.bn2.weight', 'stage3.3.branches.1.0.bn1.weight', 'stage3.2.branches.0.3.bn2.bias', 'stage2.0.branches.1.3.conv2.weight', 'stage2.0.branches.0.0.bn1.bias', 'stage3.0.branches.1.2.conv1.weight', 'stage4.0.branches.1.2.bn1.bias', 'stage4.0.branches.1.3.conv2.weight', 'stage3.0.branches.2.1.bn1.running_var', 'stage4.2.branches.1.0.bn1.running_var', 'stage4.2.branches.0.0.bn1.bias', 'stage4.1.fuse_layers.1.3.1.running_mean', 'stage3.3.branches.0.2.bn1.running_var', 'stage4.0.fuse_layers.3.1.1.0.weight', 'stage4.2.branches.1.2.bn1.num_batches_tracked', 'stage4.1.branches.0.2.bn2.weight', 'stage4.2.branches.1.2.bn1.running_var', 'stage2.0.branches.0.0.bn1.num_batches_tracked', 'stage3.2.branches.1.3.bn1.bias', 'stage3.3.branches.2.0.bn1.bias', 'stage3.0.branches.2.2.conv1.weight', 'stage4.1.branches.0.2.bn2.num_batches_tracked', 'stage4.1.fuse_layers.1.3.1.num_batches_tracked', 'stage2.0.branches.1.0.bn2.weight', 'stage3.2.branches.2.1.bn1.num_batches_tracked', 'stage4.0.branches.1.3.bn2.running_mean', 'stage3.0.branches.1.0.bn1.bias', 'stage3.0.fuse_layers.2.1.0.1.running_mean', 'stage3.3.branches.0.1.conv1.weight', 'layer1.1.conv3.weight', 'stage4.1.fuse_layers.2.0.1.1.running_var', 'stage2.0.branches.1.3.bn1.running_mean', 'stage3.0.branches.2.0.bn1.weight', 'stage4.2.branches.1.3.bn2.bias', 'stage4.1.branches.1.1.conv2.weight', 'stage4.2.branches.2.2.conv2.weight', 'stage3.0.fuse_layers.0.1.1.running_var', 'stage4.1.branches.3.1.bn1.bias', 'stage4.2.branches.3.2.bn2.num_batches_tracked', 'stage3.1.branches.1.1.bn1.num_batches_tracked', 'stage4.0.branches.0.0.bn2.weight', 'transition2.2.0.1.weight', 'stage4.1.branches.3.3.conv2.weight', 'stage4.0.branches.2.2.bn1.running_mean', 'stage3.0.branches.2.2.bn2.running_mean', 'stage3.1.branches.1.1.conv1.weight', 'layer1.0.bn1.running_var', 'stage3.0.branches.1.2.bn2.num_batches_tracked', 'stage4.1.branches.1.3.bn1.weight', 'stage3.1.branches.1.3.bn1.running_var', 'stage3.3.fuse_layers.1.2.1.running_mean', 'stage4.1.fuse_layers.0.3.1.running_mean', 'stage4.1.branches.1.0.bn2.running_var', 'stage4.0.branches.2.2.conv1.weight', 'stage3.0.branches.1.3.bn2.running_var', 'stage3.1.branches.2.0.bn1.running_var', 'stage2.0.branches.1.0.bn1.running_var', 'stage4.0.branches.1.1.bn2.running_var', 'layer1.0.bn3.running_mean', 'stage4.0.fuse_layers.3.2.0.1.running_var', 'stage3.3.fuse_layers.2.0.0.1.num_batches_tracked', 'stage4.0.fuse_layers.3.0.1.1.num_batches_tracked', 'stage3.3.branches.1.1.bn2.num_batches_tracked', 'stage3.1.branches.1.0.bn1.bias', 'stage3.2.branches.1.1.bn2.running_var', 'stage2.0.fuse_layers.1.0.0.1.running_mean', 'stage4.1.fuse_layers.1.0.0.0.weight', 'layer1.3.bn2.num_batches_tracked', 'stage4.1.branches.1.2.bn2.weight', 'stage3.1.fuse_layers.1.0.0.1.weight', 'stage2.0.branches.0.3.bn1.weight', 'stage3.3.fuse_layers.1.2.1.running_var', 'stage3.0.branches.2.2.bn2.num_batches_tracked', 'transition1.1.0.1.weight', 'stage3.0.fuse_layers.0.2.0.weight', 'stage4.0.branches.2.1.bn2.bias', 'stage4.0.branches.1.3.bn2.weight', 'stage3.1.fuse_layers.2.1.0.1.bias', 'stage4.0.branches.2.2.bn2.bias', 'stage3.2.fuse_layers.1.2.1.running_mean', 'stage4.1.branches.2.0.bn1.running_var', 'stage2.0.branches.0.3.conv2.weight', 'stage3.3.branches.0.0.conv2.weight', 'stage3.2.branches.2.2.bn2.bias', 'stage4.0.branches.3.0.bn1.weight', 'layer1.3.conv1.weight', 'stage3.2.branches.2.1.bn1.running_mean', 'stage3.0.fuse_layers.0.1.1.bias', 'stage4.0.branches.3.2.bn2.running_var', 'stage4.2.branches.1.1.bn2.running_var', 'stage4.1.branches.0.0.bn2.num_batches_tracked', 'stage3.3.branches.2.1.bn2.num_batches_tracked', 'stage4.1.fuse_layers.3.2.0.1.num_batches_tracked', 'stage3.3.branches.2.1.bn1.running_mean', 'stage4.1.branches.2.2.bn2.num_batches_tracked', 'stage3.0.branches.1.2.bn2.running_var', 'stage3.0.branches.0.2.bn1.running_var', 'stage4.1.fuse_layers.0.3.1.running_var', 'stage4.1.branches.2.1.bn2.weight', 'layer1.2.bn3.running_var', 'stage3.3.branches.2.1.bn1.num_batches_tracked', 'stage4.1.fuse_layers.1.2.1.running_mean', 'stage4.0.branches.0.2.bn2.bias', 'stage3.0.fuse_layers.0.2.1.weight', 'stage4.0.branches.3.0.bn1.bias', 'stage3.0.fuse_layers.1.0.0.1.running_var', 'stage2.0.branches.0.2.bn2.bias', 'stage3.0.branches.1.1.bn1.running_mean', 'stage3.1.branches.2.2.bn2.running_var', 'stage4.1.branches.0.2.bn1.weight', 'stage4.0.branches.3.3.bn2.weight', 'stage4.2.branches.3.0.bn2.running_var', 'stage4.0.fuse_layers.0.2.1.num_batches_tracked', 'stage3.3.fuse_layers.2.1.0.1.num_batches_tracked', 'stage3.0.branches.2.1.bn1.num_batches_tracked', 'stage3.0.branches.0.2.bn2.bias', 'stage4.2.branches.2.2.bn2.running_var', 'stage4.1.branches.1.1.conv1.weight', 'stage2.0.branches.0.0.bn2.running_mean', 'stage4.2.branches.0.1.bn1.weight', 'stage3.2.branches.0.0.bn1.running_mean', 'stage3.3.fuse_layers.2.0.0.0.weight', 'layer1.0.bn2.running_var', 'stage4.1.fuse_layers.1.3.1.weight', 'stage2.0.fuse_layers.1.0.0.1.running_var', 'stage4.2.branches.2.0.bn1.weight', 'stage3.1.branches.0.2.bn1.num_batches_tracked', 'stage3.0.branches.0.1.bn1.running_var', 'stage4.2.branches.3.1.bn2.running_mean', 'stage3.3.branches.1.1.bn2.running_mean', 'stage4.1.branches.2.0.bn1.num_batches_tracked', 'stage4.1.fuse_layers.2.0.0.1.num_batches_tracked', 'stage4.2.branches.0.2.bn2.bias', 'stage3.0.branches.0.3.bn1.weight', 'stage4.1.fuse_layers.1.0.0.1.bias', 'stage3.3.branches.1.0.bn2.running_mean', 'stage4.2.branches.3.2.bn2.running_mean', 'stage4.2.branches.1.0.bn2.running_mean', 'stage3.2.branches.1.2.bn1.bias', 'stage4.1.branches.2.2.bn1.running_mean', 'stage3.0.branches.2.2.bn2.weight', 'stage4.1.branches.0.1.bn1.weight', 'stage3.1.branches.1.2.bn1.num_batches_tracked', 'stage3.3.branches.1.0.bn2.bias', 'stage4.1.branches.1.2.bn1.running_var', 'stage2.0.branches.0.3.bn2.num_batches_tracked', 'stage2.0.branches.1.2.bn1.weight', 'stage4.1.branches.2.3.bn1.running_mean', 'stage4.0.fuse_layers.2.0.1.1.num_batches_tracked', 'stage3.2.branches.2.2.bn2.num_batches_tracked', 'stage4.0.branches.0.1.bn2.bias', 'stage3.2.branches.0.3.bn1.num_batches_tracked', 'stage3.1.branches.0.0.bn1.weight', 'stage3.1.fuse_layers.1.2.0.weight', 'stage4.0.fuse_layers.2.0.0.1.running_var', 'stage4.0.fuse_layers.0.3.1.running_var', 'stage4.0.branches.1.3.bn1.running_mean', 'transition2.2.0.0.weight', 'stage3.3.branches.0.0.bn1.running_var', 'stage3.3.branches.0.0.bn1.running_mean', 'layer1.0.conv2.weight', 'stage3.2.branches.2.0.bn1.bias', 'stage4.0.fuse_layers.2.3.1.running_var', 'stage4.1.branches.0.0.bn1.weight', 'stage3.2.fuse_layers.2.0.1.1.running_mean', 'stage4.0.branches.0.3.bn2.running_mean', 'stage4.2.branches.2.1.bn2.running_mean', 'stage3.0.branches.1.2.bn2.bias', 'stage3.1.branches.1.0.conv1.weight', 'stage4.1.branches.3.0.bn2.running_mean', 'stage4.1.branches.3.2.bn2.running_mean', 'stage4.2.branches.0.3.bn1.bias', 'stage4.2.branches.1.0.conv1.weight', 'stage3.1.branches.1.3.conv2.weight', 'stage4.1.fuse_layers.3.0.1.0.weight', 'stage4.1.fuse_layers.0.2.1.weight', 'stage2.0.branches.0.1.bn1.num_batches_tracked', 'stage4.1.branches.2.0.bn2.weight', 'stage2.0.fuse_layers.0.1.1.weight', 'stage3.0.branches.0.1.bn1.num_batches_tracked', 'stage4.0.branches.1.0.bn1.running_var', 'stage4.1.branches.0.2.conv2.weight', 'stage2.0.branches.0.0.bn1.weight', 'stage4.1.branches.1.3.bn2.bias', 'stage3.3.branches.1.0.bn2.running_var', 'stage2.0.branches.1.0.bn1.running_mean', 'stage4.1.branches.3.1.bn2.num_batches_tracked', 'stage3.0.branches.2.2.bn2.running_var', 'stage4.0.branches.1.1.bn2.weight', 'stage4.2.branches.1.3.bn2.weight', 'stage3.1.branches.2.1.bn1.num_batches_tracked', 'stage4.1.branches.1.0.bn1.weight', 'stage4.2.branches.2.1.bn1.running_var', 'stage3.2.branches.0.2.bn1.num_batches_tracked', 'stage4.0.branches.2.1.bn2.num_batches_tracked', 'stage4.2.branches.1.2.bn1.weight', 'stage4.1.branches.1.2.bn2.num_batches_tracked', 'stage3.2.branches.0.2.bn1.running_var', 'stage4.1.fuse_layers.3.2.0.0.weight', 'stage3.2.branches.1.3.bn2.running_var', 'stage4.2.branches.2.3.bn2.num_batches_tracked', 'stage4.0.branches.0.0.conv2.weight', 'stage3.1.branches.1.3.bn1.running_mean', 'stage3.1.branches.1.2.bn2.weight', 'layer1.1.bn3.weight', 'stage4.2.branches.1.3.bn1.num_batches_tracked', 'stage4.0.branches.1.2.conv1.weight', 'stage4.2.branches.1.3.bn2.running_mean', 'stage3.1.branches.2.3.bn1.running_mean', 'stage4.1.branches.0.3.bn2.bias', 'stage4.1.fuse_layers.2.1.0.1.bias', 'stage3.3.branches.2.2.bn2.num_batches_tracked', 'stage2.0.branches.0.1.bn2.running_var', 'stage4.2.branches.0.3.bn2.bias', 'stage3.0.branches.0.1.bn1.bias', 'stage4.0.branches.3.0.conv2.weight', 'stage4.0.branches.3.0.conv1.weight', 'stage2.0.branches.0.3.bn2.bias', 'stage3.0.branches.2.0.bn1.bias', 'stage3.3.branches.0.3.bn1.running_var', 'bn1.running_mean', 'stage3.0.branches.0.1.bn2.weight', 'stage4.0.branches.3.2.conv2.weight', 'stage4.0.fuse_layers.3.0.2.1.weight', 'stage3.2.branches.0.0.bn1.weight', 'stage3.0.branches.1.3.bn2.weight', 'stage4.1.branches.0.3.bn2.weight', 'stage3.0.branches.1.1.bn2.running_mean', 'stage3.1.branches.0.1.conv1.weight', 'stage3.2.branches.2.0.bn2.running_var', 'stage3.1.branches.0.1.conv2.weight', 'stage4.1.fuse_layers.0.2.1.running_var', 'stage4.0.branches.1.0.bn1.running_mean', 'stage4.2.branches.3.1.bn1.weight', 'stage3.0.branches.2.3.conv1.weight', 'stage4.2.branches.0.3.bn2.weight', 'stage4.1.fuse_layers.3.1.0.0.weight', 'stage3.2.branches.1.2.bn1.num_batches_tracked', 'stage4.1.branches.0.0.bn2.bias', 'stage3.3.fuse_layers.2.0.1.0.weight', 'stage3.2.fuse_layers.0.2.1.running_mean', 'layer1.1.bn1.num_batches_tracked', 'stage4.2.branches.0.2.bn1.bias', 'stage3.0.branches.1.0.bn1.running_mean', 'stage4.1.branches.2.2.bn1.bias', 'stage3.2.fuse_layers.0.1.1.running_var', 'stage3.2.fuse_layers.2.0.1.1.running_var', 'stage3.0.branches.2.3.bn2.running_mean', 'stage4.2.branches.0.2.bn1.running_mean', 'stage4.1.branches.0.2.bn2.running_mean', 'stage2.0.branches.0.2.conv2.weight', 'stage4.2.branches.2.0.bn2.bias', 'stage4.0.branches.3.1.conv1.weight', 'stage3.0.branches.1.2.bn1.weight', 'stage3.1.branches.1.3.bn2.num_batches_tracked', 'stage3.1.branches.2.0.bn1.running_mean', 'stage4.1.branches.0.0.bn1.running_var', 'stage3.0.branches.0.2.bn2.running_var', 'stage4.2.branches.0.3.conv2.weight', 'stage3.2.fuse_layers.0.2.1.num_batches_tracked', 'stage3.1.branches.2.3.bn1.num_batches_tracked', 'stage3.2.branches.2.0.bn2.bias', 'stage4.1.branches.1.0.bn1.running_var', 'stage4.1.branches.3.2.bn1.weight', 'stage2.0.branches.1.2.bn2.bias', 'stage4.0.branches.3.0.bn1.num_batches_tracked', 'stage4.1.branches.0.3.bn1.running_mean', 'stage3.0.fuse_layers.2.0.1.1.weight', 'stage4.0.fuse_layers.2.0.1.1.weight', 'stage4.1.branches.1.0.conv1.weight', 'stage3.2.branches.0.3.conv2.weight', 'stage3.0.branches.0.2.bn1.weight', 'stage4.1.fuse_layers.0.3.1.bias', 'stage3.1.fuse_layers.1.0.0.1.running_var', 'stage4.1.branches.3.3.bn2.running_mean', 'stage4.0.branches.1.0.bn1.bias', 'stage4.2.branches.2.2.bn1.bias', 'stage4.0.fuse_layers.3.2.0.1.weight', 'stage4.2.branches.0.1.bn1.running_mean', 'stage4.0.branches.0.1.bn1.weight', 'stage2.0.branches.0.0.bn2.weight', 'layer1.0.bn1.weight', 'stage4.2.branches.0.3.conv1.weight', 'stage4.1.branches.0.3.bn1.bias', 'stage4.1.branches.0.3.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'stage4.2.branches.3.2.bn2.bias', 'stage3.1.branches.1.1.bn1.running_mean', 'stage3.3.branches.0.0.bn1.num_batches_tracked', 'stage4.0.branches.1.2.bn1.num_batches_tracked', 'stage4.1.branches.3.3.bn2.num_batches_tracked', 'layer1.1.bn2.weight', 'stage3.3.branches.2.0.bn2.num_batches_tracked', 'stage3.2.fuse_layers.2.0.0.1.bias', 'stage3.3.branches.2.3.bn2.bias', 'stage4.0.fuse_layers.1.2.1.bias', 'stage3.0.branches.0.0.bn1.bias', 'stage3.3.branches.2.1.bn2.weight', 'stage3.1.branches.2.2.conv2.weight', 'stage3.3.branches.0.2.bn2.num_batches_tracked', 'transition1.1.0.1.bias', 'stage2.0.branches.1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'stage3.2.branches.1.0.bn2.num_batches_tracked', 'bn2.weight', 'stage3.3.fuse_layers.2.0.1.1.bias', 'stage4.1.fuse_layers.0.1.1.running_mean', 'stage3.0.branches.0.0.bn2.num_batches_tracked', 'layer1.2.conv2.weight', 'stage2.0.branches.0.1.bn2.weight', 'stage3.1.branches.2.0.conv1.weight', 'stage4.1.branches.3.2.bn2.bias', 'stage3.1.branches.0.1.bn1.weight', 'stage4.2.branches.0.2.bn2.running_var', 'stage3.2.branches.1.0.bn2.running_mean', 'stage4.2.branches.3.1.conv1.weight', 'stage3.1.branches.2.0.conv2.weight', 'stage4.0.branches.0.3.conv2.weight', 'stage4.0.branches.3.2.bn1.bias', 'stage2.0.fuse_layers.1.0.0.1.bias', 'bn1.running_var', 'stage3.0.branches.0.2.bn2.running_mean', 'stage4.1.branches.2.1.bn2.running_var', 'stage3.3.branches.1.0.bn2.weight', 'stage3.3.branches.1.2.bn2.num_batches_tracked', 'stage4.0.fuse_layers.3.0.1.1.bias', 'stage4.0.fuse_layers.3.0.2.1.running_var', 'stage3.0.branches.1.0.bn2.running_mean', 'stage3.3.branches.2.1.bn2.running_mean', 'stage3.0.fuse_layers.2.1.0.0.weight', 'stage3.2.branches.1.3.bn2.bias', 'stage2.0.branches.0.1.bn1.bias', 'stage4.1.fuse_layers.0.2.1.bias', 'stage3.2.branches.1.3.bn1.running_var', 'stage4.1.fuse_layers.3.0.1.1.running_mean', 'stage4.1.branches.3.0.bn2.running_var', 'stage3.0.branches.0.0.conv1.weight', 'stage3.3.fuse_layers.2.1.0.1.bias', 'stage4.0.fuse_layers.3.2.0.1.running_mean', 'stage3.2.fuse_layers.2.0.0.1.running_mean', 'stage3.3.branches.2.2.bn2.running_mean', 'stage2.0.branches.1.0.bn2.num_batches_tracked', 'stage3.0.fuse_layers.2.0.0.1.running_mean', 'stage3.0.branches.2.1.bn1.weight', 'stage4.2.branches.0.1.bn2.running_mean', 'stage4.2.branches.2.0.bn2.running_mean', 'stage4.2.branches.0.3.bn2.running_var', 'stage3.1.branches.1.2.conv1.weight', 'layer1.2.bn2.running_mean', 'stage3.0.fuse_layers.1.0.0.1.num_batches_tracked', 'layer1.3.bn1.weight', 'stage4.1.fuse_layers.3.2.0.1.bias', 'stage4.1.fuse_layers.2.3.1.running_var', 'stage2.0.branches.0.0.bn2.num_batches_tracked', 'stage3.0.branches.1.0.conv2.weight', 'stage3.1.branches.1.0.bn2.running_var', 'stage4.0.branches.0.0.bn1.running_var', 'stage2.0.branches.1.3.bn2.bias', 'stage2.0.fuse_layers.0.1.1.bias', 'stage4.1.branches.0.2.bn1.running_var', 'stage3.0.branches.2.3.bn1.weight', 'stage2.0.branches.0.3.bn1.running_var', 'stage4.0.branches.3.0.bn1.running_mean', 'stage4.0.branches.2.1.bn1.num_batches_tracked', 'stage3.3.branches.2.0.bn2.running_mean', 'stage2.0.branches.1.3.conv1.weight', 'stage3.3.branches.2.2.conv2.weight', 'stage3.1.fuse_layers.2.0.0.0.weight', 'stage4.1.branches.0.3.conv2.weight', 'stage4.2.branches.0.1.bn2.weight', 'stage3.3.fuse_layers.2.0.1.1.num_batches_tracked', 'stage3.1.branches.2.2.conv1.weight', 'stage4.1.branches.3.0.bn1.bias', 'stage4.1.fuse_layers.3.0.0.1.num_batches_tracked', 'stage3.3.branches.2.3.bn1.running_mean', 'stage2.0.branches.1.3.bn1.running_var', 'stage4.1.fuse_layers.0.1.1.num_batches_tracked', 'stage4.0.branches.1.3.bn2.bias', 'stage4.1.fuse_layers.3.2.0.1.running_var', 'stage3.0.branches.0.0.conv2.weight', 'stage4.0.branches.2.3.bn2.num_batches_tracked', 'stage4.1.branches.2.3.bn2.num_batches_tracked', 'stage4.2.branches.1.0.bn1.weight', 'stage4.1.branches.1.2.bn1.num_batches_tracked', 'stage4.0.branches.0.0.bn2.bias', 'stage3.0.branches.2.0.conv2.weight', 'stage4.0.branches.1.1.bn2.num_batches_tracked', 'stage3.3.fuse_layers.1.0.0.1.running_mean', 'stage4.1.fuse_layers.3.1.0.1.running_var', 'stage3.3.branches.0.1.conv2.weight', 'stage3.0.fuse_layers.1.0.0.1.weight', 'stage3.3.fuse_layers.2.1.0.0.weight', 'stage4.0.branches.2.1.bn1.running_mean', 'stage3.1.branches.2.2.bn2.num_batches_tracked', 'stage3.2.branches.2.3.bn2.running_var', 'stage4.1.fuse_layers.3.1.1.0.weight', 'stage3.1.branches.2.2.bn1.bias', 'stage4.1.fuse_layers.3.0.0.1.weight', 'stage3.3.fuse_layers.0.1.1.weight', 'stage4.0.branches.3.2.bn1.running_var', 'stage4.2.branches.0.0.conv1.weight', 'stage3.3.branches.2.0.conv1.weight', 'stage3.1.branches.0.3.bn2.running_var', 'stage2.0.branches.0.3.bn2.weight', 'layer1.3.bn2.weight', 'stage3.0.branches.0.2.conv2.weight', 'stage4.1.branches.2.0.bn2.bias', 'stage3.2.fuse_layers.0.1.0.weight', 'stage3.1.branches.1.3.bn2.bias', 'stage4.1.fuse_layers.1.0.0.1.running_var', 'stage2.0.branches.1.1.bn1.weight', 'stage4.0.branches.3.1.bn2.num_batches_tracked', 'stage4.0.branches.0.3.conv1.weight', 'stage4.0.branches.1.1.bn2.bias', 'stage3.0.branches.0.3.bn2.bias', 'stage3.1.branches.0.0.bn1.num_batches_tracked', 'stage3.2.branches.2.2.bn2.weight', 'stage2.0.branches.0.1.bn2.bias', 'stage4.0.fuse_layers.1.2.1.weight', 'stage3.0.branches.0.3.bn1.num_batches_tracked', 'stage3.1.fuse_layers.2.0.1.0.weight', 'stage4.0.branches.3.2.bn2.running_mean', 'stage4.0.fuse_layers.0.2.1.running_mean', 'stage4.1.branches.3.1.conv1.weight', 'stage3.3.fuse_layers.1.0.0.1.bias', 'stage3.2.fuse_layers.2.0.1.0.weight', 'transition1.0.1.running_var', 'stage3.0.branches.2.2.bn2.bias', 'stage3.1.fuse_layers.2.0.0.1.weight', 'stage3.0.branches.0.3.bn2.num_batches_tracked', 'stage3.1.fuse_layers.2.0.0.1.running_mean', 'stage3.1.branches.2.1.bn2.running_var', 'stage3.1.branches.0.2.bn2.running_var', 'layer1.0.bn3.weight', 'stage3.0.branches.1.3.bn2.bias', 'stage3.2.branches.0.3.conv1.weight', 'stage3.1.fuse_layers.2.1.0.0.weight', 'transition1.1.0.0.weight', 'transition1.0.1.weight', 'stage3.2.branches.0.1.bn1.num_batches_tracked', 'stage2.0.branches.1.2.bn2.running_mean', 'stage4.1.fuse_layers.2.1.0.1.num_batches_tracked', 'stage4.1.branches.1.2.conv1.weight', 'stage3.2.branches.1.2.bn2.running_var', 'stage3.1.branches.0.0.bn2.running_mean', 'stage3.3.fuse_layers.0.2.1.weight', 'bn2.running_var', 'stage3.2.branches.0.2.bn2.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'stage4.0.branches.0.3.bn2.num_batches_tracked', 'stage3.3.branches.2.3.bn2.num_batches_tracked', 'layer1.2.bn3.bias', 'stage4.2.branches.0.2.bn1.weight', 'stage4.2.branches.3.3.bn2.num_batches_tracked', 'stage4.0.fuse_layers.3.0.0.1.running_mean', 'stage4.1.fuse_layers.2.1.0.1.running_mean', 'stage3.0.fuse_layers.1.0.0.1.running_mean', 'stage4.1.fuse_layers.1.2.1.bias', 'stage3.1.fuse_layers.2.0.1.1.num_batches_tracked', 'stage4.2.branches.2.0.bn1.running_mean', 'layer1.2.bn1.running_mean', 'stage4.1.fuse_layers.3.2.0.1.running_mean', 'stage4.1.branches.1.0.bn2.running_mean', 'stage4.2.branches.3.1.bn1.running_mean', 'stage3.2.branches.1.2.bn2.bias', 'stage3.1.fuse_layers.2.0.0.1.bias', 'stage4.0.branches.1.3.bn1.weight', 'stage4.1.fuse_layers.2.1.0.1.running_var', 'stage4.0.branches.3.1.bn2.running_mean', 'stage4.0.fuse_layers.0.3.0.weight', 'stage4.1.branches.3.3.bn2.bias', 'stage4.1.branches.1.0.bn2.weight', 'stage4.0.branches.3.3.bn2.running_var', 'stage2.0.branches.0.1.bn1.running_mean', 'stage4.1.fuse_layers.0.2.1.num_batches_tracked', 'layer1.1.bn1.bias', 'stage3.0.fuse_layers.1.2.1.bias', 'stage3.2.branches.2.1.bn1.bias', 'stage4.2.branches.1.1.conv2.weight', 'stage4.0.branches.1.0.bn2.running_mean', 'stage3.2.branches.2.3.bn1.bias', 'stage4.1.branches.3.1.bn1.running_var', 'stage3.2.branches.0.2.bn2.weight', 'stage3.0.fuse_layers.2.1.0.1.num_batches_tracked', 'stage3.0.branches.0.0.bn1.running_mean', 'layer1.3.bn3.num_batches_tracked', 'stage3.0.branches.1.2.conv2.weight', 'stage3.0.branches.2.1.conv1.weight', 'layer1.0.bn3.running_var', 'stage3.1.fuse_layers.2.0.0.1.running_var', 'stage3.0.branches.1.1.bn1.running_var', 'stage4.1.branches.3.1.bn2.running_var', 'stage3.0.branches.2.0.bn1.running_mean', 'stage4.1.branches.3.3.bn2.running_var', 'stage3.2.fuse_layers.0.1.1.bias', 'stage3.0.fuse_layers.1.0.0.0.weight', 'stage2.0.branches.1.2.bn2.running_var', 'stage3.0.branches.0.1.bn2.running_mean', 'stage4.2.branches.3.3.conv1.weight', 'stage3.1.fuse_layers.0.2.1.running_mean', 'stage4.0.branches.1.1.bn1.running_var', 'stage3.0.branches.1.1.bn1.weight', 'stage4.2.branches.1.2.bn2.num_batches_tracked', 'stage3.1.branches.2.3.bn2.num_batches_tracked', 'layer1.1.bn3.running_var', 'layer1.3.bn2.bias', 'stage3.2.branches.2.3.conv1.weight', 'stage3.0.fuse_layers.0.2.1.num_batches_tracked', 'stage3.0.branches.0.2.bn1.num_batches_tracked', 'stage4.1.branches.1.1.bn2.bias', 'stage3.3.fuse_layers.2.0.1.1.running_mean', 'stage2.0.branches.1.3.bn1.num_batches_tracked', 'stage3.0.branches.2.2.bn1.num_batches_tracked', 'stage4.2.branches.0.0.bn1.running_mean', 'stage3.3.fuse_layers.0.1.1.running_mean', 'stage3.0.branches.1.1.bn2.bias', 'stage4.2.branches.0.2.bn2.num_batches_tracked', 'stage4.1.branches.2.1.conv2.weight', 'stage4.0.branches.0.0.bn2.running_mean', 'stage4.1.branches.2.2.bn1.num_batches_tracked', 'stage2.0.branches.1.2.bn2.weight', 'stage3.0.branches.2.1.bn2.running_var', 'stage4.1.branches.3.1.bn1.running_mean', 'stage3.0.branches.2.3.bn1.running_mean', 'layer1.0.conv3.weight', 'stage3.3.branches.0.3.bn1.running_mean', 'stage4.0.fuse_layers.3.0.2.0.weight', 'stage4.0.branches.3.3.bn1.weight', 'stage4.1.branches.2.3.conv2.weight', 'stage4.2.branches.2.3.bn2.bias', 'stage3.3.branches.0.1.bn1.weight', 'stage4.1.fuse_layers.3.0.0.1.running_mean', 'stage3.2.branches.1.3.bn2.running_mean', 'stage3.3.fuse_layers.2.0.0.1.weight', 'stage4.0.fuse_layers.1.2.1.running_var', 'stage4.0.branches.3.3.conv2.weight', 'stage4.0.fuse_layers.1.0.0.1.bias', 'stage4.2.branches.1.1.bn1.weight', 'stage3.0.branches.1.2.bn1.running_mean', 'stage4.0.branches.2.1.bn1.bias', 'layer1.0.downsample.1.running_mean', 'stage3.2.branches.0.3.bn1.running_mean', 'stage3.0.branches.0.0.bn2.running_mean', 'stage3.2.branches.2.2.bn1.num_batches_tracked', 'stage4.1.branches.0.1.conv2.weight', 'stage4.1.branches.0.0.bn2.running_mean', 'stage3.3.branches.2.2.bn2.running_var', 'stage3.0.branches.2.3.bn1.running_var', 'bn2.bias', 'stage2.0.branches.1.2.bn1.running_mean', 'stage4.0.branches.1.0.bn2.weight', 'layer1.1.conv2.weight', 'stage4.0.branches.0.0.bn2.running_var', 'stage4.2.branches.0.1.bn2.num_batches_tracked', 'stage3.3.branches.0.1.bn2.weight', 'stage3.2.branches.2.1.bn1.weight', 'stage4.0.branches.3.2.bn1.weight', 'stage3.2.branches.1.1.conv1.weight', 'stage4.0.branches.2.0.bn2.running_var', 'stage3.1.branches.1.0.bn2.running_mean', 'stage4.0.branches.3.0.bn1.running_var', 'stage4.1.branches.3.3.conv1.weight', 'stage3.1.branches.2.1.bn1.bias', 'stage3.2.branches.0.0.conv2.weight', 'stage2.0.fuse_layers.0.1.1.num_batches_tracked', 'stage3.2.branches.2.0.conv1.weight', 'stage3.1.branches.2.0.bn2.running_mean', 'stage3.2.branches.2.3.conv2.weight', 'transition3.3.0.1.running_var', 'stage3.3.branches.2.2.bn1.bias', 'stage4.1.branches.3.1.conv2.weight', 'stage3.0.branches.1.3.bn1.num_batches_tracked', 'stage3.2.fuse_layers.1.0.0.1.running_mean', 'stage3.2.branches.1.2.bn1.weight', 'stage3.2.branches.1.0.conv1.weight', 'transition2.2.0.1.num_batches_tracked', 'stage3.0.branches.0.2.bn2.num_batches_tracked', 'stage3.3.fuse_layers.2.0.1.1.running_var', 'stage3.0.branches.1.3.bn2.running_mean', 'stage4.2.branches.3.0.conv1.weight', 'stage4.2.branches.0.0.bn2.running_mean', 'stage3.3.branches.0.1.bn2.running_mean', 'stage4.2.branches.2.2.bn2.bias', 'stage3.3.branches.2.2.bn1.num_batches_tracked', 'stage3.0.branches.2.1.bn1.running_mean', 'stage4.0.branches.0.1.conv1.weight', 'stage3.0.branches.0.1.conv1.weight', 'layer1.1.bn2.bias', 'stage4.0.fuse_layers.3.1.0.0.weight', 'stage3.3.fuse_layers.1.2.1.num_batches_tracked', 'stage4.1.fuse_layers.3.1.1.1.running_mean', 'bn2.running_mean', 'stage3.3.branches.2.1.bn2.running_var', 'stage4.0.branches.0.3.bn1.running_var', 'stage4.1.fuse_layers.2.0.0.1.running_mean', 'stage3.2.branches.0.0.bn2.running_mean', 'stage3.3.branches.0.0.bn2.bias', 'stage4.2.branches.3.1.conv2.weight', 'stage4.0.branches.3.2.bn2.bias', 'stage3.2.branches.2.1.bn2.num_batches_tracked', 'stage2.0.branches.0.1.bn2.running_mean', 'stage4.0.branches.2.0.bn2.bias', 'stage4.1.branches.2.2.bn2.running_mean', 'stage4.2.branches.3.3.bn2.running_mean', 'stage3.3.branches.0.0.bn2.num_batches_tracked', 'stage4.1.fuse_layers.1.0.0.1.weight', 'stage3.1.branches.2.1.bn2.bias', 'stage4.0.branches.2.1.bn2.weight', 'stage4.1.branches.2.0.bn1.bias', 'stage3.0.branches.0.3.conv2.weight', 'stage4.1.branches.3.2.bn2.running_var', 'stage4.2.branches.0.0.bn2.weight', 'stage4.1.branches.0.1.bn2.num_batches_tracked', 'stage4.2.branches.1.0.bn1.bias', 'stage4.2.branches.0.3.bn1.running_mean', 'stage4.0.branches.1.0.bn2.running_var', 'stage4.0.branches.0.2.bn1.running_var', 'stage3.1.branches.0.3.bn2.bias', 'stage3.0.fuse_layers.0.1.1.num_batches_tracked', 'stage3.2.branches.0.2.bn2.running_mean', 'stage3.3.fuse_layers.0.2.1.num_batches_tracked', 'stage3.1.fuse_layers.1.0.0.1.bias', 'stage4.0.fuse_layers.3.0.0.1.running_var', 'stage4.0.branches.3.3.bn1.num_batches_tracked', 'stage3.3.branches.0.3.bn1.weight', 'stage4.0.fuse_layers.0.3.1.num_batches_tracked', 'stage4.1.branches.2.1.bn1.running_var', 'stage3.3.fuse_layers.0.1.1.num_batches_tracked', 'stage4.2.branches.3.3.bn1.running_mean', 'stage4.2.branches.0.0.bn2.bias', 'layer1.2.bn1.weight', 'stage4.1.branches.1.0.bn1.num_batches_tracked', 'stage3.3.branches.0.0.bn1.weight', 'stage4.2.branches.2.1.bn1.bias', 'stage4.0.fuse_layers.2.0.1.1.running_var', 'stage4.0.fuse_layers.2.0.1.0.weight', 'stage4.0.fuse_layers.2.3.1.weight', 'stage4.2.branches.1.0.bn2.num_batches_tracked', 'stage2.0.branches.1.3.bn1.weight', 'stage4.1.branches.0.1.bn1.bias', 'stage3.1.fuse_layers.0.2.1.weight', 'stage3.2.branches.0.3.bn2.running_mean', 'stage4.2.branches.0.0.bn2.running_var', 'stage3.1.branches.0.2.bn1.running_var', 'stage4.2.branches.2.2.bn2.weight', 'stage4.1.branches.3.2.bn1.running_mean', 'stage4.0.branches.1.2.bn2.num_batches_tracked', 'stage3.2.branches.2.2.bn2.running_mean', 'stage4.0.fuse_layers.3.1.1.1.num_batches_tracked', 'stage3.2.fuse_layers.0.2.0.weight', 'stage3.3.branches.2.0.bn2.bias', 'stage4.1.fuse_layers.3.0.0.0.weight', 'stage2.0.branches.1.1.bn1.running_var', 'stage3.3.branches.1.3.bn1.running_mean', 'stage4.0.branches.2.3.bn2.weight', 'stage4.2.branches.1.3.bn1.running_mean', 'stage3.3.fuse_layers.1.0.0.1.num_batches_tracked', 'stage4.0.branches.1.2.bn2.bias', 'stage4.1.fuse_layers.0.1.0.weight', 'stage4.1.branches.2.0.bn2.running_mean', 'stage4.0.fuse_layers.1.0.0.1.weight', 'stage4.0.fuse_layers.2.0.1.1.running_mean', 'stage3.3.branches.2.2.bn1.weight', 'stage4.2.branches.1.2.bn1.running_mean', 'transition1.1.0.1.running_mean', 'stage3.1.branches.0.1.bn1.running_var', 'transition1.0.1.num_batches_tracked', 'stage4.1.branches.2.3.bn1.num_batches_tracked', 'stage3.1.branches.1.2.bn2.bias', 'stage4.1.branches.0.0.bn2.running_var', 'stage3.2.fuse_layers.0.1.1.running_mean', 'stage4.2.branches.3.2.bn1.bias', 'stage4.0.fuse_layers.1.0.0.1.running_var', 'stage4.0.fuse_layers.2.1.0.1.running_var', 'stage4.1.branches.3.0.bn1.weight', 'stage4.0.fuse_layers.2.1.0.0.weight', 'stage3.1.branches.2.2.bn1.weight', 'stage4.2.branches.2.2.conv1.weight', 'transition1.0.1.bias', 'transition2.2.0.1.bias', 'stage3.1.branches.0.1.bn2.num_batches_tracked', 'stage3.2.branches.1.0.bn1.weight', 'stage3.0.branches.2.3.conv2.weight', 'stage4.1.branches.1.3.bn2.num_batches_tracked', 'stage3.0.branches.0.0.bn1.num_batches_tracked', 'transition3.3.0.1.weight', 'stage4.2.branches.0.2.bn1.running_var', 'stage3.1.branches.1.3.bn1.bias', 'stage4.2.branches.2.1.bn2.num_batches_tracked', 'stage3.3.branches.1.3.bn2.weight', 'stage4.0.fuse_layers.3.1.1.1.weight', 'stage3.0.branches.2.0.bn2.bias', 'stage4.2.branches.3.0.bn1.bias', 'stage3.2.branches.0.0.bn1.running_var', 'stage4.2.branches.3.2.conv2.weight', 'stage4.0.branches.0.1.conv2.weight', 'stage3.2.branches.0.1.bn2.running_mean', 'stage3.0.branches.1.3.bn1.bias', 'stage2.0.branches.0.1.bn1.weight', 'stage3.1.branches.2.3.bn1.bias', 'stage3.0.fuse_layers.0.2.1.bias', 'stage2.0.fuse_layers.0.1.1.running_var', 'stage3.2.branches.2.1.bn2.running_mean', 'stage2.0.branches.1.2.conv1.weight', 'stage2.0.branches.1.2.conv2.weight', 'stage4.0.branches.0.3.bn1.num_batches_tracked', 'stage4.1.branches.2.1.bn1.weight', 'stage2.0.branches.0.3.bn2.running_var', 'stage4.2.branches.2.0.bn2.running_var', 'stage3.0.branches.0.1.bn1.weight', 'stage4.0.branches.3.2.conv1.weight', 'stage3.1.branches.2.1.bn2.num_batches_tracked', 'stage4.1.branches.3.0.bn2.num_batches_tracked', 'stage3.1.branches.0.3.bn2.num_batches_tracked', 'stage4.2.branches.1.3.conv2.weight', 'stage3.2.branches.0.3.bn2.running_var', 'stage4.0.fuse_layers.3.0.2.1.bias', 'stage4.2.branches.0.3.bn2.num_batches_tracked', 'stage4.0.fuse_layers.3.0.1.1.running_mean', 'stage2.0.branches.1.3.bn2.running_mean', 'stage4.1.branches.3.2.conv2.weight', 'stage4.2.branches.2.0.bn2.num_batches_tracked', 'stage3.2.branches.2.3.bn1.weight', 'stage3.2.branches.1.3.bn1.num_batches_tracked', 'stage4.2.branches.2.1.bn2.running_var', 'stage3.1.branches.1.1.bn2.num_batches_tracked', 'stage4.1.branches.3.2.bn2.num_batches_tracked', 'stage4.0.fuse_layers.3.0.1.0.weight', 'conv2.weight', 'stage4.1.branches.1.1.bn1.running_mean', 'stage3.0.branches.2.2.bn1.bias', 'stage3.0.branches.1.1.bn1.bias', 'stage4.2.branches.1.2.bn1.bias', 'stage3.0.fuse_layers.0.1.0.weight', 'stage4.0.branches.3.0.bn2.bias', 'stage3.1.fuse_layers.0.1.1.running_var', 'stage3.2.branches.1.2.conv1.weight', 'stage3.2.branches.2.3.bn1.num_batches_tracked', 'stage3.1.branches.0.1.bn1.num_batches_tracked', 'stage4.2.branches.0.0.conv2.weight', 'stage4.2.branches.3.0.bn1.running_var', 'stage4.0.branches.0.1.bn1.running_var', 'stage4.1.branches.2.2.bn2.running_var', 'stage3.2.branches.1.0.conv2.weight', 'stage3.1.branches.0.3.bn1.num_batches_tracked', 'stage4.1.branches.2.2.conv1.weight', 'stage4.1.branches.1.1.bn2.num_batches_tracked', 'stage3.1.branches.1.2.bn2.running_mean', 'stage4.0.branches.2.0.bn2.running_mean', 'stage4.1.branches.2.3.bn2.running_var', 'stage3.3.branches.1.2.bn1.num_batches_tracked', 'stage4.0.branches.0.1.bn1.bias', 'stage3.0.fuse_layers.2.1.0.1.weight', 'stage4.1.fuse_layers.2.0.1.0.weight', 'stage4.1.branches.1.3.conv2.weight', 'stage3.2.branches.2.2.bn1.running_mean', 'stage4.0.branches.1.2.bn2.running_var', 'stage4.1.branches.3.3.bn1.weight', 'stage4.1.fuse_layers.2.1.0.0.weight', 'stage4.1.fuse_layers.3.1.1.1.weight', 'stage4.0.branches.0.0.bn2.num_batches_tracked', 'stage3.2.fuse_layers.0.2.1.bias', 'layer1.0.bn1.num_batches_tracked', 'stage4.1.branches.0.0.bn2.weight', 'stage4.2.branches.2.1.bn2.weight', 'stage4.0.branches.2.2.bn1.running_var', 'stage2.0.branches.1.1.bn2.running_var', 'stage4.0.branches.2.3.bn1.bias', 'stage4.1.branches.2.3.bn1.running_var', 'stage3.2.branches.2.0.bn1.running_mean', 'stage4.0.fuse_layers.0.3.1.running_mean', 'stage3.0.branches.1.0.bn1.running_var', 'stage3.0.branches.2.1.bn2.bias', 'stage4.0.branches.2.3.conv1.weight', 'stage3.0.branches.2.3.bn1.bias', 'stage3.2.branches.1.3.bn1.weight', 'stage3.1.fuse_layers.2.0.0.1.num_batches_tracked', 'stage4.0.branches.2.2.bn1.bias', 'stage3.3.branches.0.3.bn2.bias', 'stage4.2.branches.3.0.bn2.weight', 'stage3.2.branches.0.0.bn2.weight', 'stage3.3.branches.1.1.bn2.bias', 'layer1.0.downsample.1.running_var', 'stage3.2.branches.2.0.bn1.running_var', 'stage4.0.branches.1.0.conv1.weight', 'stage4.2.branches.3.2.bn2.weight', 'stage3.3.branches.0.1.bn1.bias', 'stage2.0.branches.0.3.bn2.running_mean', 'layer1.0.downsample.0.weight', 'stage3.3.branches.2.2.bn1.running_var', 'stage2.0.branches.0.1.conv1.weight', 'stage4.1.branches.1.2.bn2.running_mean', 'stage3.1.fuse_layers.1.0.0.1.num_batches_tracked', 'stage3.3.branches.1.3.conv2.weight', 'stage4.1.fuse_layers.1.0.0.1.num_batches_tracked', 'stage3.2.branches.0.1.bn1.running_var', 'stage3.2.branches.0.1.bn2.weight', 'stage3.2.branches.0.1.bn1.running_mean', 'stage4.1.branches.2.3.bn1.bias', 'stage3.2.branches.2.0.bn2.running_mean', 'stage3.0.branches.1.0.bn2.num_batches_tracked', 'stage3.0.fuse_layers.2.0.0.1.running_var', 'stage3.2.branches.0.2.bn2.num_batches_tracked', 'stage4.1.fuse_layers.2.3.1.num_batches_tracked', 'stage3.0.branches.0.3.bn1.running_mean', 'stage3.0.branches.0.3.bn2.weight', 'transition1.0.0.weight', 'stage3.1.fuse_layers.0.1.1.bias', 'stage4.0.branches.1.1.bn1.running_mean', 'stage3.2.branches.0.3.bn2.weight', 'stage3.0.branches.0.0.bn1.weight', 'stage4.0.branches.0.3.bn1.weight', 'stage4.1.branches.2.0.conv1.weight', 'stage3.3.branches.1.0.bn1.bias', 'stage3.0.branches.2.0.bn2.weight', 'stage3.2.branches.0.0.bn2.bias', 'stage4.2.branches.2.1.bn1.weight', 'stage3.3.branches.1.2.bn1.weight', 'stage3.2.branches.1.0.bn2.weight', 'stage4.0.fuse_layers.3.1.0.1.running_var', 'stage3.3.branches.0.2.bn2.weight', 'stage4.1.branches.3.1.bn1.weight', 'stage3.2.branches.1.0.bn2.bias', 'stage4.0.branches.0.1.bn2.running_var', 'stage4.0.branches.3.3.conv1.weight', 'stage4.2.branches.2.0.bn1.num_batches_tracked', 'stage3.2.fuse_layers.1.2.1.num_batches_tracked', 'stage4.1.branches.0.2.bn2.running_var', 'stage3.2.branches.0.0.conv1.weight', 'stage4.1.fuse_layers.0.1.1.running_var', 'stage3.0.branches.0.2.bn1.bias', 'layer1.1.conv1.weight', 'stage3.2.branches.0.1.bn2.running_var', 'stage3.1.branches.2.2.bn1.running_var', 'stage3.2.fuse_layers.2.0.1.1.bias', 'stage2.0.branches.0.0.conv1.weight', 'stage4.1.branches.0.0.bn1.bias', 'stage4.1.fuse_layers.0.1.1.weight', 'stage3.1.branches.0.1.bn2.bias', 'layer1.1.bn3.bias', 'stage4.1.fuse_layers.1.2.1.num_batches_tracked', 'stage4.1.fuse_layers.2.0.0.1.weight', 'stage3.3.branches.2.0.bn2.running_var', 'stage3.2.branches.2.3.bn1.running_mean', 'stage3.3.branches.1.2.conv1.weight', 'stage4.2.branches.0.2.bn1.num_batches_tracked', 'stage3.2.fuse_layers.2.1.0.1.bias', 'stage3.3.fuse_layers.2.0.0.1.bias', 'stage4.2.branches.1.2.bn2.bias', 'stage3.1.fuse_layers.0.2.1.num_batches_tracked', 'stage3.3.branches.0.0.bn2.running_var', 'stage3.3.branches.1.2.bn2.bias', 'stage3.3.branches.2.0.bn2.weight', 'stage3.2.branches.1.1.bn2.bias', 'stage4.2.branches.0.1.conv2.weight', 'stage3.2.fuse_layers.2.1.0.1.num_batches_tracked', 'stage3.0.fuse_layers.0.1.1.running_mean', 'layer1.1.bn1.weight', 'stage4.0.branches.0.1.bn1.running_mean', 'stage4.0.fuse_layers.1.3.1.bias', 'stage3.1.branches.2.2.bn2.weight', 'stage2.0.branches.0.3.conv1.weight', 'stage4.0.branches.2.3.bn2.bias', 'stage4.0.branches.3.1.bn1.bias', 'stage3.3.fuse_layers.0.1.0.weight', 'stage2.0.branches.1.0.conv2.weight', 'stage3.2.fuse_layers.2.0.0.0.weight', 'stage3.2.branches.0.1.bn2.bias', 'stage3.2.branches.1.1.bn1.running_var', 'stage4.0.branches.2.0.conv1.weight', 'stage3.1.branches.2.0.bn1.num_batches_tracked', 'stage3.0.branches.0.1.bn1.running_mean', 'stage4.1.branches.0.1.bn1.running_mean', 'stage2.0.fuse_layers.0.1.0.weight', 'stage3.3.branches.2.3.conv2.weight', 'stage4.1.fuse_layers.2.0.1.1.bias', 'stage4.1.fuse_layers.2.0.1.1.running_mean', 'layer1.0.conv1.weight', 'stage4.1.fuse_layers.2.3.1.weight', 'stage3.3.branches.0.3.bn2.num_batches_tracked', 'layer1.2.bn2.num_batches_tracked', 'stage3.1.branches.0.0.bn2.running_var', 'stage3.2.branches.2.2.conv1.weight', 'stage4.0.branches.3.2.bn2.weight', 'stage3.1.branches.0.3.bn1.running_var', 'stage4.0.fuse_layers.3.0.2.1.running_mean', 'stage3.2.branches.1.2.bn2.running_mean', 'stage4.1.branches.1.2.bn1.bias', 'stage4.1.branches.0.3.conv1.weight', 'stage4.0.branches.3.1.bn2.running_var', 'stage3.3.branches.0.2.conv2.weight', 'stage4.1.branches.2.3.bn1.weight', 'stage4.1.fuse_layers.2.0.0.0.weight', 'stage2.0.branches.1.3.bn2.weight', 'stage3.1.branches.1.3.bn1.weight', 'stage4.1.branches.0.3.bn2.num_batches_tracked', 'layer1.3.conv2.weight', 'stage4.1.branches.3.3.bn1.num_batches_tracked', 'stage4.2.branches.2.2.bn1.num_batches_tracked', 'stage3.1.branches.2.0.bn1.weight', 'stage3.1.branches.0.2.conv2.weight', 'stage4.2.branches.2.2.bn2.num_batches_tracked', 'stage3.0.branches.2.3.bn2.weight', 'stage4.2.branches.2.2.bn2.running_mean', 'stage4.0.branches.1.0.bn1.num_batches_tracked', 'stage4.2.branches.1.0.bn1.running_mean', 'stage4.1.fuse_layers.3.0.2.1.running_mean', 'stage3.1.branches.2.2.bn2.bias', 'stage4.1.fuse_layers.1.3.1.running_var', 'stage3.3.branches.1.3.bn1.bias', 'stage3.1.branches.1.1.conv2.weight', 'stage3.3.branches.1.0.bn2.num_batches_tracked', 'stage3.3.branches.1.2.bn1.running_var', 'stage3.2.branches.2.1.conv1.weight', 'stage4.2.branches.3.3.conv2.weight', 'stage3.1.fuse_layers.0.2.0.weight', 'stage4.1.fuse_layers.0.1.1.bias', 'stage4.0.fuse_layers.2.3.1.num_batches_tracked', 'stage3.0.branches.2.3.bn1.num_batches_tracked', 'stage3.0.fuse_layers.1.2.1.num_batches_tracked', 'stage2.0.branches.0.1.conv2.weight', 'stage4.1.branches.1.2.bn1.weight', 'stage3.1.branches.0.0.bn2.num_batches_tracked', 'stage3.1.branches.2.1.bn1.running_var', 'stage4.0.branches.1.3.bn1.num_batches_tracked', 'stage3.3.branches.0.1.bn1.num_batches_tracked', 'stage3.3.branches.2.2.conv1.weight', 'stage4.1.branches.1.3.bn1.running_mean', 'stage3.1.branches.2.2.bn1.running_mean', 'stage3.1.fuse_layers.0.2.1.running_var', 'stage3.1.branches.0.2.bn2.num_batches_tracked', 'stage4.1.fuse_layers.3.1.0.1.num_batches_tracked', 'layer1.3.bn3.running_mean', 'stage3.2.fuse_layers.1.0.0.1.num_batches_tracked', 'stage3.3.branches.1.2.bn2.running_mean', 'stage3.1.branches.2.1.conv2.weight', 'stage2.0.branches.0.3.bn1.num_batches_tracked', 'stage3.1.branches.0.2.bn1.weight', 'transition1.1.0.1.running_var', 'stage4.0.branches.1.2.conv2.weight', 'stage4.2.branches.0.2.bn2.weight', 'stage4.2.branches.0.3.bn1.num_batches_tracked', 'stage3.0.branches.0.2.conv1.weight', 'stage4.0.branches.3.3.bn1.running_mean', 'stage3.0.branches.0.3.bn1.bias', 'stage3.3.branches.2.3.bn2.running_var', 'stage3.3.branches.2.1.bn2.bias', 'stage4.0.branches.0.3.bn2.weight', 'stage3.1.branches.0.2.conv1.weight', 'stage4.1.branches.1.2.bn2.bias', 'stage4.2.branches.2.0.conv1.weight', 'bn2.num_batches_tracked', 'stage3.0.branches.1.0.bn2.weight', 'stage4.0.branches.2.2.bn1.num_batches_tracked', 'stage3.0.branches.0.3.bn2.running_var', 'stage4.0.branches.0.2.bn2.num_batches_tracked', 'stage4.2.branches.0.0.bn1.weight', 'stage4.0.branches.1.3.conv1.weight', 'stage4.1.fuse_layers.2.3.1.running_mean', 'stage2.0.branches.1.2.bn2.num_batches_tracked', 'stage4.2.branches.3.2.bn1.running_mean', 'stage3.2.branches.2.2.conv2.weight', 'transition3.3.0.1.num_batches_tracked', 'stage4.2.branches.3.1.bn1.num_batches_tracked', 'stage4.1.branches.0.2.bn2.bias', 'stage4.1.branches.3.1.bn2.bias', 'stage4.0.fuse_layers.3.0.0.1.bias', 'stage3.1.branches.2.0.bn1.bias', 'stage4.0.branches.3.3.bn2.num_batches_tracked', 'stage3.0.branches.0.0.bn2.weight', 'stage3.3.branches.0.0.bn2.weight', 'layer1.2.bn3.running_mean', 'stage3.2.branches.1.2.bn2.num_batches_tracked', 'stage4.0.branches.3.0.bn2.weight', 'stage4.0.branches.0.2.conv1.weight', 'layer1.0.bn2.weight', 'stage3.1.branches.2.3.bn1.running_var', 'stage3.1.branches.0.3.conv1.weight', 'stage4.0.branches.3.1.bn1.running_mean', 'stage3.2.branches.1.1.bn2.num_batches_tracked', 'stage4.0.branches.3.2.bn1.num_batches_tracked', 'stage3.1.branches.2.1.bn1.weight', 'stage3.1.branches.1.1.bn2.bias', 'stage4.1.branches.0.3.bn1.num_batches_tracked', 'stage4.2.branches.2.3.bn1.running_mean', 'stage3.0.branches.2.0.conv1.weight', 'stage4.1.branches.2.3.bn2.bias', 'stage3.0.fuse_layers.2.0.0.1.weight', 'stage3.2.branches.1.0.bn2.running_var', 'stage3.2.fuse_layers.1.0.0.1.bias', 'stage4.0.branches.2.3.bn1.running_mean', 'stage4.1.fuse_layers.1.0.0.1.running_mean', 'stage3.2.fuse_layers.2.0.0.1.running_var', 'stage4.0.fuse_layers.0.1.1.running_var', 'stage3.0.branches.1.0.bn1.num_batches_tracked', 'stage4.1.branches.1.0.conv2.weight', 'stage4.1.branches.3.2.bn2.weight', 'stage3.0.branches.1.2.bn1.bias', 'stage3.1.branches.1.0.bn1.weight', 'stage3.1.fuse_layers.1.2.1.bias', 'stage3.1.branches.1.2.bn2.running_var', 'stage4.2.branches.2.1.conv1.weight', 'stage4.1.branches.2.2.conv2.weight', 'stage3.3.branches.2.2.bn2.bias', 'stage3.1.branches.1.2.bn2.num_batches_tracked', 'stage4.2.branches.1.0.bn2.bias', 'stage3.1.fuse_layers.2.0.1.1.running_var', 'stage3.2.fuse_layers.1.2.0.weight', 'stage4.1.branches.3.3.bn1.bias', 'layer1.1.bn1.running_mean', 'stage4.1.fuse_layers.3.1.1.1.running_var', 'stage2.0.branches.1.0.bn2.running_mean', 'stage3.2.branches.1.2.bn1.running_var', 'stage4.1.fuse_layers.3.0.0.1.bias', 'stage3.1.branches.1.0.bn1.running_mean', 'stage4.0.branches.2.0.bn2.weight', 'layer1.1.bn2.running_var', 'bn1.bias', 'stage3.0.branches.1.2.bn2.weight', 'stage4.0.branches.2.3.conv2.weight', 'stage3.0.fuse_layers.0.2.1.running_mean', 'stage4.1.branches.0.3.bn1.weight', 'stage3.3.branches.0.2.bn2.running_mean', 'stage3.0.fuse_layers.1.2.1.weight', 'stage3.2.branches.0.2.bn1.weight', 'layer1.3.bn3.bias', 'transition3.3.0.0.weight', 'stage3.0.branches.0.2.bn1.running_mean', 'layer1.0.bn3.num_batches_tracked', 'stage3.3.branches.2.1.conv2.weight', 'stage2.0.branches.0.2.bn1.num_batches_tracked', 'stage4.0.branches.3.2.bn2.num_batches_tracked', 'stage4.1.fuse_layers.1.2.1.weight', 'stage4.1.fuse_layers.2.0.0.1.bias', 'stage4.1.branches.1.1.bn1.num_batches_tracked', 'stage4.1.fuse_layers.2.0.1.1.weight', 'stage3.1.branches.2.1.bn2.running_mean', 'stage4.1.branches.2.0.conv2.weight', 'stage3.1.branches.2.0.bn2.weight', 'stage3.1.branches.0.1.bn1.bias', 'stage4.0.fuse_layers.0.2.1.weight', 'stage4.2.branches.2.3.bn2.weight', 'stage3.3.branches.0.3.bn2.running_var', 'layer1.2.bn1.bias', 'layer1.0.downsample.1.weight', 'stage3.2.branches.1.0.bn1.running_mean', 'stage3.0.branches.2.1.bn2.weight', 'stage3.3.branches.1.3.bn2.bias', 'stage4.0.fuse_layers.0.2.1.running_var', 'stage3.1.branches.1.1.bn1.weight', 'stage3.3.branches.1.1.bn1.weight', 'stage4.2.branches.3.0.bn1.weight', 'stage3.1.branches.2.0.bn2.num_batches_tracked', 'stage4.1.branches.0.3.bn1.running_var', 'stage4.0.fuse_layers.3.0.1.1.running_var', 'stage3.2.branches.2.3.bn2.weight', 'stage4.1.branches.1.1.bn2.weight', 'stage4.1.branches.3.3.bn1.running_mean', 'stage3.1.branches.2.3.bn2.bias', 'stage3.1.branches.0.2.bn1.bias', 'stage4.1.branches.2.0.bn1.running_mean', 'stage3.3.branches.1.0.conv2.weight', 'stage4.1.branches.0.1.bn2.bias', 'stage2.0.branches.0.2.bn2.num_batches_tracked', 'stage3.1.branches.0.0.bn1.running_mean', 'stage3.0.branches.1.1.conv1.weight', 'stage3.3.branches.2.2.bn1.running_mean', 'stage4.1.fuse_layers.3.0.2.1.num_batches_tracked', 'stage3.1.fuse_layers.0.1.1.running_mean', 'stage4.0.fuse_layers.3.1.0.1.running_mean', 'stage3.3.branches.0.0.bn1.bias', 'stage3.0.fuse_layers.1.2.1.running_var', 'layer1.3.bn1.running_mean', 'stage4.0.branches.1.2.bn2.running_mean', 'stage4.0.branches.3.2.bn1.running_mean', 'stage4.0.fuse_layers.2.0.0.1.running_mean', 'stage4.0.branches.0.0.bn1.running_mean', 'stage4.0.branches.0.3.bn1.running_mean', 'stage3.1.branches.0.2.bn2.weight', 'stage4.1.fuse_layers.3.1.1.1.num_batches_tracked', 'stage3.2.branches.0.2.bn1.running_mean', 'stage2.0.fuse_layers.1.0.0.0.weight', 'stage3.3.branches.2.3.bn1.running_var', 'stage2.0.branches.1.1.bn1.num_batches_tracked', 'stage4.0.fuse_layers.0.1.0.weight', 'stage4.0.branches.1.3.bn1.bias', 'stage3.3.fuse_layers.1.0.0.0.weight', 'layer1.0.bn1.bias', 'stage3.3.branches.1.2.bn1.running_mean', 'stage3.1.branches.0.0.bn1.running_var', 'stage3.1.branches.0.0.bn1.bias', 'stage4.0.branches.0.2.bn1.running_mean', 'stage4.2.branches.2.1.bn1.running_mean', 'stage3.1.branches.2.3.bn2.weight', 'stage4.0.fuse_layers.2.0.1.1.bias', 'stage3.2.branches.1.1.bn2.weight', 'stage4.2.branches.1.3.bn2.num_batches_tracked', 'stage3.1.branches.1.2.bn1.running_mean', 'transition3.3.0.1.bias', 'stage3.2.branches.1.3.bn1.running_mean', 'stage3.3.branches.2.3.bn1.weight', 'stage4.1.branches.1.1.bn1.weight', 'stage3.1.branches.0.1.bn1.running_mean', 'stage4.0.branches.3.3.bn2.bias', 'stage3.2.branches.2.3.bn2.num_batches_tracked', 'stage3.2.branches.1.0.bn1.running_var', 'stage3.3.branches.0.2.bn1.running_mean', 'stage3.3.branches.1.0.bn1.num_batches_tracked', 'stage4.0.fuse_layers.0.1.1.num_batches_tracked', 'stage3.2.branches.2.2.bn1.running_var', 'stage4.0.branches.2.0.bn1.bias', 'stage3.3.branches.2.3.bn2.running_mean', 'stage4.2.branches.3.3.bn1.bias', 'layer1.3.bn2.running_mean', 'stage4.2.branches.0.1.bn1.running_var', 'stage4.2.branches.3.2.bn1.running_var', 'stage4.0.fuse_layers.3.0.2.1.num_batches_tracked', 'stage2.0.branches.1.3.bn1.bias', 'stage4.2.branches.3.1.bn1.running_var', 'stage4.2.branches.0.1.bn1.num_batches_tracked', 'stage4.0.branches.0.2.bn1.weight', 'stage3.3.branches.1.3.bn2.running_var', 'stage4.0.fuse_layers.0.1.1.running_mean', 'stage2.0.branches.0.0.bn1.running_mean', 'stage4.1.branches.2.1.conv1.weight', 'stage4.2.branches.2.1.conv2.weight', 'stage4.2.branches.3.0.bn2.running_mean', 'stage4.1.fuse_layers.1.2.1.running_var', 'stage4.1.fuse_layers.3.0.1.1.bias', 'stage4.2.branches.2.0.bn2.weight', 'stage3.0.branches.2.3.bn2.num_batches_tracked', 'stage3.2.fuse_layers.2.0.1.1.num_batches_tracked', 'stage3.2.branches.2.0.bn2.weight', 'stage4.1.branches.1.1.bn2.running_var', 'stage3.1.branches.2.2.bn2.running_mean', 'stage2.0.branches.1.1.bn2.running_mean', 'stage4.2.branches.2.3.bn2.running_var', 'stage3.1.branches.1.3.conv1.weight', 'stage3.1.branches.0.1.bn2.running_mean', 'stage4.1.branches.1.2.bn1.running_mean', 'stage3.1.branches.1.1.bn1.running_var', 'stage3.2.branches.2.1.bn1.running_var', 'stage4.0.fuse_layers.2.0.0.1.bias', 'stage4.1.branches.3.0.bn1.running_mean', 'stage4.2.branches.3.0.bn2.bias', 'layer1.2.conv1.weight', 'stage2.0.branches.1.0.bn1.weight', 'stage4.1.branches.3.0.conv1.weight', 'stage4.0.branches.0.0.bn1.num_batches_tracked', 'stage3.3.branches.1.2.bn2.running_var', 'stage3.1.fuse_layers.0.1.1.weight', 'stage4.2.branches.0.0.bn1.running_var', 'stage3.2.branches.2.2.bn1.bias', 'stage4.1.branches.3.2.bn1.running_var', 'stage4.1.branches.2.2.bn2.bias', 'stage3.0.branches.2.0.bn2.running_mean', 'stage3.2.branches.0.0.bn2.running_var', 'stage4.0.fuse_layers.3.1.0.1.weight', 'stage4.2.branches.3.1.bn2.bias', 'stage4.1.fuse_layers.3.0.2.1.weight', 'stage4.0.branches.2.1.conv2.weight', 'stage4.0.branches.2.1.bn1.running_var', 'stage3.3.branches.0.2.conv1.weight', 'stage4.0.fuse_layers.0.2.1.bias', 'stage4.2.branches.3.3.bn2.running_var', 'stage4.0.branches.0.0.bn1.bias', 'stage2.0.branches.0.0.bn1.running_var', 'stage2.0.branches.0.2.conv1.weight', 'stage3.0.fuse_layers.0.1.1.weight', 'stage2.0.branches.0.1.bn2.num_batches_tracked', 'stage4.1.branches.0.1.conv1.weight', 'stage3.3.branches.0.1.bn2.num_batches_tracked', 'transition1.0.1.running_mean', 'stage4.2.branches.0.3.bn1.running_var', 'stage4.2.branches.1.1.bn2.running_mean', 'stage4.1.fuse_layers.3.0.2.1.running_var', 'stage3.2.branches.2.2.bn2.running_var', 'stage3.0.branches.2.2.bn1.weight', 'stage4.0.branches.3.3.bn2.running_mean', 'stage4.1.branches.0.0.bn1.running_mean', 'stage4.1.fuse_layers.3.0.0.1.running_var', 'stage4.2.branches.1.3.conv1.weight', 'stage4.0.branches.2.2.bn2.weight', 'layer1.1.bn3.running_mean', 'stage3.3.fuse_layers.2.1.0.1.weight', 'stage4.0.fuse_layers.1.3.0.weight', 'stage3.2.branches.0.2.bn2.bias', 'stage4.1.fuse_layers.0.2.1.running_mean', 'stage3.1.branches.2.0.bn2.bias', 'stage4.1.fuse_layers.3.1.0.1.weight', 'stage4.1.branches.2.3.conv1.weight', 'layer1.3.bn1.bias', 'stage4.0.fuse_layers.2.0.0.1.weight', 'stage4.2.branches.2.1.bn2.bias', 'stage3.2.branches.0.1.conv1.weight', 'stage3.0.fuse_layers.2.0.1.1.num_batches_tracked', 'stage4.2.branches.1.1.bn2.bias', 'stage4.1.fuse_layers.3.0.2.1.bias', 'stage3.0.fuse_layers.2.0.1.1.bias', 'stage3.1.fuse_layers.1.2.1.num_batches_tracked', 'stage4.0.branches.2.3.bn2.running_mean', 'stage3.3.branches.0.3.bn2.running_mean', 'stage4.0.fuse_layers.0.1.1.bias', 'stage3.3.branches.2.0.conv2.weight', 'stage3.0.branches.1.3.conv2.weight', 'stage4.1.branches.3.2.conv1.weight', 'stage3.2.branches.1.1.bn2.running_mean', 'stage3.1.branches.0.3.bn1.weight', 'stage3.1.branches.2.0.bn2.running_var', 'stage4.1.branches.0.3.bn2.running_mean', 'stage4.2.branches.0.3.bn1.weight', 'stage3.3.branches.1.1.bn2.weight', 'stage3.2.branches.1.0.bn1.num_batches_tracked', 'stage3.0.branches.1.0.conv1.weight', 'stage3.3.branches.1.0.conv1.weight', 'stage3.1.fuse_layers.2.1.0.1.running_var', 'stage3.3.branches.2.1.conv1.weight', 'stage3.1.branches.2.3.conv1.weight', 'stage3.2.branches.1.3.conv1.weight', 'stage4.1.branches.2.1.bn2.bias', 'stage2.0.branches.0.2.bn2.weight', 'stage3.0.branches.1.0.bn2.bias', 'stage3.0.branches.2.3.bn2.running_var', 'stage3.0.branches.1.1.bn2.num_batches_tracked', 'stage4.0.branches.1.2.bn1.weight', 'stage3.0.branches.2.2.bn1.running_mean', 'stage4.0.branches.1.1.conv2.weight', 'stage3.2.fuse_layers.2.0.0.1.num_batches_tracked', 'stage4.0.fuse_layers.3.2.0.0.weight', 'stage3.2.branches.2.3.bn2.running_mean', 'stage4.0.branches.1.0.bn2.bias', 'stage4.1.fuse_layers.1.3.0.weight', 'stage3.3.branches.0.1.bn1.running_mean', 'stage4.2.branches.0.2.conv2.weight', 'stage4.0.branches.2.1.bn2.running_var', 'stage4.1.branches.2.1.bn1.num_batches_tracked', 'stage3.3.branches.1.1.bn1.running_var', 'stage3.1.branches.2.3.bn2.running_mean', 'stage4.2.branches.1.1.conv1.weight', 'stage3.1.fuse_layers.1.0.0.1.running_mean', 'stage4.2.branches.1.1.bn1.num_batches_tracked', 'stage4.1.branches.3.3.bn2.weight', 'stage4.2.branches.0.0.bn1.num_batches_tracked', 'stage4.1.branches.2.1.bn1.bias', 'stage3.1.branches.2.1.bn2.weight', 'stage3.0.branches.0.1.bn2.bias', 'stage3.2.branches.1.2.bn2.weight', 'stage3.2.fuse_layers.1.0.0.1.weight', 'stage4.0.branches.0.3.bn1.bias', 'stage4.1.branches.3.0.bn2.bias', 'stage4.0.branches.1.0.bn1.weight', 'stage4.0.branches.0.2.bn2.running_mean', 'stage3.3.fuse_layers.0.2.1.bias', 'stage3.3.branches.2.1.bn1.weight', 'stage3.0.fuse_layers.2.0.1.0.weight', 'stage4.0.fuse_layers.3.1.0.1.bias', 'stage3.2.branches.0.3.bn2.num_batches_tracked', 'stage4.2.branches.1.1.bn2.weight', 'stage3.1.fuse_layers.1.2.1.running_var', 'stage4.1.fuse_layers.3.1.0.1.running_mean', 'stage4.2.branches.3.1.bn1.bias', 'stage3.1.branches.0.3.conv2.weight', 'stage3.1.branches.0.2.bn1.running_mean', 'stage2.0.branches.0.0.bn2.bias', 'stage4.0.branches.1.3.bn2.num_batches_tracked', 'stage4.1.branches.2.3.bn2.weight', 'stage4.0.branches.0.3.bn2.running_var', 'stage3.1.fuse_layers.2.1.0.1.running_mean', 'layer1.1.bn2.num_batches_tracked', 'stage4.0.branches.2.0.bn1.num_batches_tracked', 'stage4.2.branches.1.1.bn2.num_batches_tracked', 'stage2.0.branches.0.2.bn2.running_mean', 'stage4.2.branches.2.3.bn1.running_var', 'stage3.3.branches.0.2.bn1.weight']\n","Namespace(cfg='configs/QNRF_HR.py', local_rank=0, opts=[], launcher='pytorch', debug=False, cfg_options=None)\n","Config (path: configs/QNRF_HR.py): {'gpus': (0, 1), 'log_dir': 'exp', 'workers': 12, 'print_freq': 30, 'seed': 3035, 'network': {'backbone': 'MocHRBackbone', 'sub_arch': 'hrnet48', 'counter_type': 'withMOE', 'loss_weight': [1.0, 0.5, 0.25, 0.125], 'resolution_num': [0, 1, 2, 3], 'sigma': [4], 'gau_kernel_size': 15, 'baseline_loss': False, 'pretrained_backbone': '../PretrainedModels/QNRF_mae_77.8_mse_138.0.pth', 'head': {'type': 'CountingHead', 'fuse_method': 'cat', 'in_channels': 96, 'stages_channel': [384, 192, 96, 48], 'inter_layer': [64, 32, 16], 'out_channels': 1}}, 'dataset': {'name': 'QNRF', 'root': '../ProcessedData/', 'test_set': 'test.txt', 'train_set': 'train.txt', 'num_classes': 1, 'den_factor': 100, 'extra_train_set': None}, 'optimizer': {'NAME': 'adamw', 'BASE_LR': 1e-05, 'BETAS': (0.9, 0.999), 'WEIGHT_DECAY': 0.0001, 'EPS': 1e-08, 'MOMENTUM': 0.9, 'AMSGRAD': False, 'NESTEROV': True}, 'lr_config': {'NAME': 'cosine', 'WARMUP_METHOD': 'linear', 'DECAY_EPOCHS': 250, 'DECAY_RATE': 0.1, 'WARMUP_EPOCHS': 10, 'WARMUP_LR': 5e-07, 'MIN_LR': 1e-07}, 'total_epochs': 210, 'log_config': {'interval': 50, 'hooks': [{'type': 'TextLoggerHook'}]}, 'train': {'counter': 'normal', 'image_size': (768, 768), 'route_size': (256, 256), 'base_size': 2048, 'batch_size_per_gpu': 8, 'shuffle': True, 'begin_epoch': 0, 'end_epoch': 1000, 'extra_epoch': 0, 'extra_lr': 0, 'resume_path': None, 'flip': True, 'multi_scale': True, 'scale_factor': (0.5, 2.0), 'val_span': [-1000, -800, -600, -600, -400, -400, -200, -200], 'downsamplerate': 1, 'ignore_label': 255}, 'test': {'image_size': (1024, 2048), 'base_size': 2048, 'batch_size_per_gpu': 1, 'patch_batch_size': 16, 'flip_test': False, 'multi_scale': False, 'model_file': './exp/QNRF/MocHRBackbone_hrnet48/QNRF_mocHR_small_2022-09-23-20-07/Ep_617_mae_78.82519394195009_mse_136.08208312773016.pth'}, 'CUDNN': {'BENCHMARK': True, 'DETERMINISTIC': False, 'ENABLED': True}}\n","| name                               | #elements or shape   |\n","|:-----------------------------------|:---------------------|\n","| model                              | 64.6M                |\n","|  backbone                          |  63.6M               |\n","|   backbone.conv1                   |   1.7K               |\n","|    backbone.conv1.weight           |    (64, 3, 3, 3)     |\n","|   backbone.bn1                     |   0.1K               |\n","|    backbone.bn1.weight             |    (64,)             |\n","|    backbone.bn1.bias               |    (64,)             |\n","|   backbone.conv2                   |   36.9K              |\n","|    backbone.conv2.weight           |    (64, 64, 3, 3)    |\n","|   backbone.bn2                     |   0.1K               |\n","|    backbone.bn2.weight             |    (64,)             |\n","|    backbone.bn2.bias               |    (64,)             |\n","|   backbone.layer1                  |   0.3M               |\n","|    backbone.layer1.0               |    75.0K             |\n","|    backbone.layer1.1               |    70.4K             |\n","|    backbone.layer1.2               |    70.4K             |\n","|    backbone.layer1.3               |    70.4K             |\n","|   backbone.transition1             |   0.3M               |\n","|    backbone.transition1.0          |    0.1M              |\n","|    backbone.transition1.1          |    0.2M              |\n","|   backbone.stage2                  |   0.9M               |\n","|    backbone.stage2.0               |    0.9M              |\n","|   backbone.transition2             |   0.2M               |\n","|    backbone.transition2.2          |    0.2M              |\n","|   backbone.stage3                  |   15.3M              |\n","|    backbone.stage3.0               |    3.8M              |\n","|    backbone.stage3.1               |    3.8M              |\n","|    backbone.stage3.2               |    3.8M              |\n","|    backbone.stage3.3               |    3.8M              |\n","|   backbone.transition3             |   0.7M               |\n","|    backbone.transition3.3          |    0.7M              |\n","|   backbone.stage4                  |   45.9M              |\n","|    backbone.stage4.0               |    15.9M             |\n","|    backbone.stage4.1               |    15.9M             |\n","|    backbone.stage4.2               |    14.1M             |\n","|  gaussian                          |  0.2K                |\n","|   gaussian.gaussian                |   0.2K               |\n","|    gaussian.gaussian.gkernel       |    0.2K              |\n","|  multi_counters                    |  78.6K               |\n","|   multi_counters.decoder           |   78.6K              |\n","|    multi_counters.decoder.1        |    55.3K             |\n","|    multi_counters.decoder.2        |    0.1K              |\n","|    multi_counters.decoder.4        |    18.4K             |\n","|    multi_counters.decoder.5        |    64                |\n","|    multi_counters.decoder.8        |    4.6K              |\n","|    multi_counters.decoder.9        |    32                |\n","|    multi_counters.decoder.11       |    16                |\n","|  counter_copy                      |  78.6K               |\n","|   counter_copy.decoder             |   78.6K              |\n","|    counter_copy.decoder.1          |    55.3K             |\n","|    counter_copy.decoder.2          |    0.1K              |\n","|    counter_copy.decoder.4          |    18.4K             |\n","|    counter_copy.decoder.5          |    64                |\n","|    counter_copy.decoder.8          |    4.6K              |\n","|    counter_copy.decoder.9          |    32                |\n","|    counter_copy.decoder.11         |    16                |\n","|  upsample_module                   |  0.9M                |\n","|   upsample_module.multi_outputs    |   0.9M               |\n","|    upsample_module.multi_outputs.0 |    37.1K             |\n","|    upsample_module.multi_outputs.1 |    0.3M              |\n","|    upsample_module.multi_outputs.2 |    0.3M              |\n","|    upsample_module.multi_outputs.3 |    0.3M              |\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([1, 48, 192, 256]), torch.Size([1, 96, 96, 128]), torch.Size([1, 192, 48, 64]), torch.Size([1, 384, 24, 32])]\n","check multi outputs: torch.Size([1, 1, 96, 128]) last stage: torch.Size([1, 96, 24, 32])\n","current_stage: torch.Size([1, 48, 48, 64])\n","last_stage:  torch.Size([1, 96, 48, 64])\n","i-1\n","output size:  torch.Size([1, 1, 192, 256])\n","current_stage: torch.Size([1, 48, 96, 128])\n","last_stage:  torch.Size([1, 96, 96, 128])\n","i-1\n","output size:  torch.Size([1, 1, 384, 512])\n","out branch last_stage:  torch.Size([1, 48, 192, 256])\n","out branch current_stage: torch.Size([1, 48, 192, 256])\n","i\n","output size:  torch.Size([1, 1, 768, 1024])\n","out list 확인 4\n","0 out list torch.Size([1, 1, 768, 1024])\n","Unsupported operator aten::add_ encountered 426 time(s)\n","Unsupported operator aten::add encountered 52 time(s)\n","Unsupported operator aten::softmax encountered 2 time(s)\n","Unsupported operator aten::mul encountered 4 time(s)\n","The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n","backbone.stage4.2.relu, gaussian, gaussian.gaussian, gaussian.gaussian.gkernel, mse_loss, upsample_module.multi_outputs.3.modulation_layer_small, upsample_module.multi_outputs.3.modulation_layer_small.0, upsample_module.multi_outputs.3.modulation_layer_small.1, upsample_module.multi_outputs.3.modulation_layer_small.2, upsample_module.multi_outputs.3.modulation_layer_small.3, upsample_module.multi_outputs.3.modulation_layer_small.4, upsample_module.multi_outputs.3.modulation_layer_small.5, upsample_module.multi_outputs.3.soft_mask, upsample_module.multi_outputs.3.soft_mask.cls.0, upsample_module.multi_outputs.3.soft_mask.cls.0.0, upsample_module.multi_outputs.3.soft_mask.cls.0.1, upsample_module.multi_outputs.3.soft_mask.cls.0.2, upsample_module.multi_outputs.3.soft_mask.cls.1, upsample_module.multi_outputs.3.soft_mask.cls.1.0, upsample_module.multi_outputs.3.soft_mask.cls.1.1, upsample_module.multi_outputs.3.soft_mask.cls.1.2, upsample_module.multi_outputs.3.soft_mask.cls.2, upsample_module.multi_outputs.3.soft_mask.cls.2.0, upsample_module.multi_outputs.3.soft_mask.cls.2.1\n","(defaultdict(<class 'float'>, {'conv': 280.731205632, 'batch_norm': 2.27917824, 'upsample_bilinear2d': 0.417988608, 'upsample_nearest2d': 0.006223872}), Counter({'aten::add_': 426, 'aten::add': 52, 'aten::mul': 4, 'aten::softmax': 2}))\n","num of train loader 150\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","/content/drive/MyDrive/STEERER/STEERER/./lib/models/build_counter.py:181: UserWarning: `nn.functional.upsample_nearest` is deprecated. Use `nn.functional.interpolate` instead.\n","  loss_mask = F.upsample_nearest(mask_add,   size=(out_list[i].size()[2:]))\n","/content/drive/MyDrive/STEERER/STEERER/./lib/models/build_counter.py:189: UserWarning: `nn.functional.upsample_nearest` is deprecated. Use `nn.functional.interpolate` instead.\n","  label_patch += (label_list[0] * F.upsample_nearest(mask_gt[:,i].unsqueeze(1),\n","Epoch: [0/1000] Iter:[0/150], Time: 9.73, lr: 0.0500, Loss: 0.1593, pre: 6753.8, gt: 1174.0,acc:0.00, accx8:0.00,  accx16:0.13,accx32:0.69,acc1:0.00\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Epoch: [0/1000] Iter:[30/150], Time: 1.21, lr: 0.0690, Loss: 0.1350, pre: 3642.2, gt: 2660.0,acc:0.36, accx8:0.20,  accx16:0.36,accx32:0.76,acc1:0.00\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Epoch: [0/1000] Iter:[60/150], Time: 1.51, lr: 0.0880, Loss: 0.1096, pre: 2524.6, gt: 829.0,acc:0.47, accx8:0.35,  accx16:0.38,accx32:0.73,acc1:0.00\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Number of feature maps from backbone: 4\n","Feature map sizes: [torch.Size([8, 48, 192, 192]), torch.Size([8, 96, 96, 96]), torch.Size([8, 192, 48, 48]), torch.Size([8, 384, 24, 24])]\n","check multi outputs: torch.Size([8, 1, 96, 96]) last stage: torch.Size([8, 96, 24, 24])\n","current_stage: torch.Size([8, 48, 48, 48])\n","last_stage:  torch.Size([8, 96, 48, 48])\n","i-1\n","output size:  torch.Size([8, 1, 192, 192])\n","current_stage: torch.Size([8, 48, 96, 96])\n","last_stage:  torch.Size([8, 96, 96, 96])\n","i-1\n","output size:  torch.Size([8, 1, 384, 384])\n","out branch last_stage:  torch.Size([8, 48, 192, 192])\n","out branch current_stage: torch.Size([8, 48, 192, 192])\n","i\n","output size:  torch.Size([8, 1, 768, 768])\n","out list 확인 4\n","0 out list torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 768, 768]), gt size: torch.Size([8, 1, 768, 768])\n","check-----\n","pre size: torch.Size([8, 1, 384, 384]), gt size: torch.Size([8, 1, 384, 384])\n","check-----\n","pre size: torch.Size([8, 1, 192, 192]), gt size: torch.Size([8, 1, 192, 192])\n","check-----\n","pre size: torch.Size([8, 1, 96, 96]), gt size: torch.Size([8, 1, 96, 96])\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1448, in _next_data\n","    idx, data = self._get_data()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1402, in _get_data\n","    success, data = self._try_get_data()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1243, in _try_get_data\n","    data = self._data_queue.get(timeout=timeout)\n","  File \"/usr/lib/python3.10/queue.py\", line 180, in get\n","    self.not_empty.wait(remaining)\n","  File \"/usr/lib/python3.10/threading.py\", line 324, in wait\n","    gotit = waiter.acquire(True, timeout)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/STEERER/STEERER/tools/train_cc.py\", line 353, in <module>\n","    main()\n","  File \"/content/drive/MyDrive/STEERER/STEERER/tools/train_cc.py\", line 283, in main\n","    train(config, epoch, config.train.end_epoch,\n","  File \"/content/drive/MyDrive/STEERER/STEERER/./lib/core/cc_function.py\", line 62, in train\n","    for i_iter, batch in enumerate(trainloader):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 697, in __next__\n","    with torch.autograd.profiler.record_function(self._profile_name):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/profiler.py\", line 750, in __exit__\n","    torch.ops.profiler._record_function_exit._RecordFunction(record)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 939, in __call__\n","    def __call__(self, /, *args, **kwargs):\n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"code","source":["! python tools/train_cc.py --cfg=configs/QNRF_final.py --launcher=\"pytorch\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aSCxlKAxzTWq","executionInfo":{"status":"ok","timestamp":1733836060123,"user_tz":-540,"elapsed":3914373,"user":{"displayName":"박수연 (GREAT)","userId":"09302565313834136190"}},"outputId":"aad8bca3-d0fe-41b2-e2e2-ddb78abb7dfb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  192.33, Best_MAE:  135.0480 MSE:  283.1742,Best_MSE:  224.0210\n","Epoch: [130/800] Iter:[0/150], Time: 4.36, lr: 9.3631, Loss: 0.0244, pre: 1505.0, gt: 2082.0,acc:0.80, accx8:0.87,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [130/800] Iter:[20/150], Time: 0.77, lr: 9.3618, Loss: 0.0287, pre: 1570.9, gt: 1928.0,acc:0.80, accx8:0.87,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [130/800] Iter:[40/150], Time: 0.68, lr: 9.3606, Loss: 0.0282, pre: 1857.8, gt: 1959.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [130/800] Iter:[60/150], Time: 0.64, lr: 9.3593, Loss: 0.0306, pre: 2375.1, gt: 3142.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [130/800] Iter:[80/150], Time: 0.63, lr: 9.3580, Loss: 0.0309, pre: 1746.2, gt: 2177.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [130/800] Iter:[100/150], Time: 0.62, lr: 9.3567, Loss: 0.0309, pre: 1923.5, gt: 2780.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [130/800] Iter:[120/150], Time: 0.61, lr: 9.3554, Loss: 0.0300, pre: 462.3, gt: 422.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [130/800] Iter:[140/150], Time: 0.61, lr: 9.3541, Loss: 0.0305, pre: 1641.7, gt: 1625.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [131/800] Iter:[0/150], Time: 1.93, lr: 9.3535, Loss: 0.0179, pre: 711.3, gt: 702.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [131/800] Iter:[20/150], Time: 0.65, lr: 9.3522, Loss: 0.0281, pre: 2246.9, gt: 2009.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [131/800] Iter:[40/150], Time: 0.62, lr: 9.3509, Loss: 0.0301, pre: 2350.5, gt: 2823.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [131/800] Iter:[60/150], Time: 0.61, lr: 9.3496, Loss: 0.0290, pre: 1651.5, gt: 1964.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [131/800] Iter:[80/150], Time: 0.60, lr: 9.3483, Loss: 0.0286, pre: 332.8, gt: 255.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [131/800] Iter:[100/150], Time: 0.60, lr: 9.3471, Loss: 0.0302, pre: 1141.3, gt: 1035.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [131/800] Iter:[120/150], Time: 0.59, lr: 9.3458, Loss: 0.0300, pre: 1635.6, gt: 1847.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [131/800] Iter:[140/150], Time: 0.59, lr: 9.3445, Loss: 0.0299, pre: 971.9, gt: 1014.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [132/800] Iter:[0/150], Time: 2.21, lr: 9.3438, Loss: 0.0356, pre: 3513.5, gt: 3401.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [132/800] Iter:[20/150], Time: 0.66, lr: 9.3425, Loss: 0.0307, pre: 3843.5, gt: 4613.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [132/800] Iter:[40/150], Time: 0.62, lr: 9.3412, Loss: 0.0293, pre: 1770.3, gt: 1880.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [132/800] Iter:[60/150], Time: 0.61, lr: 9.3399, Loss: 0.0286, pre: 906.5, gt: 878.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [132/800] Iter:[80/150], Time: 0.60, lr: 9.3386, Loss: 0.0285, pre: 2141.3, gt: 2418.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [132/800] Iter:[100/150], Time: 0.60, lr: 9.3373, Loss: 0.0288, pre: 3541.4, gt: 3614.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [132/800] Iter:[120/150], Time: 0.60, lr: 9.3360, Loss: 0.0286, pre: 547.9, gt: 575.0,acc:0.82, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [132/800] Iter:[140/150], Time: 0.59, lr: 9.3347, Loss: 0.0289, pre: 2028.2, gt: 2859.0,acc:0.82, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [133/800] Iter:[0/150], Time: 1.86, lr: 9.3341, Loss: 0.0249, pre: 1463.4, gt: 1511.0,acc:0.82, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [133/800] Iter:[20/150], Time: 0.64, lr: 9.3328, Loss: 0.0278, pre: 1411.7, gt: 1784.0,acc:0.82, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [133/800] Iter:[40/150], Time: 0.61, lr: 9.3315, Loss: 0.0290, pre: 850.2, gt: 845.0,acc:0.82, accx8:0.89,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [133/800] Iter:[60/150], Time: 0.60, lr: 9.3301, Loss: 0.0286, pre: 985.6, gt: 934.0,acc:0.82, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [133/800] Iter:[80/150], Time: 0.60, lr: 9.3288, Loss: 0.0295, pre: 990.8, gt: 1165.0,acc:0.82, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [133/800] Iter:[100/150], Time: 0.60, lr: 9.3275, Loss: 0.0295, pre: 895.8, gt: 1020.0,acc:0.82, accx8:0.89,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [133/800] Iter:[120/150], Time: 0.59, lr: 9.3262, Loss: 0.0294, pre: 1368.5, gt: 1408.0,acc:0.82, accx8:0.89,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [133/800] Iter:[140/150], Time: 0.59, lr: 9.3249, Loss: 0.0302, pre: 745.8, gt: 783.0,acc:0.82, accx8:0.89,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [134/800] Iter:[0/150], Time: 2.10, lr: 9.3242, Loss: 0.0254, pre: 1142.5, gt: 1223.0,acc:0.82, accx8:0.89,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [134/800] Iter:[20/150], Time: 0.66, lr: 9.3229, Loss: 0.0343, pre: 1527.7, gt: 2082.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [134/800] Iter:[40/150], Time: 0.62, lr: 9.3216, Loss: 0.0306, pre: 1462.7, gt: 1969.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [134/800] Iter:[60/150], Time: 0.61, lr: 9.3203, Loss: 0.0310, pre: 2482.7, gt: 1828.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [134/800] Iter:[80/150], Time: 0.60, lr: 9.3190, Loss: 0.0307, pre: 2668.9, gt: 2044.0,acc:0.82, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [134/800] Iter:[100/150], Time: 0.60, lr: 9.3177, Loss: 0.0297, pre: 173.4, gt: 126.0,acc:0.83, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [134/800] Iter:[120/150], Time: 0.60, lr: 9.3163, Loss: 0.0317, pre: 1623.5, gt: 1796.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [134/800] Iter:[140/150], Time: 0.59, lr: 9.3150, Loss: 0.0316, pre: 731.4, gt: 734.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.89,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  195.92, Best_MAE:  135.0480 MSE:  397.2988,Best_MSE:  224.0210\n","Epoch: [135/800] Iter:[0/150], Time: 4.15, lr: 9.3144, Loss: 0.0262, pre: 1149.4, gt: 1525.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [135/800] Iter:[20/150], Time: 0.76, lr: 9.3130, Loss: 0.0334, pre: 1380.8, gt: 819.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [135/800] Iter:[40/150], Time: 0.67, lr: 9.3117, Loss: 0.0353, pre: 1336.5, gt: 1437.0,acc:0.82, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [135/800] Iter:[60/150], Time: 0.64, lr: 9.3104, Loss: 0.0342, pre: 605.0, gt: 1095.0,acc:0.82, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [135/800] Iter:[80/150], Time: 0.63, lr: 9.3091, Loss: 0.0354, pre: 1708.4, gt: 1713.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [135/800] Iter:[100/150], Time: 0.62, lr: 9.3077, Loss: 0.0354, pre: 1952.3, gt: 1998.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [135/800] Iter:[120/150], Time: 0.61, lr: 9.3064, Loss: 0.0369, pre: 2641.2, gt: 2114.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [135/800] Iter:[140/150], Time: 0.61, lr: 9.3051, Loss: 0.0364, pre: 765.0, gt: 686.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [136/800] Iter:[0/150], Time: 1.87, lr: 9.3044, Loss: 0.0399, pre: 3824.2, gt: 3567.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [136/800] Iter:[20/150], Time: 0.65, lr: 9.3031, Loss: 0.0370, pre: 2430.7, gt: 1830.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [136/800] Iter:[40/150], Time: 0.61, lr: 9.3017, Loss: 0.0319, pre: 955.1, gt: 1096.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [136/800] Iter:[60/150], Time: 0.60, lr: 9.3004, Loss: 0.0322, pre: 1684.2, gt: 1633.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [136/800] Iter:[80/150], Time: 0.60, lr: 9.2991, Loss: 0.0317, pre: 935.5, gt: 785.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [136/800] Iter:[100/150], Time: 0.60, lr: 9.2977, Loss: 0.0320, pre: 2585.1, gt: 2330.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [136/800] Iter:[120/150], Time: 0.59, lr: 9.2964, Loss: 0.0324, pre: 742.3, gt: 356.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [136/800] Iter:[140/150], Time: 0.59, lr: 9.2951, Loss: 0.0318, pre: 468.3, gt: 578.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [137/800] Iter:[0/150], Time: 1.94, lr: 9.2944, Loss: 0.0252, pre: 1197.6, gt: 603.0,acc:0.80, accx8:0.87,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [137/800] Iter:[20/150], Time: 0.65, lr: 9.2930, Loss: 0.0349, pre: 579.1, gt: 521.0,acc:0.80, accx8:0.87,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [137/800] Iter:[40/150], Time: 0.62, lr: 9.2917, Loss: 0.0334, pre: 2025.7, gt: 2176.0,acc:0.80, accx8:0.87,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [137/800] Iter:[60/150], Time: 0.61, lr: 9.2904, Loss: 0.0321, pre: 3376.0, gt: 4178.0,acc:0.80, accx8:0.87,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [137/800] Iter:[80/150], Time: 0.60, lr: 9.2890, Loss: 0.0320, pre: 1892.5, gt: 1782.0,acc:0.80, accx8:0.87,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [137/800] Iter:[100/150], Time: 0.60, lr: 9.2877, Loss: 0.0317, pre: 495.2, gt: 616.0,acc:0.80, accx8:0.87,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [137/800] Iter:[120/150], Time: 0.59, lr: 9.2863, Loss: 0.0321, pre: 1536.0, gt: 1052.0,acc:0.80, accx8:0.87,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [137/800] Iter:[140/150], Time: 0.59, lr: 9.2850, Loss: 0.0309, pre: 1683.5, gt: 2194.0,acc:0.80, accx8:0.87,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [138/800] Iter:[0/150], Time: 1.90, lr: 9.2843, Loss: 0.0370, pre: 1719.7, gt: 2080.0,acc:0.80, accx8:0.87,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [138/800] Iter:[20/150], Time: 0.65, lr: 9.2830, Loss: 0.0349, pre: 508.7, gt: 727.0,acc:0.80, accx8:0.87,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [138/800] Iter:[40/150], Time: 0.62, lr: 9.2816, Loss: 0.0373, pre: 2981.8, gt: 1933.0,acc:0.79, accx8:0.87,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [138/800] Iter:[60/150], Time: 0.60, lr: 9.2803, Loss: 0.0348, pre: 1817.6, gt: 1445.0,acc:0.79, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [138/800] Iter:[80/150], Time: 0.60, lr: 9.2789, Loss: 0.0341, pre: 1700.2, gt: 1826.0,acc:0.79, accx8:0.87,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [138/800] Iter:[100/150], Time: 0.60, lr: 9.2775, Loss: 0.0356, pre: 808.1, gt: 666.0,acc:0.79, accx8:0.87,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [138/800] Iter:[120/150], Time: 0.59, lr: 9.2762, Loss: 0.0346, pre: 674.1, gt: 354.0,acc:0.79, accx8:0.87,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [138/800] Iter:[140/150], Time: 0.59, lr: 9.2748, Loss: 0.0334, pre: 3216.7, gt: 2813.0,acc:0.79, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [139/800] Iter:[0/150], Time: 1.92, lr: 9.2742, Loss: 0.0376, pre: 1466.3, gt: 1455.0,acc:0.79, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [139/800] Iter:[20/150], Time: 0.65, lr: 9.2728, Loss: 0.0373, pre: 1796.4, gt: 2946.0,acc:0.79, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [139/800] Iter:[40/150], Time: 0.62, lr: 9.2714, Loss: 0.0352, pre: 2481.9, gt: 2404.0,acc:0.79, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [139/800] Iter:[60/150], Time: 0.61, lr: 9.2701, Loss: 0.0328, pre: 1114.2, gt: 1824.0,acc:0.79, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [139/800] Iter:[80/150], Time: 0.60, lr: 9.2687, Loss: 0.0323, pre: 778.6, gt: 784.0,acc:0.79, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [139/800] Iter:[100/150], Time: 0.60, lr: 9.2674, Loss: 0.0322, pre: 554.5, gt: 500.0,acc:0.78, accx8:0.86,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [139/800] Iter:[120/150], Time: 0.59, lr: 9.2660, Loss: 0.0333, pre: 2872.5, gt: 3173.0,acc:0.78, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [139/800] Iter:[140/150], Time: 0.59, lr: 9.2646, Loss: 0.0339, pre: 633.6, gt: 646.0,acc:0.78, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.013, MAE:  174.77, Best_MAE:  135.0480 MSE:  425.9542,Best_MSE:  224.0210\n","Epoch: [140/800] Iter:[0/150], Time: 4.65, lr: 9.2639, Loss: 0.0214, pre: 1383.9, gt: 1121.0,acc:0.78, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [140/800] Iter:[20/150], Time: 0.78, lr: 9.2626, Loss: 0.0233, pre: 840.5, gt: 1184.0,acc:0.79, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [140/800] Iter:[40/150], Time: 0.68, lr: 9.2612, Loss: 0.0254, pre: 2886.7, gt: 2811.0,acc:0.79, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [140/800] Iter:[60/150], Time: 0.65, lr: 9.2598, Loss: 0.0263, pre: 1353.9, gt: 1025.0,acc:0.79, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [140/800] Iter:[80/150], Time: 0.63, lr: 9.2585, Loss: 0.0284, pre: 1527.2, gt: 1999.0,acc:0.78, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [140/800] Iter:[100/150], Time: 0.62, lr: 9.2571, Loss: 0.0297, pre: 1120.7, gt: 920.0,acc:0.79, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [140/800] Iter:[120/150], Time: 0.62, lr: 9.2557, Loss: 0.0295, pre: 621.5, gt: 559.0,acc:0.78, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [140/800] Iter:[140/150], Time: 0.61, lr: 9.2543, Loss: 0.0296, pre: 684.5, gt: 751.0,acc:0.78, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [141/800] Iter:[0/150], Time: 2.22, lr: 9.2537, Loss: 0.0248, pre: 1710.1, gt: 1818.0,acc:0.79, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [141/800] Iter:[20/150], Time: 0.66, lr: 9.2523, Loss: 0.0298, pre: 2940.2, gt: 2240.0,acc:0.79, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [141/800] Iter:[40/150], Time: 0.62, lr: 9.2509, Loss: 0.0313, pre: 682.5, gt: 644.0,acc:0.79, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [141/800] Iter:[60/150], Time: 0.61, lr: 9.2495, Loss: 0.0317, pre: 1520.4, gt: 2368.0,acc:0.79, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [141/800] Iter:[80/150], Time: 0.60, lr: 9.2481, Loss: 0.0310, pre: 4150.4, gt: 4209.0,acc:0.79, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [141/800] Iter:[100/150], Time: 0.60, lr: 9.2468, Loss: 0.0298, pre: 1403.1, gt: 1606.0,acc:0.79, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [141/800] Iter:[120/150], Time: 0.60, lr: 9.2454, Loss: 0.0293, pre: 1564.3, gt: 1587.0,acc:0.79, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [141/800] Iter:[140/150], Time: 0.59, lr: 9.2440, Loss: 0.0289, pre: 1357.7, gt: 1382.0,acc:0.79, accx8:0.87,  accx16:0.88,accx32:0.89,acc1:0.00\n","Epoch: [142/800] Iter:[0/150], Time: 2.07, lr: 9.2433, Loss: 0.0621, pre: 3648.6, gt: 3566.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [142/800] Iter:[20/150], Time: 0.65, lr: 9.2419, Loss: 0.0335, pre: 2191.5, gt: 2874.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [142/800] Iter:[40/150], Time: 0.62, lr: 9.2405, Loss: 0.0309, pre: 531.7, gt: 625.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [142/800] Iter:[60/150], Time: 0.61, lr: 9.2392, Loss: 0.0302, pre: 1395.3, gt: 1119.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [142/800] Iter:[80/150], Time: 0.60, lr: 9.2378, Loss: 0.0296, pre: 3325.6, gt: 4335.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [142/800] Iter:[100/150], Time: 0.60, lr: 9.2364, Loss: 0.0294, pre: 1028.2, gt: 1701.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [142/800] Iter:[120/150], Time: 0.59, lr: 9.2350, Loss: 0.0303, pre: 4938.7, gt: 8555.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [142/800] Iter:[140/150], Time: 0.59, lr: 9.2336, Loss: 0.0320, pre: 687.6, gt: 305.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [143/800] Iter:[0/150], Time: 1.84, lr: 9.2329, Loss: 0.0296, pre: 1762.7, gt: 2424.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [143/800] Iter:[20/150], Time: 0.64, lr: 9.2315, Loss: 0.0354, pre: 4745.1, gt: 5458.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [143/800] Iter:[40/150], Time: 0.61, lr: 9.2301, Loss: 0.0326, pre: 2028.3, gt: 2028.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [143/800] Iter:[60/150], Time: 0.60, lr: 9.2287, Loss: 0.0322, pre: 1710.2, gt: 2974.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [143/800] Iter:[80/150], Time: 0.60, lr: 9.2273, Loss: 0.0333, pre: 1281.9, gt: 1106.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [143/800] Iter:[100/150], Time: 0.59, lr: 9.2259, Loss: 0.0330, pre: 2696.1, gt: 1966.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [143/800] Iter:[120/150], Time: 0.59, lr: 9.2245, Loss: 0.0326, pre: 1178.4, gt: 1192.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [143/800] Iter:[140/150], Time: 0.59, lr: 9.2231, Loss: 0.0311, pre: 1643.4, gt: 1842.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [144/800] Iter:[0/150], Time: 1.59, lr: 9.2224, Loss: 0.0229, pre: 858.7, gt: 999.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [144/800] Iter:[20/150], Time: 0.64, lr: 9.2210, Loss: 0.0294, pre: 889.6, gt: 814.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [144/800] Iter:[40/150], Time: 0.61, lr: 9.2196, Loss: 0.0263, pre: 1347.7, gt: 1193.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [144/800] Iter:[60/150], Time: 0.60, lr: 9.2182, Loss: 0.0278, pre: 725.9, gt: 1008.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [144/800] Iter:[80/150], Time: 0.60, lr: 9.2168, Loss: 0.0296, pre: 1879.4, gt: 2695.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [144/800] Iter:[100/150], Time: 0.59, lr: 9.2154, Loss: 0.0310, pre: 2959.2, gt: 1966.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [144/800] Iter:[120/150], Time: 0.59, lr: 9.2140, Loss: 0.0302, pre: 1008.3, gt: 1081.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [144/800] Iter:[140/150], Time: 0.59, lr: 9.2126, Loss: 0.0305, pre: 1703.9, gt: 2174.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  171.10, Best_MAE:  135.0480 MSE:  291.2301,Best_MSE:  224.0210\n","Epoch: [145/800] Iter:[0/150], Time: 4.23, lr: 9.2119, Loss: 0.0180, pre: 642.4, gt: 586.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [145/800] Iter:[20/150], Time: 0.76, lr: 9.2105, Loss: 0.0315, pre: 1305.6, gt: 1192.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [145/800] Iter:[40/150], Time: 0.67, lr: 9.2091, Loss: 0.0283, pre: 775.1, gt: 625.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [145/800] Iter:[60/150], Time: 0.64, lr: 9.2076, Loss: 0.0314, pre: 3373.4, gt: 3822.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [145/800] Iter:[80/150], Time: 0.63, lr: 9.2062, Loss: 0.0314, pre: 393.2, gt: 508.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [145/800] Iter:[100/150], Time: 0.62, lr: 9.2048, Loss: 0.0305, pre: 922.0, gt: 1014.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [145/800] Iter:[120/150], Time: 0.61, lr: 9.2034, Loss: 0.0303, pre: 2495.0, gt: 2874.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [145/800] Iter:[140/150], Time: 0.61, lr: 9.2020, Loss: 0.0311, pre: 1466.2, gt: 1443.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [146/800] Iter:[0/150], Time: 1.82, lr: 9.2013, Loss: 0.0314, pre: 1787.8, gt: 2237.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [146/800] Iter:[20/150], Time: 0.64, lr: 9.1998, Loss: 0.0295, pre: 1858.2, gt: 1479.0,acc:0.81, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [146/800] Iter:[40/150], Time: 0.61, lr: 9.1984, Loss: 0.0302, pre: 1000.1, gt: 790.0,acc:0.81, accx8:0.89,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [146/800] Iter:[60/150], Time: 0.60, lr: 9.1970, Loss: 0.0296, pre: 1573.1, gt: 1773.0,acc:0.82, accx8:0.89,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [146/800] Iter:[80/150], Time: 0.60, lr: 9.1956, Loss: 0.0303, pre: 1577.4, gt: 1636.0,acc:0.82, accx8:0.89,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [146/800] Iter:[100/150], Time: 0.60, lr: 9.1942, Loss: 0.0309, pre: 1218.1, gt: 1154.0,acc:0.81, accx8:0.89,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [146/800] Iter:[120/150], Time: 0.59, lr: 9.1927, Loss: 0.0313, pre: 593.2, gt: 666.0,acc:0.81, accx8:0.89,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [146/800] Iter:[140/150], Time: 0.59, lr: 9.1913, Loss: 0.0314, pre: 1852.8, gt: 1828.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.89,acc1:0.00\n","Epoch: [147/800] Iter:[0/150], Time: 2.36, lr: 9.1906, Loss: 0.0387, pre: 4335.7, gt: 3993.0,acc:0.81, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [147/800] Iter:[20/150], Time: 0.67, lr: 9.1892, Loss: 0.0345, pre: 2855.7, gt: 1896.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [147/800] Iter:[40/150], Time: 0.63, lr: 9.1877, Loss: 0.0308, pre: 2565.6, gt: 2137.0,acc:0.81, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [147/800] Iter:[60/150], Time: 0.61, lr: 9.1863, Loss: 0.0334, pre: 2681.4, gt: 3788.0,acc:0.81, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [147/800] Iter:[80/150], Time: 0.60, lr: 9.1849, Loss: 0.0337, pre: 506.1, gt: 606.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [147/800] Iter:[100/150], Time: 0.60, lr: 9.1834, Loss: 0.0324, pre: 1033.1, gt: 1247.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [147/800] Iter:[120/150], Time: 0.60, lr: 9.1820, Loss: 0.0324, pre: 1954.2, gt: 1332.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [147/800] Iter:[140/150], Time: 0.60, lr: 9.1806, Loss: 0.0323, pre: 1422.5, gt: 2083.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [148/800] Iter:[0/150], Time: 2.02, lr: 9.1799, Loss: 0.0315, pre: 2059.2, gt: 1018.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [148/800] Iter:[20/150], Time: 0.65, lr: 9.1784, Loss: 0.0275, pre: 740.5, gt: 625.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [148/800] Iter:[40/150], Time: 0.62, lr: 9.1770, Loss: 0.0301, pre: 1002.0, gt: 736.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [148/800] Iter:[60/150], Time: 0.61, lr: 9.1755, Loss: 0.0294, pre: 1134.0, gt: 904.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [148/800] Iter:[80/150], Time: 0.60, lr: 9.1741, Loss: 0.0306, pre: 823.0, gt: 1097.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [148/800] Iter:[100/150], Time: 0.60, lr: 9.1727, Loss: 0.0314, pre: 1117.6, gt: 796.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [148/800] Iter:[120/150], Time: 0.60, lr: 9.1712, Loss: 0.0321, pre: 909.2, gt: 1569.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [148/800] Iter:[140/150], Time: 0.59, lr: 9.1698, Loss: 0.0322, pre: 862.9, gt: 1048.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [149/800] Iter:[0/150], Time: 1.80, lr: 9.1691, Loss: 0.0252, pre: 1159.7, gt: 1092.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [149/800] Iter:[20/150], Time: 0.64, lr: 9.1676, Loss: 0.0315, pre: 1926.0, gt: 2214.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [149/800] Iter:[40/150], Time: 0.61, lr: 9.1662, Loss: 0.0316, pre: 672.1, gt: 459.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [149/800] Iter:[60/150], Time: 0.60, lr: 9.1647, Loss: 0.0335, pre: 1677.0, gt: 1575.0,acc:0.80, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [149/800] Iter:[80/150], Time: 0.60, lr: 9.1633, Loss: 0.0333, pre: 1783.4, gt: 1775.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [149/800] Iter:[100/150], Time: 0.60, lr: 9.1618, Loss: 0.0325, pre: 1954.1, gt: 2442.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [149/800] Iter:[120/150], Time: 0.59, lr: 9.1604, Loss: 0.0310, pre: 1190.2, gt: 1316.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [149/800] Iter:[140/150], Time: 0.59, lr: 9.1589, Loss: 0.0304, pre: 974.0, gt: 952.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  140.77, Best_MAE:  135.0480 MSE:  236.3972,Best_MSE:  224.0210\n","Epoch: [150/800] Iter:[0/150], Time: 4.33, lr: 9.1582, Loss: 0.0222, pre: 1014.7, gt: 1028.0,acc:0.81, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [150/800] Iter:[20/150], Time: 0.76, lr: 9.1567, Loss: 0.0272, pre: 1164.8, gt: 855.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [150/800] Iter:[40/150], Time: 0.68, lr: 9.1553, Loss: 0.0276, pre: 482.4, gt: 468.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [150/800] Iter:[60/150], Time: 0.65, lr: 9.1538, Loss: 0.0281, pre: 2802.7, gt: 2761.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [150/800] Iter:[80/150], Time: 0.63, lr: 9.1524, Loss: 0.0267, pre: 132.3, gt: 170.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [150/800] Iter:[100/150], Time: 0.62, lr: 9.1509, Loss: 0.0275, pre: 1353.5, gt: 1346.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [150/800] Iter:[120/150], Time: 0.61, lr: 9.1495, Loss: 0.0272, pre: 441.0, gt: 421.0,acc:0.81, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [150/800] Iter:[140/150], Time: 0.61, lr: 9.1480, Loss: 0.0287, pre: 1187.3, gt: 2086.0,acc:0.81, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [151/800] Iter:[0/150], Time: 1.77, lr: 9.1473, Loss: 0.0279, pre: 1400.7, gt: 1291.0,acc:0.81, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [151/800] Iter:[20/150], Time: 0.64, lr: 9.1458, Loss: 0.0269, pre: 649.2, gt: 1152.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [151/800] Iter:[40/150], Time: 0.61, lr: 9.1443, Loss: 0.0285, pre: 1842.6, gt: 1684.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [151/800] Iter:[60/150], Time: 0.60, lr: 9.1429, Loss: 0.0296, pre: 1620.3, gt: 1214.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [151/800] Iter:[80/150], Time: 0.60, lr: 9.1414, Loss: 0.0293, pre: 2010.7, gt: 2916.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [151/800] Iter:[100/150], Time: 0.60, lr: 9.1399, Loss: 0.0297, pre: 1982.3, gt: 1873.0,acc:0.81, accx8:0.88,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [151/800] Iter:[120/150], Time: 0.59, lr: 9.1385, Loss: 0.0306, pre: 1211.4, gt: 1262.0,acc:0.81, accx8:0.88,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [151/800] Iter:[140/150], Time: 0.59, lr: 9.1370, Loss: 0.0306, pre: 2378.4, gt: 2520.0,acc:0.81, accx8:0.88,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [152/800] Iter:[0/150], Time: 1.90, lr: 9.1363, Loss: 0.0097, pre: 356.0, gt: 412.0,acc:0.81, accx8:0.88,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [152/800] Iter:[20/150], Time: 0.65, lr: 9.1348, Loss: 0.0362, pre: 1148.9, gt: 1132.0,acc:0.81, accx8:0.88,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [152/800] Iter:[40/150], Time: 0.62, lr: 9.1333, Loss: 0.0317, pre: 3940.8, gt: 4339.0,acc:0.81, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [152/800] Iter:[60/150], Time: 0.60, lr: 9.1319, Loss: 0.0311, pre: 721.8, gt: 834.0,acc:0.81, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [152/800] Iter:[80/150], Time: 0.60, lr: 9.1304, Loss: 0.0313, pre: 6685.8, gt: 6094.0,acc:0.81, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [152/800] Iter:[100/150], Time: 0.60, lr: 9.1289, Loss: 0.0307, pre: 2363.2, gt: 2254.0,acc:0.81, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [152/800] Iter:[120/150], Time: 0.59, lr: 9.1274, Loss: 0.0302, pre: 1829.5, gt: 1715.0,acc:0.81, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [152/800] Iter:[140/150], Time: 0.59, lr: 9.1259, Loss: 0.0298, pre: 1607.5, gt: 1474.0,acc:0.81, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [153/800] Iter:[0/150], Time: 2.11, lr: 9.1252, Loss: 0.0346, pre: 2084.2, gt: 2222.0,acc:0.81, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [153/800] Iter:[20/150], Time: 0.66, lr: 9.1237, Loss: 0.0311, pre: 643.2, gt: 774.0,acc:0.82, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [153/800] Iter:[40/150], Time: 0.62, lr: 9.1223, Loss: 0.0288, pre: 1569.6, gt: 1185.0,acc:0.82, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [153/800] Iter:[60/150], Time: 0.61, lr: 9.1208, Loss: 0.0273, pre: 5016.3, gt: 4970.0,acc:0.82, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [153/800] Iter:[80/150], Time: 0.60, lr: 9.1193, Loss: 0.0298, pre: 1152.4, gt: 1378.0,acc:0.82, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [153/800] Iter:[100/150], Time: 0.60, lr: 9.1178, Loss: 0.0291, pre: 805.2, gt: 766.0,acc:0.82, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [153/800] Iter:[120/150], Time: 0.60, lr: 9.1163, Loss: 0.0299, pre: 936.4, gt: 891.0,acc:0.82, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [153/800] Iter:[140/150], Time: 0.59, lr: 9.1148, Loss: 0.0303, pre: 1592.3, gt: 2401.0,acc:0.82, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [154/800] Iter:[0/150], Time: 2.10, lr: 9.1141, Loss: 0.0929, pre: 3042.6, gt: 2395.0,acc:0.82, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [154/800] Iter:[20/150], Time: 0.66, lr: 9.1126, Loss: 0.0308, pre: 901.4, gt: 1044.0,acc:0.82, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [154/800] Iter:[40/150], Time: 0.62, lr: 9.1111, Loss: 0.0304, pre: 316.9, gt: 519.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [154/800] Iter:[60/150], Time: 0.61, lr: 9.1096, Loss: 0.0288, pre: 1542.5, gt: 1405.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [154/800] Iter:[80/150], Time: 0.60, lr: 9.1081, Loss: 0.0285, pre: 487.5, gt: 550.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [154/800] Iter:[100/150], Time: 0.60, lr: 9.1066, Loss: 0.0310, pre: 3798.8, gt: 4240.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [154/800] Iter:[120/150], Time: 0.60, lr: 9.1051, Loss: 0.0305, pre: 3642.1, gt: 3263.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [154/800] Iter:[140/150], Time: 0.59, lr: 9.1037, Loss: 0.0300, pre: 1078.2, gt: 1398.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.014, MAE:  262.40, Best_MAE:  135.0480 MSE:  584.5491,Best_MSE:  224.0210\n","Epoch: [155/800] Iter:[0/150], Time: 4.13, lr: 9.1029, Loss: 0.0332, pre: 1444.9, gt: 1141.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [155/800] Iter:[20/150], Time: 0.75, lr: 9.1014, Loss: 0.0342, pre: 1616.0, gt: 1815.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [155/800] Iter:[40/150], Time: 0.67, lr: 9.0999, Loss: 0.0308, pre: 1414.0, gt: 1488.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [155/800] Iter:[60/150], Time: 0.64, lr: 9.0984, Loss: 0.0308, pre: 2065.9, gt: 1898.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [155/800] Iter:[80/150], Time: 0.63, lr: 9.0969, Loss: 0.0302, pre: 217.3, gt: 286.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [155/800] Iter:[100/150], Time: 0.62, lr: 9.0954, Loss: 0.0309, pre: 666.3, gt: 525.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [155/800] Iter:[120/150], Time: 0.61, lr: 9.0939, Loss: 0.0308, pre: 2044.6, gt: 2438.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [155/800] Iter:[140/150], Time: 0.61, lr: 9.0924, Loss: 0.0303, pre: 1595.0, gt: 1778.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [156/800] Iter:[0/150], Time: 1.95, lr: 9.0917, Loss: 0.0189, pre: 1397.5, gt: 1558.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [156/800] Iter:[20/150], Time: 0.65, lr: 9.0902, Loss: 0.0272, pre: 1059.4, gt: 1137.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [156/800] Iter:[40/150], Time: 0.62, lr: 9.0886, Loss: 0.0268, pre: 2944.6, gt: 2275.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [156/800] Iter:[60/150], Time: 0.61, lr: 9.0871, Loss: 0.0286, pre: 1746.4, gt: 1412.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [156/800] Iter:[80/150], Time: 0.60, lr: 9.0856, Loss: 0.0304, pre: 1973.1, gt: 2027.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [156/800] Iter:[100/150], Time: 0.60, lr: 9.0841, Loss: 0.0299, pre: 251.6, gt: 212.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [156/800] Iter:[120/150], Time: 0.60, lr: 9.0826, Loss: 0.0309, pre: 1271.8, gt: 1232.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [156/800] Iter:[140/150], Time: 0.59, lr: 9.0811, Loss: 0.0305, pre: 642.8, gt: 484.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [157/800] Iter:[0/150], Time: 1.80, lr: 9.0803, Loss: 0.0183, pre: 1217.7, gt: 1074.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [157/800] Iter:[20/150], Time: 0.64, lr: 9.0788, Loss: 0.0275, pre: 804.3, gt: 893.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [157/800] Iter:[40/150], Time: 0.61, lr: 9.0773, Loss: 0.0279, pre: 791.6, gt: 751.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [157/800] Iter:[60/150], Time: 0.60, lr: 9.0758, Loss: 0.0305, pre: 1200.1, gt: 2022.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [157/800] Iter:[80/150], Time: 0.60, lr: 9.0743, Loss: 0.0301, pre: 2463.1, gt: 3097.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [157/800] Iter:[100/150], Time: 0.59, lr: 9.0728, Loss: 0.0297, pre: 779.2, gt: 791.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [157/800] Iter:[120/150], Time: 0.59, lr: 9.0713, Loss: 0.0295, pre: 575.7, gt: 656.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [157/800] Iter:[140/150], Time: 0.59, lr: 9.0697, Loss: 0.0297, pre: 2506.0, gt: 3171.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [158/800] Iter:[0/150], Time: 1.83, lr: 9.0690, Loss: 0.0276, pre: 1792.0, gt: 1597.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [158/800] Iter:[20/150], Time: 0.64, lr: 9.0675, Loss: 0.0298, pre: 2189.6, gt: 1719.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [158/800] Iter:[40/150], Time: 0.61, lr: 9.0659, Loss: 0.0286, pre: 1840.1, gt: 1473.0,acc:0.84, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [158/800] Iter:[60/150], Time: 0.60, lr: 9.0644, Loss: 0.0280, pre: 2864.5, gt: 3732.0,acc:0.84, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [158/800] Iter:[80/150], Time: 0.60, lr: 9.0629, Loss: 0.0286, pre: 626.4, gt: 525.0,acc:0.84, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [158/800] Iter:[100/150], Time: 0.59, lr: 9.0614, Loss: 0.0293, pre: 756.1, gt: 1068.0,acc:0.84, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [158/800] Iter:[120/150], Time: 0.59, lr: 9.0598, Loss: 0.0294, pre: 2654.7, gt: 3499.0,acc:0.84, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [158/800] Iter:[140/150], Time: 0.59, lr: 9.0583, Loss: 0.0298, pre: 945.2, gt: 1153.0,acc:0.84, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [159/800] Iter:[0/150], Time: 1.85, lr: 9.0575, Loss: 0.0374, pre: 1518.8, gt: 1528.0,acc:0.84, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [159/800] Iter:[20/150], Time: 0.65, lr: 9.0560, Loss: 0.0393, pre: 1317.3, gt: 1858.0,acc:0.83, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [159/800] Iter:[40/150], Time: 0.62, lr: 9.0545, Loss: 0.0347, pre: 1280.8, gt: 906.0,acc:0.83, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [159/800] Iter:[60/150], Time: 0.61, lr: 9.0529, Loss: 0.0348, pre: 2632.2, gt: 2331.0,acc:0.83, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [159/800] Iter:[80/150], Time: 0.60, lr: 9.0514, Loss: 0.0329, pre: 787.0, gt: 616.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [159/800] Iter:[100/150], Time: 0.60, lr: 9.0499, Loss: 0.0316, pre: 1030.9, gt: 826.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [159/800] Iter:[120/150], Time: 0.59, lr: 9.0483, Loss: 0.0310, pre: 605.1, gt: 612.0,acc:0.83, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [159/800] Iter:[140/150], Time: 0.59, lr: 9.0468, Loss: 0.0311, pre: 3146.6, gt: 3643.0,acc:0.83, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  154.22, Best_MAE:  135.0480 MSE:  235.4059,Best_MSE:  224.0210\n","Epoch: [160/800] Iter:[0/150], Time: 4.30, lr: 9.0460, Loss: 0.0210, pre: 1156.3, gt: 824.0,acc:0.83, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [160/800] Iter:[20/150], Time: 0.76, lr: 9.0445, Loss: 0.0304, pre: 778.6, gt: 1194.0,acc:0.83, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [160/800] Iter:[40/150], Time: 0.67, lr: 9.0430, Loss: 0.0298, pre: 1331.2, gt: 1523.0,acc:0.83, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [160/800] Iter:[60/150], Time: 0.64, lr: 9.0414, Loss: 0.0299, pre: 1419.1, gt: 924.0,acc:0.83, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [160/800] Iter:[80/150], Time: 0.63, lr: 9.0399, Loss: 0.0299, pre: 549.9, gt: 379.0,acc:0.82, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [160/800] Iter:[100/150], Time: 0.62, lr: 9.0383, Loss: 0.0300, pre: 1180.4, gt: 1190.0,acc:0.83, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [160/800] Iter:[120/150], Time: 0.61, lr: 9.0368, Loss: 0.0299, pre: 742.6, gt: 562.0,acc:0.83, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [160/800] Iter:[140/150], Time: 0.61, lr: 9.0353, Loss: 0.0302, pre: 3578.8, gt: 3896.0,acc:0.83, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [161/800] Iter:[0/150], Time: 1.88, lr: 9.0345, Loss: 0.0237, pre: 1167.8, gt: 1330.0,acc:0.83, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [161/800] Iter:[20/150], Time: 0.65, lr: 9.0329, Loss: 0.0330, pre: 4312.3, gt: 5882.0,acc:0.83, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [161/800] Iter:[40/150], Time: 0.62, lr: 9.0314, Loss: 0.0316, pre: 653.8, gt: 685.0,acc:0.83, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [161/800] Iter:[60/150], Time: 0.61, lr: 9.0298, Loss: 0.0298, pre: 3267.1, gt: 4087.0,acc:0.83, accx8:0.90,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [161/800] Iter:[80/150], Time: 0.60, lr: 9.0283, Loss: 0.0306, pre: 1848.3, gt: 2025.0,acc:0.83, accx8:0.90,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [161/800] Iter:[100/150], Time: 0.60, lr: 9.0267, Loss: 0.0313, pre: 436.3, gt: 515.0,acc:0.83, accx8:0.90,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [161/800] Iter:[120/150], Time: 0.59, lr: 9.0252, Loss: 0.0311, pre: 1939.0, gt: 2042.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [161/800] Iter:[140/150], Time: 0.59, lr: 9.0236, Loss: 0.0306, pre: 1432.6, gt: 1393.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [162/800] Iter:[0/150], Time: 1.85, lr: 9.0229, Loss: 0.0128, pre: 528.5, gt: 511.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [162/800] Iter:[20/150], Time: 0.64, lr: 9.0213, Loss: 0.0396, pre: 1119.0, gt: 1103.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [162/800] Iter:[40/150], Time: 0.61, lr: 9.0197, Loss: 0.0337, pre: 1292.7, gt: 1004.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [162/800] Iter:[60/150], Time: 0.60, lr: 9.0182, Loss: 0.0333, pre: 581.1, gt: 800.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [162/800] Iter:[80/150], Time: 0.60, lr: 9.0166, Loss: 0.0320, pre: 1175.9, gt: 979.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [162/800] Iter:[100/150], Time: 0.59, lr: 9.0151, Loss: 0.0307, pre: 914.1, gt: 1108.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [162/800] Iter:[120/150], Time: 0.59, lr: 9.0135, Loss: 0.0313, pre: 1047.3, gt: 1117.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [162/800] Iter:[140/150], Time: 0.59, lr: 9.0120, Loss: 0.0314, pre: 2791.6, gt: 3148.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [163/800] Iter:[0/150], Time: 1.97, lr: 9.0112, Loss: 0.0332, pre: 2134.4, gt: 2529.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [163/800] Iter:[20/150], Time: 0.65, lr: 9.0096, Loss: 0.0322, pre: 886.7, gt: 681.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [163/800] Iter:[40/150], Time: 0.62, lr: 9.0080, Loss: 0.0308, pre: 2194.8, gt: 2210.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [163/800] Iter:[60/150], Time: 0.61, lr: 9.0065, Loss: 0.0292, pre: 385.6, gt: 452.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [163/800] Iter:[80/150], Time: 0.60, lr: 9.0049, Loss: 0.0314, pre: 984.8, gt: 685.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [163/800] Iter:[100/150], Time: 0.60, lr: 9.0033, Loss: 0.0311, pre: 1442.5, gt: 1992.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [163/800] Iter:[120/150], Time: 0.60, lr: 9.0018, Loss: 0.0315, pre: 4049.4, gt: 4534.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [163/800] Iter:[140/150], Time: 0.59, lr: 9.0002, Loss: 0.0322, pre: 3218.8, gt: 3400.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [164/800] Iter:[0/150], Time: 1.94, lr: 8.9994, Loss: 0.0492, pre: 2958.8, gt: 2913.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [164/800] Iter:[20/150], Time: 0.65, lr: 8.9979, Loss: 0.0299, pre: 4175.2, gt: 4107.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [164/800] Iter:[40/150], Time: 0.62, lr: 8.9963, Loss: 0.0280, pre: 434.5, gt: 430.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [164/800] Iter:[60/150], Time: 0.60, lr: 8.9947, Loss: 0.0307, pre: 6838.5, gt: 9674.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [164/800] Iter:[80/150], Time: 0.60, lr: 8.9931, Loss: 0.0294, pre: 2090.5, gt: 2047.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [164/800] Iter:[100/150], Time: 0.60, lr: 8.9916, Loss: 0.0288, pre: 2719.7, gt: 2967.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [164/800] Iter:[120/150], Time: 0.59, lr: 8.9900, Loss: 0.0293, pre: 3192.6, gt: 3557.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [164/800] Iter:[140/150], Time: 0.59, lr: 8.9884, Loss: 0.0293, pre: 1451.8, gt: 1498.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  143.97, Best_MAE:  135.0480 MSE:  232.1988,Best_MSE:  224.0210\n","Epoch: [165/800] Iter:[0/150], Time: 4.55, lr: 8.9876, Loss: 0.0160, pre: 603.7, gt: 610.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [165/800] Iter:[20/150], Time: 0.77, lr: 8.9860, Loss: 0.0283, pre: 2041.2, gt: 2726.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [165/800] Iter:[40/150], Time: 0.68, lr: 8.9845, Loss: 0.0284, pre: 1273.4, gt: 952.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [165/800] Iter:[60/150], Time: 0.65, lr: 8.9829, Loss: 0.0298, pre: 1733.2, gt: 1580.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [165/800] Iter:[80/150], Time: 0.63, lr: 8.9813, Loss: 0.0300, pre: 2088.4, gt: 2296.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [165/800] Iter:[100/150], Time: 0.62, lr: 8.9797, Loss: 0.0299, pre: 375.4, gt: 348.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [165/800] Iter:[120/150], Time: 0.62, lr: 8.9781, Loss: 0.0308, pre: 948.6, gt: 1657.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [165/800] Iter:[140/150], Time: 0.61, lr: 8.9765, Loss: 0.0308, pre: 1258.4, gt: 1128.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [166/800] Iter:[0/150], Time: 1.80, lr: 8.9757, Loss: 0.0173, pre: 955.2, gt: 800.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [166/800] Iter:[20/150], Time: 0.64, lr: 8.9742, Loss: 0.0307, pre: 816.7, gt: 625.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [166/800] Iter:[40/150], Time: 0.61, lr: 8.9726, Loss: 0.0307, pre: 578.8, gt: 681.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [166/800] Iter:[60/150], Time: 0.60, lr: 8.9710, Loss: 0.0308, pre: 867.6, gt: 932.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [166/800] Iter:[80/150], Time: 0.60, lr: 8.9694, Loss: 0.0291, pre: 272.8, gt: 232.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [166/800] Iter:[100/150], Time: 0.59, lr: 8.9678, Loss: 0.0292, pre: 744.5, gt: 849.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [166/800] Iter:[120/150], Time: 0.59, lr: 8.9662, Loss: 0.0303, pre: 2485.3, gt: 1508.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [166/800] Iter:[140/150], Time: 0.59, lr: 8.9646, Loss: 0.0298, pre: 265.3, gt: 315.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [167/800] Iter:[0/150], Time: 2.24, lr: 8.9638, Loss: 0.0242, pre: 707.7, gt: 774.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [167/800] Iter:[20/150], Time: 0.66, lr: 8.9622, Loss: 0.0267, pre: 2530.1, gt: 2899.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [167/800] Iter:[40/150], Time: 0.62, lr: 8.9606, Loss: 0.0277, pre: 1256.0, gt: 891.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [167/800] Iter:[60/150], Time: 0.61, lr: 8.9590, Loss: 0.0329, pre: 4644.8, gt: 3249.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [167/800] Iter:[80/150], Time: 0.60, lr: 8.9574, Loss: 0.0324, pre: 588.2, gt: 883.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [167/800] Iter:[100/150], Time: 0.60, lr: 8.9558, Loss: 0.0317, pre: 2812.6, gt: 3128.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [167/800] Iter:[120/150], Time: 0.60, lr: 8.9542, Loss: 0.0316, pre: 1787.0, gt: 2073.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [167/800] Iter:[140/150], Time: 0.59, lr: 8.9526, Loss: 0.0318, pre: 512.5, gt: 560.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [168/800] Iter:[0/150], Time: 2.32, lr: 8.9518, Loss: 0.0640, pre: 4120.9, gt: 6354.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [168/800] Iter:[20/150], Time: 0.67, lr: 8.9502, Loss: 0.0337, pre: 934.6, gt: 1018.0,acc:0.82, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [168/800] Iter:[40/150], Time: 0.63, lr: 8.9486, Loss: 0.0321, pre: 1338.3, gt: 1215.0,acc:0.82, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [168/800] Iter:[60/150], Time: 0.61, lr: 8.9470, Loss: 0.0313, pre: 1520.2, gt: 1436.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [168/800] Iter:[80/150], Time: 0.61, lr: 8.9454, Loss: 0.0307, pre: 4196.4, gt: 4189.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [168/800] Iter:[100/150], Time: 0.60, lr: 8.9438, Loss: 0.0296, pre: 785.0, gt: 713.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [168/800] Iter:[120/150], Time: 0.60, lr: 8.9422, Loss: 0.0288, pre: 972.1, gt: 1169.0,acc:0.83, accx8:0.89,  accx16:0.89,accx32:0.90,acc1:0.00\n","Epoch: [168/800] Iter:[140/150], Time: 0.60, lr: 8.9406, Loss: 0.0287, pre: 2185.4, gt: 3283.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [169/800] Iter:[0/150], Time: 2.07, lr: 8.9398, Loss: 0.0242, pre: 876.8, gt: 892.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [169/800] Iter:[20/150], Time: 0.66, lr: 8.9382, Loss: 0.0259, pre: 1097.8, gt: 1005.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [169/800] Iter:[40/150], Time: 0.62, lr: 8.9365, Loss: 0.0267, pre: 874.2, gt: 1025.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [169/800] Iter:[60/150], Time: 0.61, lr: 8.9349, Loss: 0.0272, pre: 2602.5, gt: 2824.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [169/800] Iter:[80/150], Time: 0.60, lr: 8.9333, Loss: 0.0276, pre: 4535.1, gt: 6190.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [169/800] Iter:[100/150], Time: 0.60, lr: 8.9317, Loss: 0.0288, pre: 1590.8, gt: 2422.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [169/800] Iter:[120/150], Time: 0.60, lr: 8.9301, Loss: 0.0290, pre: 2661.1, gt: 1823.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.90,acc1:0.00\n","Epoch: [169/800] Iter:[140/150], Time: 0.59, lr: 8.9285, Loss: 0.0295, pre: 1148.8, gt: 1459.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  242.11, Best_MAE:  135.0480 MSE:  436.6356,Best_MSE:  224.0210\n","Epoch: [170/800] Iter:[0/150], Time: 3.85, lr: 8.9277, Loss: 0.0479, pre: 2447.9, gt: 2414.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [170/800] Iter:[20/150], Time: 0.74, lr: 8.9260, Loss: 0.0308, pre: 1039.5, gt: 2046.0,acc:0.83, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [170/800] Iter:[40/150], Time: 0.66, lr: 8.9244, Loss: 0.0292, pre: 1002.2, gt: 1036.0,acc:0.84, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [170/800] Iter:[60/150], Time: 0.64, lr: 8.9228, Loss: 0.0294, pre: 519.2, gt: 351.0,acc:0.84, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [170/800] Iter:[80/150], Time: 0.62, lr: 8.9212, Loss: 0.0285, pre: 798.7, gt: 1348.0,acc:0.84, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [170/800] Iter:[100/150], Time: 0.62, lr: 8.9195, Loss: 0.0290, pre: 2409.7, gt: 2324.0,acc:0.84, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [170/800] Iter:[120/150], Time: 0.61, lr: 8.9179, Loss: 0.0288, pre: 986.7, gt: 846.0,acc:0.84, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [170/800] Iter:[140/150], Time: 0.61, lr: 8.9163, Loss: 0.0287, pre: 2327.0, gt: 2747.0,acc:0.84, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [171/800] Iter:[0/150], Time: 1.78, lr: 8.9155, Loss: 0.0275, pre: 1738.2, gt: 1670.0,acc:0.84, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [171/800] Iter:[20/150], Time: 0.64, lr: 8.9139, Loss: 0.0309, pre: 1502.4, gt: 2024.0,acc:0.84, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [171/800] Iter:[40/150], Time: 0.61, lr: 8.9122, Loss: 0.0310, pre: 315.3, gt: 359.0,acc:0.84, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [171/800] Iter:[60/150], Time: 0.60, lr: 8.9106, Loss: 0.0322, pre: 1417.9, gt: 1245.0,acc:0.84, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [171/800] Iter:[80/150], Time: 0.60, lr: 8.9090, Loss: 0.0314, pre: 462.0, gt: 595.0,acc:0.84, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [171/800] Iter:[100/150], Time: 0.59, lr: 8.9073, Loss: 0.0309, pre: 2306.0, gt: 3392.0,acc:0.84, accx8:0.89,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [171/800] Iter:[120/150], Time: 0.59, lr: 8.9057, Loss: 0.0308, pre: 2354.7, gt: 2326.0,acc:0.84, accx8:0.90,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [171/800] Iter:[140/150], Time: 0.59, lr: 8.9041, Loss: 0.0314, pre: 660.3, gt: 189.0,acc:0.85, accx8:0.90,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [172/800] Iter:[0/150], Time: 2.21, lr: 8.9032, Loss: 0.0285, pre: 2058.7, gt: 2023.0,acc:0.85, accx8:0.90,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [172/800] Iter:[20/150], Time: 0.66, lr: 8.9016, Loss: 0.0371, pre: 1271.4, gt: 1260.0,acc:0.85, accx8:0.90,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [172/800] Iter:[40/150], Time: 0.62, lr: 8.9000, Loss: 0.0334, pre: 1326.1, gt: 1510.0,acc:0.85, accx8:0.90,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [172/800] Iter:[60/150], Time: 0.61, lr: 8.8983, Loss: 0.0314, pre: 1435.7, gt: 817.0,acc:0.84, accx8:0.90,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [172/800] Iter:[80/150], Time: 0.60, lr: 8.8967, Loss: 0.0303, pre: 991.0, gt: 1190.0,acc:0.84, accx8:0.90,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [172/800] Iter:[100/150], Time: 0.60, lr: 8.8951, Loss: 0.0296, pre: 1547.5, gt: 1264.0,acc:0.84, accx8:0.90,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [172/800] Iter:[120/150], Time: 0.60, lr: 8.8934, Loss: 0.0294, pre: 5470.3, gt: 7335.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [172/800] Iter:[140/150], Time: 0.59, lr: 8.8918, Loss: 0.0303, pre: 2092.8, gt: 2103.0,acc:0.84, accx8:0.90,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [173/800] Iter:[0/150], Time: 2.36, lr: 8.8910, Loss: 0.0336, pre: 1723.7, gt: 2235.0,acc:0.84, accx8:0.90,  accx16:0.90,accx32:0.91,acc1:0.00\n","Epoch: [173/800] Iter:[20/150], Time: 0.67, lr: 8.8893, Loss: 0.0269, pre: 1345.9, gt: 1054.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [173/800] Iter:[40/150], Time: 0.63, lr: 8.8877, Loss: 0.0319, pre: 2091.7, gt: 1907.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [173/800] Iter:[60/150], Time: 0.61, lr: 8.8860, Loss: 0.0324, pre: 1886.3, gt: 2715.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [173/800] Iter:[80/150], Time: 0.61, lr: 8.8844, Loss: 0.0325, pre: 2778.2, gt: 3253.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [173/800] Iter:[100/150], Time: 0.60, lr: 8.8827, Loss: 0.0320, pre: 1569.8, gt: 1300.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [173/800] Iter:[120/150], Time: 0.60, lr: 8.8811, Loss: 0.0315, pre: 3511.9, gt: 3219.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [173/800] Iter:[140/150], Time: 0.60, lr: 8.8794, Loss: 0.0317, pre: 802.7, gt: 862.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [174/800] Iter:[0/150], Time: 1.96, lr: 8.8786, Loss: 0.0167, pre: 832.5, gt: 648.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [174/800] Iter:[20/150], Time: 0.65, lr: 8.8769, Loss: 0.0299, pre: 4163.8, gt: 4220.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [174/800] Iter:[40/150], Time: 0.62, lr: 8.8753, Loss: 0.0309, pre: 902.4, gt: 875.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [174/800] Iter:[60/150], Time: 0.60, lr: 8.8736, Loss: 0.0295, pre: 1122.3, gt: 893.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [174/800] Iter:[80/150], Time: 0.60, lr: 8.8720, Loss: 0.0293, pre: 853.7, gt: 844.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [174/800] Iter:[100/150], Time: 0.60, lr: 8.8703, Loss: 0.0285, pre: 1310.0, gt: 1227.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [174/800] Iter:[120/150], Time: 0.59, lr: 8.8687, Loss: 0.0295, pre: 5986.9, gt: 5196.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [174/800] Iter:[140/150], Time: 0.59, lr: 8.8670, Loss: 0.0300, pre: 1921.5, gt: 1456.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  183.75, Best_MAE:  135.0480 MSE:  307.4691,Best_MSE:  224.0210\n","Epoch: [175/800] Iter:[0/150], Time: 4.66, lr: 8.8662, Loss: 0.0198, pre: 907.4, gt: 876.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [175/800] Iter:[20/150], Time: 0.78, lr: 8.8645, Loss: 0.0308, pre: 6975.0, gt: 7740.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [175/800] Iter:[40/150], Time: 0.68, lr: 8.8629, Loss: 0.0314, pre: 617.5, gt: 1372.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [175/800] Iter:[60/150], Time: 0.65, lr: 8.8612, Loss: 0.0306, pre: 930.7, gt: 1015.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [175/800] Iter:[80/150], Time: 0.63, lr: 8.8595, Loss: 0.0294, pre: 1944.3, gt: 1891.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [175/800] Iter:[100/150], Time: 0.62, lr: 8.8579, Loss: 0.0285, pre: 972.4, gt: 1122.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [175/800] Iter:[120/150], Time: 0.62, lr: 8.8562, Loss: 0.0288, pre: 883.6, gt: 1199.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [175/800] Iter:[140/150], Time: 0.61, lr: 8.8545, Loss: 0.0290, pre: 1427.9, gt: 1299.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [176/800] Iter:[0/150], Time: 2.04, lr: 8.8537, Loss: 0.0192, pre: 570.9, gt: 326.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [176/800] Iter:[20/150], Time: 0.65, lr: 8.8520, Loss: 0.0264, pre: 1825.1, gt: 1597.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [176/800] Iter:[40/150], Time: 0.62, lr: 8.8504, Loss: 0.0254, pre: 557.0, gt: 522.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [176/800] Iter:[60/150], Time: 0.61, lr: 8.8487, Loss: 0.0270, pre: 1454.3, gt: 1523.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [176/800] Iter:[80/150], Time: 0.60, lr: 8.8470, Loss: 0.0259, pre: 1431.8, gt: 1363.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [176/800] Iter:[100/150], Time: 0.60, lr: 8.8454, Loss: 0.0282, pre: 1017.3, gt: 959.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [176/800] Iter:[120/150], Time: 0.59, lr: 8.8437, Loss: 0.0285, pre: 1545.9, gt: 1316.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [176/800] Iter:[140/150], Time: 0.59, lr: 8.8420, Loss: 0.0286, pre: 867.1, gt: 967.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [177/800] Iter:[0/150], Time: 1.94, lr: 8.8412, Loss: 0.0183, pre: 742.0, gt: 677.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [177/800] Iter:[20/150], Time: 0.65, lr: 8.8395, Loss: 0.0275, pre: 1243.5, gt: 1494.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [177/800] Iter:[40/150], Time: 0.61, lr: 8.8378, Loss: 0.0266, pre: 886.0, gt: 877.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [177/800] Iter:[60/150], Time: 0.60, lr: 8.8362, Loss: 0.0277, pre: 560.9, gt: 551.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [177/800] Iter:[80/150], Time: 0.60, lr: 8.8345, Loss: 0.0290, pre: 2549.8, gt: 1975.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [177/800] Iter:[100/150], Time: 0.59, lr: 8.8328, Loss: 0.0283, pre: 736.6, gt: 627.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [177/800] Iter:[120/150], Time: 0.59, lr: 8.8311, Loss: 0.0285, pre: 1023.6, gt: 1107.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [177/800] Iter:[140/150], Time: 0.59, lr: 8.8294, Loss: 0.0287, pre: 2433.5, gt: 2883.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [178/800] Iter:[0/150], Time: 2.28, lr: 8.8286, Loss: 0.0120, pre: 272.0, gt: 204.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [178/800] Iter:[20/150], Time: 0.66, lr: 8.8269, Loss: 0.0318, pre: 2295.2, gt: 2463.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [178/800] Iter:[40/150], Time: 0.62, lr: 8.8252, Loss: 0.0307, pre: 2735.5, gt: 2286.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [178/800] Iter:[60/150], Time: 0.61, lr: 8.8235, Loss: 0.0308, pre: 515.4, gt: 474.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [178/800] Iter:[80/150], Time: 0.60, lr: 8.8218, Loss: 0.0301, pre: 939.8, gt: 1250.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [178/800] Iter:[100/150], Time: 0.60, lr: 8.8202, Loss: 0.0295, pre: 2359.8, gt: 3194.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [178/800] Iter:[120/150], Time: 0.60, lr: 8.8185, Loss: 0.0294, pre: 2130.9, gt: 2581.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [178/800] Iter:[140/150], Time: 0.59, lr: 8.8168, Loss: 0.0289, pre: 365.9, gt: 588.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [179/800] Iter:[0/150], Time: 1.80, lr: 8.8159, Loss: 0.0389, pre: 2059.9, gt: 1897.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [179/800] Iter:[20/150], Time: 0.64, lr: 8.8142, Loss: 0.0340, pre: 1596.0, gt: 2033.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [179/800] Iter:[40/150], Time: 0.61, lr: 8.8126, Loss: 0.0321, pre: 1951.9, gt: 1871.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [179/800] Iter:[60/150], Time: 0.60, lr: 8.8109, Loss: 0.0305, pre: 1188.0, gt: 1689.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [179/800] Iter:[80/150], Time: 0.60, lr: 8.8092, Loss: 0.0310, pre: 1363.9, gt: 1789.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [179/800] Iter:[100/150], Time: 0.60, lr: 8.8075, Loss: 0.0303, pre: 1464.3, gt: 1871.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [179/800] Iter:[120/150], Time: 0.59, lr: 8.8058, Loss: 0.0303, pre: 1897.6, gt: 1706.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [179/800] Iter:[140/150], Time: 0.59, lr: 8.8041, Loss: 0.0301, pre: 1652.7, gt: 1425.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  195.45, Best_MAE:  135.0480 MSE:  314.5612,Best_MSE:  224.0210\n","Epoch: [180/800] Iter:[0/150], Time: 4.23, lr: 8.8032, Loss: 0.0193, pre: 684.8, gt: 795.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [180/800] Iter:[20/150], Time: 0.77, lr: 8.8015, Loss: 0.0264, pre: 1273.5, gt: 1348.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [180/800] Iter:[40/150], Time: 0.68, lr: 8.7998, Loss: 0.0291, pre: 1664.2, gt: 2062.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [180/800] Iter:[60/150], Time: 0.65, lr: 8.7981, Loss: 0.0279, pre: 649.4, gt: 526.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [180/800] Iter:[80/150], Time: 0.63, lr: 8.7964, Loss: 0.0272, pre: 1182.2, gt: 1604.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [180/800] Iter:[100/150], Time: 0.62, lr: 8.7947, Loss: 0.0281, pre: 2797.6, gt: 2684.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [180/800] Iter:[120/150], Time: 0.62, lr: 8.7930, Loss: 0.0283, pre: 1720.4, gt: 2457.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [180/800] Iter:[140/150], Time: 0.61, lr: 8.7913, Loss: 0.0292, pre: 2332.7, gt: 2349.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [181/800] Iter:[0/150], Time: 1.87, lr: 8.7905, Loss: 0.0241, pre: 778.9, gt: 925.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [181/800] Iter:[20/150], Time: 0.65, lr: 8.7888, Loss: 0.0298, pre: 1161.8, gt: 1147.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [181/800] Iter:[40/150], Time: 0.61, lr: 8.7870, Loss: 0.0268, pre: 1972.2, gt: 1569.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [181/800] Iter:[60/150], Time: 0.60, lr: 8.7853, Loss: 0.0281, pre: 3935.9, gt: 3391.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [181/800] Iter:[80/150], Time: 0.60, lr: 8.7836, Loss: 0.0280, pre: 1366.9, gt: 1185.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [181/800] Iter:[100/150], Time: 0.60, lr: 8.7819, Loss: 0.0293, pre: 715.9, gt: 349.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [181/800] Iter:[120/150], Time: 0.59, lr: 8.7802, Loss: 0.0298, pre: 3529.0, gt: 3951.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [181/800] Iter:[140/150], Time: 0.59, lr: 8.7785, Loss: 0.0292, pre: 3554.8, gt: 3838.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [182/800] Iter:[0/150], Time: 1.77, lr: 8.7776, Loss: 0.0270, pre: 1107.1, gt: 1346.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [182/800] Iter:[20/150], Time: 0.64, lr: 8.7759, Loss: 0.0285, pre: 817.6, gt: 886.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [182/800] Iter:[40/150], Time: 0.61, lr: 8.7742, Loss: 0.0279, pre: 1138.2, gt: 1519.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [182/800] Iter:[60/150], Time: 0.60, lr: 8.7725, Loss: 0.0280, pre: 1587.5, gt: 1302.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [182/800] Iter:[80/150], Time: 0.60, lr: 8.7708, Loss: 0.0288, pre: 748.9, gt: 978.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [182/800] Iter:[100/150], Time: 0.60, lr: 8.7690, Loss: 0.0299, pre: 1047.7, gt: 900.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [182/800] Iter:[120/150], Time: 0.59, lr: 8.7673, Loss: 0.0292, pre: 2030.3, gt: 2166.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [182/800] Iter:[140/150], Time: 0.59, lr: 8.7656, Loss: 0.0294, pre: 1222.6, gt: 1224.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [183/800] Iter:[0/150], Time: 1.87, lr: 8.7647, Loss: 0.0271, pre: 1171.9, gt: 1009.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [183/800] Iter:[20/150], Time: 0.64, lr: 8.7630, Loss: 0.0326, pre: 2871.2, gt: 2675.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [183/800] Iter:[40/150], Time: 0.61, lr: 8.7613, Loss: 0.0320, pre: 908.0, gt: 1270.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [183/800] Iter:[60/150], Time: 0.60, lr: 8.7596, Loss: 0.0342, pre: 2371.1, gt: 3281.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [183/800] Iter:[80/150], Time: 0.60, lr: 8.7579, Loss: 0.0330, pre: 2335.0, gt: 2501.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [183/800] Iter:[100/150], Time: 0.60, lr: 8.7561, Loss: 0.0331, pre: 975.0, gt: 1153.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [183/800] Iter:[120/150], Time: 0.59, lr: 8.7544, Loss: 0.0326, pre: 1600.5, gt: 1167.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [183/800] Iter:[140/150], Time: 0.59, lr: 8.7527, Loss: 0.0316, pre: 423.2, gt: 317.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [184/800] Iter:[0/150], Time: 2.24, lr: 8.7518, Loss: 0.0243, pre: 917.1, gt: 609.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [184/800] Iter:[20/150], Time: 0.66, lr: 8.7501, Loss: 0.0264, pre: 2567.8, gt: 2572.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [184/800] Iter:[40/150], Time: 0.62, lr: 8.7483, Loss: 0.0262, pre: 805.0, gt: 974.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [184/800] Iter:[60/150], Time: 0.61, lr: 8.7466, Loss: 0.0264, pre: 1552.1, gt: 1843.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [184/800] Iter:[80/150], Time: 0.60, lr: 8.7449, Loss: 0.0279, pre: 4213.3, gt: 3754.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [184/800] Iter:[100/150], Time: 0.60, lr: 8.7431, Loss: 0.0288, pre: 1373.8, gt: 1337.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [184/800] Iter:[120/150], Time: 0.60, lr: 8.7414, Loss: 0.0282, pre: 257.7, gt: 240.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [184/800] Iter:[140/150], Time: 0.60, lr: 8.7397, Loss: 0.0292, pre: 366.9, gt: 332.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  167.08, Best_MAE:  135.0480 MSE:  259.3599,Best_MSE:  224.0210\n","Epoch: [185/800] Iter:[0/150], Time: 4.55, lr: 8.7388, Loss: 0.0353, pre: 1242.3, gt: 1633.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [185/800] Iter:[20/150], Time: 0.77, lr: 8.7371, Loss: 0.0274, pre: 2588.5, gt: 2230.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [185/800] Iter:[40/150], Time: 0.68, lr: 8.7353, Loss: 0.0276, pre: 1099.0, gt: 812.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [185/800] Iter:[60/150], Time: 0.65, lr: 8.7336, Loss: 0.0291, pre: 702.2, gt: 816.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [185/800] Iter:[80/150], Time: 0.63, lr: 8.7318, Loss: 0.0294, pre: 1098.1, gt: 1145.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [185/800] Iter:[100/150], Time: 0.62, lr: 8.7301, Loss: 0.0298, pre: 1115.7, gt: 1141.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [185/800] Iter:[120/150], Time: 0.62, lr: 8.7284, Loss: 0.0300, pre: 4517.3, gt: 5725.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [185/800] Iter:[140/150], Time: 0.61, lr: 8.7266, Loss: 0.0299, pre: 739.9, gt: 747.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [186/800] Iter:[0/150], Time: 1.83, lr: 8.7257, Loss: 0.0270, pre: 2282.4, gt: 2188.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [186/800] Iter:[20/150], Time: 0.64, lr: 8.7240, Loss: 0.0244, pre: 975.7, gt: 903.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [186/800] Iter:[40/150], Time: 0.61, lr: 8.7223, Loss: 0.0289, pre: 1612.8, gt: 1527.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [186/800] Iter:[60/150], Time: 0.60, lr: 8.7205, Loss: 0.0287, pre: 1160.6, gt: 1105.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [186/800] Iter:[80/150], Time: 0.60, lr: 8.7188, Loss: 0.0284, pre: 2795.1, gt: 2591.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [186/800] Iter:[100/150], Time: 0.59, lr: 8.7170, Loss: 0.0284, pre: 2126.2, gt: 2334.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [186/800] Iter:[120/150], Time: 0.59, lr: 8.7153, Loss: 0.0291, pre: 773.6, gt: 498.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [186/800] Iter:[140/150], Time: 0.59, lr: 8.7135, Loss: 0.0286, pre: 1305.2, gt: 1256.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [187/800] Iter:[0/150], Time: 2.14, lr: 8.7126, Loss: 0.0272, pre: 1092.7, gt: 1189.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [187/800] Iter:[20/150], Time: 0.66, lr: 8.7109, Loss: 0.0257, pre: 3274.9, gt: 3897.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [187/800] Iter:[40/150], Time: 0.62, lr: 8.7091, Loss: 0.0259, pre: 277.8, gt: 242.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [187/800] Iter:[60/150], Time: 0.61, lr: 8.7074, Loss: 0.0270, pre: 2136.1, gt: 2366.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [187/800] Iter:[80/150], Time: 0.60, lr: 8.7056, Loss: 0.0282, pre: 1603.8, gt: 1586.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [187/800] Iter:[100/150], Time: 0.60, lr: 8.7039, Loss: 0.0281, pre: 1643.5, gt: 2062.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [187/800] Iter:[120/150], Time: 0.60, lr: 8.7021, Loss: 0.0277, pre: 2458.4, gt: 1848.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [187/800] Iter:[140/150], Time: 0.59, lr: 8.7003, Loss: 0.0281, pre: 594.5, gt: 617.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [188/800] Iter:[0/150], Time: 2.24, lr: 8.6995, Loss: 0.0362, pre: 2860.9, gt: 2376.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [188/800] Iter:[20/150], Time: 0.66, lr: 8.6977, Loss: 0.0324, pre: 1370.4, gt: 1147.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [188/800] Iter:[40/150], Time: 0.62, lr: 8.6959, Loss: 0.0313, pre: 748.8, gt: 714.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [188/800] Iter:[60/150], Time: 0.61, lr: 8.6942, Loss: 0.0297, pre: 508.6, gt: 424.0,acc:0.85, accx8:0.90,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [188/800] Iter:[80/150], Time: 0.60, lr: 8.6924, Loss: 0.0284, pre: 616.1, gt: 474.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [188/800] Iter:[100/150], Time: 0.60, lr: 8.6906, Loss: 0.0287, pre: 1395.3, gt: 1183.0,acc:0.85, accx8:0.90,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [188/800] Iter:[120/150], Time: 0.60, lr: 8.6889, Loss: 0.0287, pre: 1118.8, gt: 917.0,acc:0.85, accx8:0.90,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [188/800] Iter:[140/150], Time: 0.59, lr: 8.6871, Loss: 0.0287, pre: 1053.6, gt: 1041.0,acc:0.85, accx8:0.90,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [189/800] Iter:[0/150], Time: 2.34, lr: 8.6862, Loss: 0.0205, pre: 1268.7, gt: 1360.0,acc:0.85, accx8:0.90,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [189/800] Iter:[20/150], Time: 0.67, lr: 8.6845, Loss: 0.0318, pre: 1272.6, gt: 1687.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [189/800] Iter:[40/150], Time: 0.63, lr: 8.6827, Loss: 0.0386, pre: 1554.0, gt: 1959.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [189/800] Iter:[60/150], Time: 0.61, lr: 8.6809, Loss: 0.0357, pre: 3760.5, gt: 4739.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [189/800] Iter:[80/150], Time: 0.60, lr: 8.6791, Loss: 0.0336, pre: 961.5, gt: 1117.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [189/800] Iter:[100/150], Time: 0.60, lr: 8.6774, Loss: 0.0319, pre: 720.4, gt: 797.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [189/800] Iter:[120/150], Time: 0.60, lr: 8.6756, Loss: 0.0314, pre: 1022.9, gt: 1201.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [189/800] Iter:[140/150], Time: 0.60, lr: 8.6738, Loss: 0.0313, pre: 1249.3, gt: 1352.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.92,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  177.99, Best_MAE:  135.0480 MSE:  300.4404,Best_MSE:  224.0210\n","Epoch: [190/800] Iter:[0/150], Time: 4.51, lr: 8.6729, Loss: 0.0304, pre: 1217.7, gt: 1397.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [190/800] Iter:[20/150], Time: 0.77, lr: 8.6712, Loss: 0.0308, pre: 1221.2, gt: 1257.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [190/800] Iter:[40/150], Time: 0.68, lr: 8.6694, Loss: 0.0292, pre: 647.2, gt: 529.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [190/800] Iter:[60/150], Time: 0.65, lr: 8.6676, Loss: 0.0296, pre: 969.4, gt: 811.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [190/800] Iter:[80/150], Time: 0.63, lr: 8.6658, Loss: 0.0291, pre: 1076.6, gt: 1108.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [190/800] Iter:[100/150], Time: 0.62, lr: 8.6641, Loss: 0.0299, pre: 470.1, gt: 443.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [190/800] Iter:[120/150], Time: 0.61, lr: 8.6623, Loss: 0.0300, pre: 837.1, gt: 899.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [190/800] Iter:[140/150], Time: 0.61, lr: 8.6605, Loss: 0.0296, pre: 655.9, gt: 1135.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [191/800] Iter:[0/150], Time: 2.02, lr: 8.6596, Loss: 0.0281, pre: 1057.7, gt: 909.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [191/800] Iter:[20/150], Time: 0.65, lr: 8.6578, Loss: 0.0318, pre: 528.4, gt: 720.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [191/800] Iter:[40/150], Time: 0.62, lr: 8.6560, Loss: 0.0325, pre: 3262.1, gt: 3905.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [191/800] Iter:[60/150], Time: 0.61, lr: 8.6542, Loss: 0.0317, pre: 1937.7, gt: 1938.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [191/800] Iter:[80/150], Time: 0.60, lr: 8.6525, Loss: 0.0307, pre: 1758.3, gt: 2101.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [191/800] Iter:[100/150], Time: 0.60, lr: 8.6507, Loss: 0.0300, pre: 956.8, gt: 1067.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [191/800] Iter:[120/150], Time: 0.59, lr: 8.6489, Loss: 0.0291, pre: 776.4, gt: 706.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [191/800] Iter:[140/150], Time: 0.59, lr: 8.6471, Loss: 0.0296, pre: 5748.0, gt: 3827.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [192/800] Iter:[0/150], Time: 2.32, lr: 8.6462, Loss: 0.0720, pre: 2573.2, gt: 2831.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [192/800] Iter:[20/150], Time: 0.67, lr: 8.6444, Loss: 0.0290, pre: 4204.4, gt: 4173.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [192/800] Iter:[40/150], Time: 0.63, lr: 8.6426, Loss: 0.0283, pre: 437.6, gt: 391.0,acc:0.84, accx8:0.91,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [192/800] Iter:[60/150], Time: 0.61, lr: 8.6408, Loss: 0.0284, pre: 1097.7, gt: 979.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [192/800] Iter:[80/150], Time: 0.60, lr: 8.6390, Loss: 0.0286, pre: 2674.1, gt: 2502.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [192/800] Iter:[100/150], Time: 0.60, lr: 8.6372, Loss: 0.0287, pre: 3091.6, gt: 3560.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [192/800] Iter:[120/150], Time: 0.60, lr: 8.6354, Loss: 0.0284, pre: 1726.6, gt: 1740.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [192/800] Iter:[140/150], Time: 0.60, lr: 8.6336, Loss: 0.0279, pre: 1127.9, gt: 1442.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [193/800] Iter:[0/150], Time: 1.95, lr: 8.6327, Loss: 0.0177, pre: 765.0, gt: 914.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [193/800] Iter:[20/150], Time: 0.65, lr: 8.6309, Loss: 0.0287, pre: 196.8, gt: 245.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [193/800] Iter:[40/150], Time: 0.62, lr: 8.6291, Loss: 0.0308, pre: 1896.0, gt: 2099.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [193/800] Iter:[60/150], Time: 0.60, lr: 8.6273, Loss: 0.0315, pre: 1508.4, gt: 1272.0,acc:0.85, accx8:0.91,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [193/800] Iter:[80/150], Time: 0.60, lr: 8.6255, Loss: 0.0311, pre: 306.1, gt: 293.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [193/800] Iter:[100/150], Time: 0.60, lr: 8.6237, Loss: 0.0314, pre: 2943.4, gt: 2514.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [193/800] Iter:[120/150], Time: 0.59, lr: 8.6219, Loss: 0.0313, pre: 1153.0, gt: 788.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [193/800] Iter:[140/150], Time: 0.59, lr: 8.6201, Loss: 0.0312, pre: 3382.8, gt: 4067.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [194/800] Iter:[0/150], Time: 2.05, lr: 8.6192, Loss: 0.0355, pre: 1428.3, gt: 1297.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [194/800] Iter:[20/150], Time: 0.65, lr: 8.6174, Loss: 0.0281, pre: 873.8, gt: 804.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [194/800] Iter:[40/150], Time: 0.62, lr: 8.6156, Loss: 0.0299, pre: 2700.8, gt: 2637.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [194/800] Iter:[60/150], Time: 0.61, lr: 8.6138, Loss: 0.0283, pre: 789.4, gt: 783.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [194/800] Iter:[80/150], Time: 0.60, lr: 8.6120, Loss: 0.0286, pre: 662.0, gt: 608.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [194/800] Iter:[100/150], Time: 0.60, lr: 8.6102, Loss: 0.0290, pre: 174.3, gt: 162.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [194/800] Iter:[120/150], Time: 0.59, lr: 8.6084, Loss: 0.0290, pre: 2140.7, gt: 2399.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [194/800] Iter:[140/150], Time: 0.59, lr: 8.6066, Loss: 0.0297, pre: 1783.8, gt: 1732.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.91,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  177.67, Best_MAE:  135.0480 MSE:  312.2882,Best_MSE:  224.0210\n","Epoch: [195/800] Iter:[0/150], Time: 4.34, lr: 8.6057, Loss: 0.0243, pre: 458.2, gt: 715.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [195/800] Iter:[20/150], Time: 0.76, lr: 8.6039, Loss: 0.0275, pre: 1132.3, gt: 1222.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [195/800] Iter:[40/150], Time: 0.68, lr: 8.6020, Loss: 0.0265, pre: 3182.3, gt: 3399.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [195/800] Iter:[60/150], Time: 0.65, lr: 8.6002, Loss: 0.0275, pre: 1116.1, gt: 944.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [195/800] Iter:[80/150], Time: 0.63, lr: 8.5984, Loss: 0.0287, pre: 1539.0, gt: 835.0,acc:0.85, accx8:0.90,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [195/800] Iter:[100/150], Time: 0.62, lr: 8.5966, Loss: 0.0307, pre: 1644.1, gt: 1302.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [195/800] Iter:[120/150], Time: 0.61, lr: 8.5948, Loss: 0.0301, pre: 1624.5, gt: 1153.0,acc:0.85, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [195/800] Iter:[140/150], Time: 0.61, lr: 8.5930, Loss: 0.0307, pre: 1617.7, gt: 1560.0,acc:0.85, accx8:0.90,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [196/800] Iter:[0/150], Time: 1.79, lr: 8.5920, Loss: 0.0229, pre: 1156.4, gt: 1686.0,acc:0.85, accx8:0.90,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [196/800] Iter:[20/150], Time: 0.64, lr: 8.5902, Loss: 0.0307, pre: 876.6, gt: 614.0,acc:0.85, accx8:0.90,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [196/800] Iter:[40/150], Time: 0.61, lr: 8.5884, Loss: 0.0289, pre: 1516.1, gt: 1482.0,acc:0.85, accx8:0.90,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [196/800] Iter:[60/150], Time: 0.60, lr: 8.5866, Loss: 0.0286, pre: 1311.3, gt: 1701.0,acc:0.84, accx8:0.90,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [196/800] Iter:[80/150], Time: 0.60, lr: 8.5848, Loss: 0.0278, pre: 856.2, gt: 744.0,acc:0.84, accx8:0.90,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [196/800] Iter:[100/150], Time: 0.60, lr: 8.5829, Loss: 0.0289, pre: 688.3, gt: 702.0,acc:0.84, accx8:0.90,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [196/800] Iter:[120/150], Time: 0.59, lr: 8.5811, Loss: 0.0298, pre: 1759.8, gt: 1223.0,acc:0.84, accx8:0.90,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [196/800] Iter:[140/150], Time: 0.59, lr: 8.5793, Loss: 0.0292, pre: 1337.3, gt: 1456.0,acc:0.84, accx8:0.90,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [197/800] Iter:[0/150], Time: 2.38, lr: 8.5784, Loss: 0.0180, pre: 1236.8, gt: 1494.0,acc:0.84, accx8:0.90,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [197/800] Iter:[20/150], Time: 0.67, lr: 8.5765, Loss: 0.0333, pre: 1013.4, gt: 1732.0,acc:0.84, accx8:0.90,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [197/800] Iter:[40/150], Time: 0.63, lr: 8.5747, Loss: 0.0320, pre: 2828.7, gt: 2472.0,acc:0.84, accx8:0.90,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [197/800] Iter:[60/150], Time: 0.61, lr: 8.5729, Loss: 0.0311, pre: 1784.7, gt: 1278.0,acc:0.83, accx8:0.90,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [197/800] Iter:[80/150], Time: 0.61, lr: 8.5710, Loss: 0.0324, pre: 1102.4, gt: 1444.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [197/800] Iter:[100/150], Time: 0.60, lr: 8.5692, Loss: 0.0308, pre: 1194.1, gt: 1189.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [197/800] Iter:[120/150], Time: 0.60, lr: 8.5674, Loss: 0.0297, pre: 385.8, gt: 430.0,acc:0.84, accx8:0.90,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [197/800] Iter:[140/150], Time: 0.60, lr: 8.5655, Loss: 0.0298, pre: 2724.6, gt: 3311.0,acc:0.83, accx8:0.90,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [198/800] Iter:[0/150], Time: 2.07, lr: 8.5646, Loss: 0.0160, pre: 648.4, gt: 513.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [198/800] Iter:[20/150], Time: 0.66, lr: 8.5628, Loss: 0.0305, pre: 1051.0, gt: 1032.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [198/800] Iter:[40/150], Time: 0.62, lr: 8.5610, Loss: 0.0322, pre: 1136.1, gt: 1166.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [198/800] Iter:[60/150], Time: 0.61, lr: 8.5591, Loss: 0.0313, pre: 1514.1, gt: 2749.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [198/800] Iter:[80/150], Time: 0.60, lr: 8.5573, Loss: 0.0332, pre: 1567.7, gt: 1171.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [198/800] Iter:[100/150], Time: 0.60, lr: 8.5554, Loss: 0.0329, pre: 1088.6, gt: 1038.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [198/800] Iter:[120/150], Time: 0.60, lr: 8.5536, Loss: 0.0318, pre: 1076.4, gt: 1267.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [198/800] Iter:[140/150], Time: 0.59, lr: 8.5518, Loss: 0.0310, pre: 829.6, gt: 594.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [199/800] Iter:[0/150], Time: 1.88, lr: 8.5508, Loss: 0.0473, pre: 2232.2, gt: 2103.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [199/800] Iter:[20/150], Time: 0.65, lr: 8.5490, Loss: 0.0297, pre: 1210.7, gt: 1407.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [199/800] Iter:[40/150], Time: 0.62, lr: 8.5472, Loss: 0.0285, pre: 1687.5, gt: 1881.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [199/800] Iter:[60/150], Time: 0.60, lr: 8.5453, Loss: 0.0281, pre: 686.0, gt: 831.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [199/800] Iter:[80/150], Time: 0.60, lr: 8.5435, Loss: 0.0280, pre: 765.4, gt: 584.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [199/800] Iter:[100/150], Time: 0.60, lr: 8.5416, Loss: 0.0284, pre: 1299.8, gt: 1899.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [199/800] Iter:[120/150], Time: 0.59, lr: 8.5398, Loss: 0.0280, pre: 848.6, gt: 1068.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [199/800] Iter:[140/150], Time: 0.59, lr: 8.5379, Loss: 0.0281, pre: 528.1, gt: 388.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  171.89, Best_MAE:  135.0480 MSE:  296.8054,Best_MSE:  224.0210\n","Epoch: [200/800] Iter:[0/150], Time: 4.21, lr: 8.5370, Loss: 0.0359, pre: 1216.8, gt: 1838.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [200/800] Iter:[20/150], Time: 0.76, lr: 8.5351, Loss: 0.0294, pre: 3657.3, gt: 3087.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [200/800] Iter:[40/150], Time: 0.67, lr: 8.5333, Loss: 0.0294, pre: 1084.9, gt: 1298.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [200/800] Iter:[60/150], Time: 0.64, lr: 8.5314, Loss: 0.0293, pre: 1574.4, gt: 1295.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [200/800] Iter:[80/150], Time: 0.63, lr: 8.5296, Loss: 0.0291, pre: 3597.1, gt: 3487.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [200/800] Iter:[100/150], Time: 0.62, lr: 8.5277, Loss: 0.0289, pre: 984.3, gt: 1045.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [200/800] Iter:[120/150], Time: 0.61, lr: 8.5259, Loss: 0.0290, pre: 1936.4, gt: 1949.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [200/800] Iter:[140/150], Time: 0.61, lr: 8.5240, Loss: 0.0292, pre: 5121.3, gt: 5113.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [201/800] Iter:[0/150], Time: 1.78, lr: 8.5231, Loss: 0.0254, pre: 972.4, gt: 1061.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [201/800] Iter:[20/150], Time: 0.64, lr: 8.5212, Loss: 0.0314, pre: 1933.3, gt: 2490.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [201/800] Iter:[40/150], Time: 0.61, lr: 8.5194, Loss: 0.0282, pre: 2206.4, gt: 2562.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [201/800] Iter:[60/150], Time: 0.60, lr: 8.5175, Loss: 0.0283, pre: 277.9, gt: 331.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [201/800] Iter:[80/150], Time: 0.60, lr: 8.5157, Loss: 0.0294, pre: 2866.9, gt: 3003.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [201/800] Iter:[100/150], Time: 0.59, lr: 8.5138, Loss: 0.0291, pre: 518.5, gt: 556.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [201/800] Iter:[120/150], Time: 0.59, lr: 8.5119, Loss: 0.0288, pre: 1242.4, gt: 992.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [201/800] Iter:[140/150], Time: 0.59, lr: 8.5101, Loss: 0.0285, pre: 1624.1, gt: 1521.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [202/800] Iter:[0/150], Time: 2.35, lr: 8.5091, Loss: 0.0303, pre: 873.9, gt: 1000.0,acc:0.83, accx8:0.89,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [202/800] Iter:[20/150], Time: 0.67, lr: 8.5073, Loss: 0.0335, pre: 5734.0, gt: 6075.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [202/800] Iter:[40/150], Time: 0.62, lr: 8.5054, Loss: 0.0303, pre: 2128.8, gt: 1724.0,acc:0.83, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [202/800] Iter:[60/150], Time: 0.61, lr: 8.5036, Loss: 0.0303, pre: 935.1, gt: 845.0,acc:0.84, accx8:0.90,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [202/800] Iter:[80/150], Time: 0.60, lr: 8.5017, Loss: 0.0292, pre: 2722.4, gt: 3099.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.91,acc1:0.00\n","Epoch: [202/800] Iter:[100/150], Time: 0.60, lr: 8.4998, Loss: 0.0294, pre: 1423.5, gt: 1206.0,acc:0.84, accx8:0.90,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [202/800] Iter:[120/150], Time: 0.60, lr: 8.4979, Loss: 0.0303, pre: 1631.5, gt: 1991.0,acc:0.84, accx8:0.90,  accx16:0.92,accx32:0.91,acc1:0.00\n","Epoch: [202/800] Iter:[140/150], Time: 0.60, lr: 8.4961, Loss: 0.0304, pre: 1403.7, gt: 1924.0,acc:0.84, accx8:0.90,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [203/800] Iter:[0/150], Time: 1.78, lr: 8.4951, Loss: 0.0469, pre: 1810.6, gt: 2395.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [203/800] Iter:[20/150], Time: 0.65, lr: 8.4933, Loss: 0.0305, pre: 699.3, gt: 1045.0,acc:0.84, accx8:0.90,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [203/800] Iter:[40/150], Time: 0.62, lr: 8.4914, Loss: 0.0297, pre: 1137.0, gt: 1055.0,acc:0.84, accx8:0.90,  accx16:0.91,accx32:0.92,acc1:0.00\n","Epoch: [203/800] Iter:[60/150], Time: 0.61, lr: 8.4895, Loss: 0.0281, pre: 1068.2, gt: 1193.0,acc:0.84, accx8:0.90,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [203/800] Iter:[80/150], Time: 0.60, lr: 8.4877, Loss: 0.0289, pre: 2122.7, gt: 2496.0,acc:0.84, accx8:0.90,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [203/800] Iter:[100/150], Time: 0.60, lr: 8.4858, Loss: 0.0282, pre: 2996.9, gt: 2751.0,acc:0.84, accx8:0.90,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [203/800] Iter:[120/150], Time: 0.59, lr: 8.4839, Loss: 0.0279, pre: 1121.8, gt: 1224.0,acc:0.85, accx8:0.90,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [203/800] Iter:[140/150], Time: 0.59, lr: 8.4820, Loss: 0.0282, pre: 371.9, gt: 504.0,acc:0.85, accx8:0.90,  accx16:0.92,accx32:0.92,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  104.19, Best_MAE:  104.1941 MSE:  164.2538,Best_MSE:  164.2538\n","Epoch: [204/800] Iter:[0/150], Time: 4.02, lr: 8.4811, Loss: 0.0305, pre: 676.0, gt: 691.0,acc:0.85, accx8:0.90,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [204/800] Iter:[20/150], Time: 0.75, lr: 8.4792, Loss: 0.0266, pre: 884.2, gt: 1310.0,acc:0.85, accx8:0.90,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [204/800] Iter:[40/150], Time: 0.67, lr: 8.4773, Loss: 0.0277, pre: 962.1, gt: 1058.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [204/800] Iter:[60/150], Time: 0.64, lr: 8.4754, Loss: 0.0285, pre: 6823.7, gt: 8766.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [204/800] Iter:[80/150], Time: 0.63, lr: 8.4736, Loss: 0.0289, pre: 2241.9, gt: 2538.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [204/800] Iter:[100/150], Time: 0.62, lr: 8.4717, Loss: 0.0290, pre: 898.0, gt: 1182.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [204/800] Iter:[120/150], Time: 0.61, lr: 8.4698, Loss: 0.0294, pre: 2083.0, gt: 3372.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [204/800] Iter:[140/150], Time: 0.61, lr: 8.4679, Loss: 0.0301, pre: 1918.2, gt: 1738.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [205/800] Iter:[0/150], Time: 2.48, lr: 8.4670, Loss: 0.0577, pre: 4558.4, gt: 4819.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [205/800] Iter:[20/150], Time: 0.67, lr: 8.4651, Loss: 0.0290, pre: 926.5, gt: 864.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [205/800] Iter:[40/150], Time: 0.63, lr: 8.4632, Loss: 0.0279, pre: 975.2, gt: 1045.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [205/800] Iter:[60/150], Time: 0.61, lr: 8.4613, Loss: 0.0283, pre: 560.8, gt: 528.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [205/800] Iter:[80/150], Time: 0.61, lr: 8.4594, Loss: 0.0301, pre: 1009.2, gt: 829.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [205/800] Iter:[100/150], Time: 0.60, lr: 8.4575, Loss: 0.0303, pre: 1845.8, gt: 2687.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [205/800] Iter:[120/150], Time: 0.60, lr: 8.4556, Loss: 0.0305, pre: 497.9, gt: 597.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [205/800] Iter:[140/150], Time: 0.60, lr: 8.4538, Loss: 0.0309, pre: 1028.9, gt: 1210.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [206/800] Iter:[0/150], Time: 2.15, lr: 8.4528, Loss: 0.0184, pre: 870.8, gt: 1022.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [206/800] Iter:[20/150], Time: 0.66, lr: 8.4509, Loss: 0.0251, pre: 1498.6, gt: 1309.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [206/800] Iter:[40/150], Time: 0.62, lr: 8.4490, Loss: 0.0272, pre: 924.7, gt: 795.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [206/800] Iter:[60/150], Time: 0.61, lr: 8.4471, Loss: 0.0278, pre: 2239.5, gt: 3077.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [206/800] Iter:[80/150], Time: 0.60, lr: 8.4452, Loss: 0.0269, pre: 1534.9, gt: 1682.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [206/800] Iter:[100/150], Time: 0.60, lr: 8.4433, Loss: 0.0265, pre: 2284.0, gt: 2883.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [206/800] Iter:[120/150], Time: 0.60, lr: 8.4414, Loss: 0.0266, pre: 754.4, gt: 851.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [206/800] Iter:[140/150], Time: 0.59, lr: 8.4395, Loss: 0.0274, pre: 2921.5, gt: 3064.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  120.27, Best_MAE:  104.1941 MSE:  208.1854,Best_MSE:  164.2538\n","Epoch: [207/800] Iter:[0/150], Time: 4.81, lr: 8.4386, Loss: 0.0331, pre: 1546.6, gt: 1835.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [207/800] Iter:[20/150], Time: 0.79, lr: 8.4367, Loss: 0.0303, pre: 1178.7, gt: 1153.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [207/800] Iter:[40/150], Time: 0.69, lr: 8.4348, Loss: 0.0324, pre: 790.0, gt: 1099.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [207/800] Iter:[60/150], Time: 0.65, lr: 8.4329, Loss: 0.0310, pre: 1155.7, gt: 931.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [207/800] Iter:[80/150], Time: 0.63, lr: 8.4310, Loss: 0.0301, pre: 1071.2, gt: 768.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [207/800] Iter:[100/150], Time: 0.62, lr: 8.4291, Loss: 0.0293, pre: 1404.8, gt: 1472.0,acc:0.85, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [207/800] Iter:[120/150], Time: 0.62, lr: 8.4272, Loss: 0.0293, pre: 1661.2, gt: 1603.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [207/800] Iter:[140/150], Time: 0.61, lr: 8.4253, Loss: 0.0299, pre: 2294.6, gt: 2029.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [208/800] Iter:[0/150], Time: 2.41, lr: 8.4243, Loss: 0.0267, pre: 1310.0, gt: 1341.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [208/800] Iter:[20/150], Time: 0.67, lr: 8.4224, Loss: 0.0316, pre: 857.0, gt: 789.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [208/800] Iter:[40/150], Time: 0.63, lr: 8.4205, Loss: 0.0320, pre: 1054.6, gt: 1179.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [208/800] Iter:[60/150], Time: 0.61, lr: 8.4186, Loss: 0.0294, pre: 920.5, gt: 1174.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [208/800] Iter:[80/150], Time: 0.60, lr: 8.4167, Loss: 0.0290, pre: 1974.0, gt: 1780.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [208/800] Iter:[100/150], Time: 0.60, lr: 8.4148, Loss: 0.0292, pre: 1174.6, gt: 898.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [208/800] Iter:[120/150], Time: 0.60, lr: 8.4129, Loss: 0.0281, pre: 678.7, gt: 817.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [208/800] Iter:[140/150], Time: 0.60, lr: 8.4109, Loss: 0.0286, pre: 3142.5, gt: 3581.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [209/800] Iter:[0/150], Time: 2.01, lr: 8.4100, Loss: 0.0265, pre: 1789.0, gt: 1673.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [209/800] Iter:[20/150], Time: 0.65, lr: 8.4081, Loss: 0.0251, pre: 476.1, gt: 507.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [209/800] Iter:[40/150], Time: 0.62, lr: 8.4062, Loss: 0.0289, pre: 4109.2, gt: 3550.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [209/800] Iter:[60/150], Time: 0.61, lr: 8.4042, Loss: 0.0287, pre: 2961.6, gt: 3371.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [209/800] Iter:[80/150], Time: 0.60, lr: 8.4023, Loss: 0.0282, pre: 4049.5, gt: 3633.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [209/800] Iter:[100/150], Time: 0.60, lr: 8.4004, Loss: 0.0279, pre: 987.7, gt: 883.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [209/800] Iter:[120/150], Time: 0.59, lr: 8.3985, Loss: 0.0282, pre: 512.9, gt: 404.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [209/800] Iter:[140/150], Time: 0.59, lr: 8.3966, Loss: 0.0282, pre: 4004.2, gt: 4177.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  119.97, Best_MAE:  104.1941 MSE:  190.5005,Best_MSE:  164.2538\n","Epoch: [210/800] Iter:[0/150], Time: 4.54, lr: 8.3956, Loss: 0.0135, pre: 476.6, gt: 527.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [210/800] Iter:[20/150], Time: 0.78, lr: 8.3937, Loss: 0.0291, pre: 1228.7, gt: 827.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [210/800] Iter:[40/150], Time: 0.68, lr: 8.3918, Loss: 0.0291, pre: 1655.3, gt: 1120.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [210/800] Iter:[60/150], Time: 0.65, lr: 8.3898, Loss: 0.0292, pre: 3045.7, gt: 2982.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [210/800] Iter:[80/150], Time: 0.63, lr: 8.3879, Loss: 0.0302, pre: 3432.9, gt: 3214.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [210/800] Iter:[100/150], Time: 0.62, lr: 8.3860, Loss: 0.0305, pre: 861.4, gt: 995.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [210/800] Iter:[120/150], Time: 0.62, lr: 8.3841, Loss: 0.0311, pre: 806.5, gt: 768.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [210/800] Iter:[140/150], Time: 0.61, lr: 8.3821, Loss: 0.0305, pre: 555.9, gt: 643.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [211/800] Iter:[0/150], Time: 2.13, lr: 8.3812, Loss: 0.0197, pre: 1146.8, gt: 1070.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [211/800] Iter:[20/150], Time: 0.66, lr: 8.3793, Loss: 0.0259, pre: 2021.4, gt: 1648.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [211/800] Iter:[40/150], Time: 0.62, lr: 8.3773, Loss: 0.0268, pre: 784.3, gt: 918.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [211/800] Iter:[60/150], Time: 0.61, lr: 8.3754, Loss: 0.0266, pre: 293.1, gt: 324.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [211/800] Iter:[80/150], Time: 0.60, lr: 8.3735, Loss: 0.0281, pre: 4562.2, gt: 4643.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [211/800] Iter:[100/150], Time: 0.60, lr: 8.3715, Loss: 0.0288, pre: 1867.9, gt: 2467.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [211/800] Iter:[120/150], Time: 0.60, lr: 8.3696, Loss: 0.0280, pre: 855.8, gt: 1043.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [211/800] Iter:[140/150], Time: 0.59, lr: 8.3677, Loss: 0.0278, pre: 730.9, gt: 949.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [212/800] Iter:[0/150], Time: 1.89, lr: 8.3667, Loss: 0.0195, pre: 876.8, gt: 821.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [212/800] Iter:[20/150], Time: 0.65, lr: 8.3648, Loss: 0.0291, pre: 1078.9, gt: 1189.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [212/800] Iter:[40/150], Time: 0.62, lr: 8.3628, Loss: 0.0274, pre: 1139.1, gt: 1739.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [212/800] Iter:[60/150], Time: 0.61, lr: 8.3609, Loss: 0.0262, pre: 1430.5, gt: 1490.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [212/800] Iter:[80/150], Time: 0.60, lr: 8.3590, Loss: 0.0266, pre: 1839.1, gt: 1459.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [212/800] Iter:[100/150], Time: 0.60, lr: 8.3570, Loss: 0.0274, pre: 1052.2, gt: 1338.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [212/800] Iter:[120/150], Time: 0.59, lr: 8.3551, Loss: 0.0292, pre: 704.9, gt: 687.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [212/800] Iter:[140/150], Time: 0.59, lr: 8.3531, Loss: 0.0292, pre: 1504.2, gt: 1279.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  136.00, Best_MAE:  104.1941 MSE:  219.4207,Best_MSE:  164.2538\n","Epoch: [213/800] Iter:[0/150], Time: 4.13, lr: 8.3522, Loss: 0.0312, pre: 1979.9, gt: 2264.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [213/800] Iter:[20/150], Time: 0.75, lr: 8.3502, Loss: 0.0241, pre: 782.0, gt: 926.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [213/800] Iter:[40/150], Time: 0.67, lr: 8.3483, Loss: 0.0253, pre: 3678.9, gt: 3161.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [213/800] Iter:[60/150], Time: 0.64, lr: 8.3463, Loss: 0.0267, pre: 645.0, gt: 530.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [213/800] Iter:[80/150], Time: 0.63, lr: 8.3444, Loss: 0.0268, pre: 1832.1, gt: 1514.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [213/800] Iter:[100/150], Time: 0.62, lr: 8.3424, Loss: 0.0277, pre: 2023.8, gt: 2110.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [213/800] Iter:[120/150], Time: 0.61, lr: 8.3405, Loss: 0.0277, pre: 1390.7, gt: 1555.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [213/800] Iter:[140/150], Time: 0.61, lr: 8.3386, Loss: 0.0275, pre: 2707.1, gt: 2336.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [214/800] Iter:[0/150], Time: 2.13, lr: 8.3376, Loss: 0.0406, pre: 2211.6, gt: 2615.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [214/800] Iter:[20/150], Time: 0.66, lr: 8.3356, Loss: 0.0280, pre: 1114.5, gt: 1242.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [214/800] Iter:[40/150], Time: 0.62, lr: 8.3337, Loss: 0.0268, pre: 2440.2, gt: 2404.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [214/800] Iter:[60/150], Time: 0.61, lr: 8.3317, Loss: 0.0275, pre: 1458.3, gt: 1539.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [214/800] Iter:[80/150], Time: 0.60, lr: 8.3298, Loss: 0.0273, pre: 686.3, gt: 721.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [214/800] Iter:[100/150], Time: 0.60, lr: 8.3278, Loss: 0.0276, pre: 2257.3, gt: 1917.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [214/800] Iter:[120/150], Time: 0.60, lr: 8.3259, Loss: 0.0290, pre: 3368.6, gt: 4020.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [214/800] Iter:[140/150], Time: 0.59, lr: 8.3239, Loss: 0.0287, pre: 1646.9, gt: 1663.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [215/800] Iter:[0/150], Time: 1.69, lr: 8.3229, Loss: 0.0269, pre: 1197.3, gt: 1500.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [215/800] Iter:[20/150], Time: 0.64, lr: 8.3210, Loss: 0.0319, pre: 2117.2, gt: 2012.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [215/800] Iter:[40/150], Time: 0.61, lr: 8.3190, Loss: 0.0319, pre: 1482.5, gt: 1101.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [215/800] Iter:[60/150], Time: 0.60, lr: 8.3171, Loss: 0.0295, pre: 729.5, gt: 650.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [215/800] Iter:[80/150], Time: 0.60, lr: 8.3151, Loss: 0.0289, pre: 400.8, gt: 341.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [215/800] Iter:[100/150], Time: 0.59, lr: 8.3132, Loss: 0.0293, pre: 2427.8, gt: 2520.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [215/800] Iter:[120/150], Time: 0.59, lr: 8.3112, Loss: 0.0294, pre: 2513.6, gt: 2515.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [215/800] Iter:[140/150], Time: 0.59, lr: 8.3092, Loss: 0.0297, pre: 523.1, gt: 633.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  204.67, Best_MAE:  104.1941 MSE:  328.7246,Best_MSE:  164.2538\n","Epoch: [216/800] Iter:[0/150], Time: 4.50, lr: 8.3083, Loss: 0.0325, pre: 977.7, gt: 1477.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [216/800] Iter:[20/150], Time: 0.77, lr: 8.3063, Loss: 0.0295, pre: 2526.5, gt: 3221.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [216/800] Iter:[40/150], Time: 0.68, lr: 8.3043, Loss: 0.0330, pre: 1993.2, gt: 2017.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [216/800] Iter:[60/150], Time: 0.65, lr: 8.3024, Loss: 0.0313, pre: 1742.0, gt: 2150.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [216/800] Iter:[80/150], Time: 0.63, lr: 8.3004, Loss: 0.0299, pre: 788.7, gt: 668.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [216/800] Iter:[100/150], Time: 0.62, lr: 8.2984, Loss: 0.0292, pre: 599.7, gt: 486.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [216/800] Iter:[120/150], Time: 0.61, lr: 8.2965, Loss: 0.0287, pre: 2998.7, gt: 3291.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [216/800] Iter:[140/150], Time: 0.61, lr: 8.2945, Loss: 0.0297, pre: 2230.1, gt: 2696.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [217/800] Iter:[0/150], Time: 2.22, lr: 8.2935, Loss: 0.0796, pre: 4987.0, gt: 5839.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [217/800] Iter:[20/150], Time: 0.66, lr: 8.2915, Loss: 0.0313, pre: 397.2, gt: 303.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [217/800] Iter:[40/150], Time: 0.62, lr: 8.2896, Loss: 0.0267, pre: 472.8, gt: 559.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [217/800] Iter:[60/150], Time: 0.61, lr: 8.2876, Loss: 0.0284, pre: 920.9, gt: 1225.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [217/800] Iter:[80/150], Time: 0.60, lr: 8.2856, Loss: 0.0290, pre: 604.5, gt: 738.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [217/800] Iter:[100/150], Time: 0.60, lr: 8.2837, Loss: 0.0294, pre: 1569.5, gt: 1696.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [217/800] Iter:[120/150], Time: 0.60, lr: 8.2817, Loss: 0.0297, pre: 2010.3, gt: 2101.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [217/800] Iter:[140/150], Time: 0.59, lr: 8.2797, Loss: 0.0293, pre: 2266.5, gt: 2738.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [218/800] Iter:[0/150], Time: 2.40, lr: 8.2787, Loss: 0.0261, pre: 1153.0, gt: 1013.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [218/800] Iter:[20/150], Time: 0.67, lr: 8.2767, Loss: 0.0306, pre: 2172.2, gt: 2744.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [218/800] Iter:[40/150], Time: 0.63, lr: 8.2748, Loss: 0.0320, pre: 4824.6, gt: 4911.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [218/800] Iter:[60/150], Time: 0.61, lr: 8.2728, Loss: 0.0298, pre: 1961.8, gt: 2703.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [218/800] Iter:[80/150], Time: 0.60, lr: 8.2708, Loss: 0.0299, pre: 467.4, gt: 404.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [218/800] Iter:[100/150], Time: 0.60, lr: 8.2688, Loss: 0.0295, pre: 2662.5, gt: 2249.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [218/800] Iter:[120/150], Time: 0.60, lr: 8.2669, Loss: 0.0290, pre: 1898.9, gt: 1770.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [218/800] Iter:[140/150], Time: 0.60, lr: 8.2649, Loss: 0.0287, pre: 1251.3, gt: 1379.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  115.84, Best_MAE:  104.1941 MSE:  206.7249,Best_MSE:  164.2538\n","Epoch: [219/800] Iter:[0/150], Time: 4.33, lr: 8.2639, Loss: 0.0307, pre: 1508.1, gt: 1794.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [219/800] Iter:[20/150], Time: 0.77, lr: 8.2619, Loss: 0.0259, pre: 3036.5, gt: 3149.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [219/800] Iter:[40/150], Time: 0.68, lr: 8.2599, Loss: 0.0278, pre: 4329.8, gt: 4350.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [219/800] Iter:[60/150], Time: 0.64, lr: 8.2579, Loss: 0.0282, pre: 2328.3, gt: 2775.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [219/800] Iter:[80/150], Time: 0.63, lr: 8.2559, Loss: 0.0279, pre: 1342.3, gt: 1631.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [219/800] Iter:[100/150], Time: 0.62, lr: 8.2540, Loss: 0.0290, pre: 1311.2, gt: 1274.0,acc:0.87, accx8:0.92,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [219/800] Iter:[120/150], Time: 0.61, lr: 8.2520, Loss: 0.0291, pre: 916.2, gt: 889.0,acc:0.87, accx8:0.92,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [219/800] Iter:[140/150], Time: 0.61, lr: 8.2500, Loss: 0.0296, pre: 438.0, gt: 542.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [220/800] Iter:[0/150], Time: 1.81, lr: 8.2490, Loss: 0.0647, pre: 4476.4, gt: 4155.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [220/800] Iter:[20/150], Time: 0.64, lr: 8.2470, Loss: 0.0292, pre: 1129.2, gt: 1282.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [220/800] Iter:[40/150], Time: 0.61, lr: 8.2450, Loss: 0.0283, pre: 844.5, gt: 756.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [220/800] Iter:[60/150], Time: 0.60, lr: 8.2430, Loss: 0.0281, pre: 1058.2, gt: 1091.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [220/800] Iter:[80/150], Time: 0.60, lr: 8.2410, Loss: 0.0271, pre: 2118.9, gt: 2287.0,acc:0.86, accx8:0.92,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [220/800] Iter:[100/150], Time: 0.59, lr: 8.2390, Loss: 0.0270, pre: 932.3, gt: 834.0,acc:0.86, accx8:0.92,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [220/800] Iter:[120/150], Time: 0.59, lr: 8.2370, Loss: 0.0284, pre: 3881.3, gt: 4779.0,acc:0.86, accx8:0.92,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [220/800] Iter:[140/150], Time: 0.59, lr: 8.2351, Loss: 0.0282, pre: 965.3, gt: 1034.0,acc:0.86, accx8:0.92,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [221/800] Iter:[0/150], Time: 2.07, lr: 8.2341, Loss: 0.0242, pre: 1172.6, gt: 1127.0,acc:0.86, accx8:0.92,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [221/800] Iter:[20/150], Time: 0.65, lr: 8.2321, Loss: 0.0319, pre: 3832.2, gt: 3523.0,acc:0.86, accx8:0.92,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [221/800] Iter:[40/150], Time: 0.62, lr: 8.2301, Loss: 0.0306, pre: 666.5, gt: 663.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [221/800] Iter:[60/150], Time: 0.61, lr: 8.2281, Loss: 0.0291, pre: 1693.0, gt: 1565.0,acc:0.86, accx8:0.92,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [221/800] Iter:[80/150], Time: 0.60, lr: 8.2261, Loss: 0.0286, pre: 1030.7, gt: 1258.0,acc:0.86, accx8:0.92,  accx16:0.92,accx32:0.92,acc1:0.00\n","Epoch: [221/800] Iter:[100/150], Time: 0.60, lr: 8.2241, Loss: 0.0282, pre: 678.7, gt: 719.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [221/800] Iter:[120/150], Time: 0.59, lr: 8.2221, Loss: 0.0284, pre: 3461.6, gt: 2807.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [221/800] Iter:[140/150], Time: 0.59, lr: 8.2201, Loss: 0.0285, pre: 471.1, gt: 352.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  133.84, Best_MAE:  104.1941 MSE:  221.7957,Best_MSE:  164.2538\n","Epoch: [222/800] Iter:[0/150], Time: 4.07, lr: 8.2191, Loss: 0.0158, pre: 746.0, gt: 716.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [222/800] Iter:[20/150], Time: 0.75, lr: 8.2171, Loss: 0.0278, pre: 1604.2, gt: 1114.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [222/800] Iter:[40/150], Time: 0.67, lr: 8.2151, Loss: 0.0282, pre: 2071.6, gt: 2555.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [222/800] Iter:[60/150], Time: 0.64, lr: 8.2131, Loss: 0.0285, pre: 1207.4, gt: 1377.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [222/800] Iter:[80/150], Time: 0.63, lr: 8.2110, Loss: 0.0288, pre: 1760.8, gt: 1985.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [222/800] Iter:[100/150], Time: 0.62, lr: 8.2090, Loss: 0.0297, pre: 6358.5, gt: 8674.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [222/800] Iter:[120/150], Time: 0.61, lr: 8.2070, Loss: 0.0293, pre: 594.7, gt: 651.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [222/800] Iter:[140/150], Time: 0.61, lr: 8.2050, Loss: 0.0284, pre: 278.7, gt: 223.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [223/800] Iter:[0/150], Time: 2.03, lr: 8.2040, Loss: 0.0176, pre: 1026.4, gt: 971.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [223/800] Iter:[20/150], Time: 0.66, lr: 8.2020, Loss: 0.0327, pre: 377.8, gt: 427.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [223/800] Iter:[40/150], Time: 0.62, lr: 8.2000, Loss: 0.0357, pre: 1070.6, gt: 1158.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [223/800] Iter:[60/150], Time: 0.61, lr: 8.1980, Loss: 0.0333, pre: 3415.1, gt: 3902.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [223/800] Iter:[80/150], Time: 0.60, lr: 8.1960, Loss: 0.0320, pre: 1069.2, gt: 885.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [223/800] Iter:[100/150], Time: 0.60, lr: 8.1940, Loss: 0.0314, pre: 614.0, gt: 698.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [223/800] Iter:[120/150], Time: 0.60, lr: 8.1920, Loss: 0.0315, pre: 1048.2, gt: 977.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [223/800] Iter:[140/150], Time: 0.59, lr: 8.1899, Loss: 0.0306, pre: 707.4, gt: 536.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [224/800] Iter:[0/150], Time: 1.84, lr: 8.1889, Loss: 0.0244, pre: 1259.2, gt: 1384.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [224/800] Iter:[20/150], Time: 0.64, lr: 8.1869, Loss: 0.0274, pre: 2534.9, gt: 2231.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [224/800] Iter:[40/150], Time: 0.61, lr: 8.1849, Loss: 0.0273, pre: 568.4, gt: 513.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [224/800] Iter:[60/150], Time: 0.60, lr: 8.1829, Loss: 0.0272, pre: 328.4, gt: 438.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [224/800] Iter:[80/150], Time: 0.60, lr: 8.1809, Loss: 0.0272, pre: 988.2, gt: 1299.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [224/800] Iter:[100/150], Time: 0.60, lr: 8.1788, Loss: 0.0271, pre: 2230.7, gt: 2548.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [224/800] Iter:[120/150], Time: 0.59, lr: 8.1768, Loss: 0.0268, pre: 1581.5, gt: 1640.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [224/800] Iter:[140/150], Time: 0.59, lr: 8.1748, Loss: 0.0280, pre: 4193.4, gt: 4031.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  261.54, Best_MAE:  104.1941 MSE:  394.2889,Best_MSE:  164.2538\n","Epoch: [225/800] Iter:[0/150], Time: 4.36, lr: 8.1738, Loss: 0.0327, pre: 1400.4, gt: 1677.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [225/800] Iter:[20/150], Time: 0.77, lr: 8.1718, Loss: 0.0332, pre: 1122.5, gt: 910.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [225/800] Iter:[40/150], Time: 0.68, lr: 8.1697, Loss: 0.0304, pre: 1427.8, gt: 1522.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [225/800] Iter:[60/150], Time: 0.65, lr: 8.1677, Loss: 0.0305, pre: 1154.1, gt: 847.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [225/800] Iter:[80/150], Time: 0.63, lr: 8.1657, Loss: 0.0293, pre: 516.3, gt: 399.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [225/800] Iter:[100/150], Time: 0.62, lr: 8.1637, Loss: 0.0289, pre: 1105.0, gt: 1253.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [225/800] Iter:[120/150], Time: 0.61, lr: 8.1616, Loss: 0.0292, pre: 1413.1, gt: 1981.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [225/800] Iter:[140/150], Time: 0.61, lr: 8.1596, Loss: 0.0287, pre: 1427.1, gt: 992.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [226/800] Iter:[0/150], Time: 1.99, lr: 8.1586, Loss: 0.0330, pre: 2015.8, gt: 2277.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [226/800] Iter:[20/150], Time: 0.65, lr: 8.1566, Loss: 0.0282, pre: 2462.3, gt: 2579.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [226/800] Iter:[40/150], Time: 0.62, lr: 8.1545, Loss: 0.0281, pre: 1780.3, gt: 1874.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [226/800] Iter:[60/150], Time: 0.61, lr: 8.1525, Loss: 0.0298, pre: 640.0, gt: 810.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [226/800] Iter:[80/150], Time: 0.60, lr: 8.1505, Loss: 0.0286, pre: 814.9, gt: 649.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [226/800] Iter:[100/150], Time: 0.60, lr: 8.1485, Loss: 0.0290, pre: 1757.0, gt: 1707.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [226/800] Iter:[120/150], Time: 0.59, lr: 8.1464, Loss: 0.0291, pre: 1513.4, gt: 1684.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.92,acc1:0.00\n","Epoch: [226/800] Iter:[140/150], Time: 0.59, lr: 8.1444, Loss: 0.0288, pre: 1483.3, gt: 1686.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [227/800] Iter:[0/150], Time: 1.91, lr: 8.1434, Loss: 0.0132, pre: 641.7, gt: 759.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [227/800] Iter:[20/150], Time: 0.65, lr: 8.1413, Loss: 0.0294, pre: 1644.5, gt: 1542.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [227/800] Iter:[40/150], Time: 0.62, lr: 8.1393, Loss: 0.0287, pre: 1467.0, gt: 1560.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [227/800] Iter:[60/150], Time: 0.61, lr: 8.1373, Loss: 0.0283, pre: 1165.3, gt: 1175.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [227/800] Iter:[80/150], Time: 0.60, lr: 8.1352, Loss: 0.0278, pre: 2570.2, gt: 2413.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [227/800] Iter:[100/150], Time: 0.60, lr: 8.1332, Loss: 0.0279, pre: 1282.6, gt: 1317.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [227/800] Iter:[120/150], Time: 0.60, lr: 8.1311, Loss: 0.0278, pre: 2635.9, gt: 3036.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [227/800] Iter:[140/150], Time: 0.59, lr: 8.1291, Loss: 0.0278, pre: 2900.4, gt: 2882.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  115.54, Best_MAE:  104.1941 MSE:  179.1229,Best_MSE:  164.2538\n","Epoch: [228/800] Iter:[0/150], Time: 4.32, lr: 8.1281, Loss: 0.0419, pre: 3365.3, gt: 3327.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [228/800] Iter:[20/150], Time: 0.77, lr: 8.1260, Loss: 0.0316, pre: 4549.4, gt: 4187.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [228/800] Iter:[40/150], Time: 0.68, lr: 8.1240, Loss: 0.0298, pre: 1151.5, gt: 1113.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [228/800] Iter:[60/150], Time: 0.65, lr: 8.1220, Loss: 0.0276, pre: 455.1, gt: 449.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.93,acc1:0.00\n","Epoch: [228/800] Iter:[80/150], Time: 0.63, lr: 8.1199, Loss: 0.0268, pre: 1016.2, gt: 949.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.93,acc1:0.00\n","Epoch: [228/800] Iter:[100/150], Time: 0.62, lr: 8.1179, Loss: 0.0274, pre: 303.7, gt: 296.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.93,acc1:0.00\n","Epoch: [228/800] Iter:[120/150], Time: 0.61, lr: 8.1158, Loss: 0.0279, pre: 504.8, gt: 552.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.93,acc1:0.00\n","Epoch: [228/800] Iter:[140/150], Time: 0.61, lr: 8.1138, Loss: 0.0276, pre: 3577.4, gt: 3517.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.93,acc1:0.00\n","Epoch: [229/800] Iter:[0/150], Time: 2.46, lr: 8.1128, Loss: 0.0533, pre: 6586.5, gt: 5900.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.93,acc1:0.00\n","Epoch: [229/800] Iter:[20/150], Time: 0.67, lr: 8.1107, Loss: 0.0279, pre: 619.3, gt: 588.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.93,acc1:0.00\n","Epoch: [229/800] Iter:[40/150], Time: 0.63, lr: 8.1087, Loss: 0.0280, pre: 4018.8, gt: 4808.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.93,acc1:0.00\n","Epoch: [229/800] Iter:[60/150], Time: 0.61, lr: 8.1066, Loss: 0.0279, pre: 986.4, gt: 1230.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.93,acc1:0.00\n","Epoch: [229/800] Iter:[80/150], Time: 0.61, lr: 8.1046, Loss: 0.0276, pre: 400.9, gt: 389.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.93,acc1:0.00\n","Epoch: [229/800] Iter:[100/150], Time: 0.60, lr: 8.1025, Loss: 0.0275, pre: 825.4, gt: 760.0,acc:0.86, accx8:0.91,  accx16:0.92,accx32:0.93,acc1:0.00\n","Epoch: [229/800] Iter:[120/150], Time: 0.60, lr: 8.1005, Loss: 0.0278, pre: 435.9, gt: 300.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [229/800] Iter:[140/150], Time: 0.60, lr: 8.0984, Loss: 0.0285, pre: 373.0, gt: 448.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.93,acc1:0.00\n","Epoch: [230/800] Iter:[0/150], Time: 2.20, lr: 8.0974, Loss: 0.0201, pre: 1021.0, gt: 972.0,acc:0.87, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [230/800] Iter:[20/150], Time: 0.66, lr: 8.0953, Loss: 0.0308, pre: 170.5, gt: 98.0,acc:0.87, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [230/800] Iter:[40/150], Time: 0.62, lr: 8.0933, Loss: 0.0324, pre: 2350.5, gt: 2290.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.93,acc1:0.00\n","Epoch: [230/800] Iter:[60/150], Time: 0.61, lr: 8.0912, Loss: 0.0308, pre: 1110.7, gt: 826.0,acc:0.87, accx8:0.91,  accx16:0.92,accx32:0.93,acc1:0.00\n","Epoch: [230/800] Iter:[80/150], Time: 0.60, lr: 8.0892, Loss: 0.0321, pre: 1554.6, gt: 1967.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [230/800] Iter:[100/150], Time: 0.60, lr: 8.0871, Loss: 0.0310, pre: 1137.4, gt: 1558.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [230/800] Iter:[120/150], Time: 0.60, lr: 8.0850, Loss: 0.0304, pre: 6053.7, gt: 5249.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [230/800] Iter:[140/150], Time: 0.59, lr: 8.0830, Loss: 0.0296, pre: 1148.0, gt: 1006.0,acc:0.87, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  147.37, Best_MAE:  104.1941 MSE:  269.6790,Best_MSE:  164.2538\n","Epoch: [231/800] Iter:[0/150], Time: 4.67, lr: 8.0819, Loss: 0.0207, pre: 807.8, gt: 773.0,acc:0.87, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [231/800] Iter:[20/150], Time: 0.78, lr: 8.0799, Loss: 0.0279, pre: 1714.5, gt: 1450.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [231/800] Iter:[40/150], Time: 0.68, lr: 8.0778, Loss: 0.0276, pre: 843.3, gt: 885.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [231/800] Iter:[60/150], Time: 0.65, lr: 8.0758, Loss: 0.0269, pre: 1766.8, gt: 1712.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [231/800] Iter:[80/150], Time: 0.63, lr: 8.0737, Loss: 0.0266, pre: 231.3, gt: 257.0,acc:0.87, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [231/800] Iter:[100/150], Time: 0.62, lr: 8.0716, Loss: 0.0262, pre: 1358.2, gt: 1484.0,acc:0.87, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [231/800] Iter:[120/150], Time: 0.62, lr: 8.0696, Loss: 0.0262, pre: 848.4, gt: 943.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [231/800] Iter:[140/150], Time: 0.61, lr: 8.0675, Loss: 0.0275, pre: 3186.3, gt: 3683.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [232/800] Iter:[0/150], Time: 2.30, lr: 8.0665, Loss: 0.0232, pre: 1558.2, gt: 1652.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [232/800] Iter:[20/150], Time: 0.66, lr: 8.0644, Loss: 0.0257, pre: 3334.0, gt: 3065.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [232/800] Iter:[40/150], Time: 0.62, lr: 8.0623, Loss: 0.0288, pre: 875.0, gt: 790.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [232/800] Iter:[60/150], Time: 0.61, lr: 8.0603, Loss: 0.0297, pre: 833.8, gt: 854.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [232/800] Iter:[80/150], Time: 0.60, lr: 8.0582, Loss: 0.0292, pre: 2261.0, gt: 2073.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [232/800] Iter:[100/150], Time: 0.60, lr: 8.0561, Loss: 0.0292, pre: 290.8, gt: 210.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [232/800] Iter:[120/150], Time: 0.60, lr: 8.0541, Loss: 0.0290, pre: 1947.0, gt: 2194.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [232/800] Iter:[140/150], Time: 0.59, lr: 8.0520, Loss: 0.0286, pre: 424.8, gt: 485.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [233/800] Iter:[0/150], Time: 1.90, lr: 8.0509, Loss: 0.0250, pre: 1010.3, gt: 898.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [233/800] Iter:[20/150], Time: 0.65, lr: 8.0489, Loss: 0.0284, pre: 1829.5, gt: 1899.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [233/800] Iter:[40/150], Time: 0.61, lr: 8.0468, Loss: 0.0275, pre: 1515.6, gt: 1616.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [233/800] Iter:[60/150], Time: 0.60, lr: 8.0447, Loss: 0.0271, pre: 2064.6, gt: 2305.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [233/800] Iter:[80/150], Time: 0.60, lr: 8.0427, Loss: 0.0269, pre: 766.4, gt: 650.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [233/800] Iter:[100/150], Time: 0.60, lr: 8.0406, Loss: 0.0267, pre: 2084.7, gt: 2397.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [233/800] Iter:[120/150], Time: 0.59, lr: 8.0385, Loss: 0.0276, pre: 1426.5, gt: 1223.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [233/800] Iter:[140/150], Time: 0.59, lr: 8.0364, Loss: 0.0275, pre: 623.4, gt: 698.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  158.73, Best_MAE:  104.1941 MSE:  299.8329,Best_MSE:  164.2538\n","Epoch: [234/800] Iter:[0/150], Time: 4.46, lr: 8.0354, Loss: 0.0226, pre: 1468.0, gt: 1710.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [234/800] Iter:[20/150], Time: 0.77, lr: 8.0333, Loss: 0.0301, pre: 3243.9, gt: 2296.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [234/800] Iter:[40/150], Time: 0.68, lr: 8.0312, Loss: 0.0297, pre: 930.8, gt: 713.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [234/800] Iter:[60/150], Time: 0.65, lr: 8.0291, Loss: 0.0287, pre: 1828.2, gt: 2155.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [234/800] Iter:[80/150], Time: 0.63, lr: 8.0271, Loss: 0.0284, pre: 2520.0, gt: 2373.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [234/800] Iter:[100/150], Time: 0.62, lr: 8.0250, Loss: 0.0280, pre: 1897.1, gt: 1817.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [234/800] Iter:[120/150], Time: 0.62, lr: 8.0229, Loss: 0.0278, pre: 248.0, gt: 195.0,acc:0.87, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [234/800] Iter:[140/150], Time: 0.61, lr: 8.0208, Loss: 0.0279, pre: 473.7, gt: 598.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [235/800] Iter:[0/150], Time: 2.22, lr: 8.0198, Loss: 0.0295, pre: 1105.7, gt: 967.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [235/800] Iter:[20/150], Time: 0.66, lr: 8.0177, Loss: 0.0301, pre: 3186.1, gt: 2455.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [235/800] Iter:[40/150], Time: 0.62, lr: 8.0156, Loss: 0.0284, pre: 1949.3, gt: 2034.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [235/800] Iter:[60/150], Time: 0.61, lr: 8.0135, Loss: 0.0273, pre: 1174.7, gt: 1257.0,acc:0.87, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [235/800] Iter:[80/150], Time: 0.60, lr: 8.0114, Loss: 0.0270, pre: 2265.1, gt: 2435.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [235/800] Iter:[100/150], Time: 0.60, lr: 8.0093, Loss: 0.0279, pre: 1900.9, gt: 2051.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [235/800] Iter:[120/150], Time: 0.60, lr: 8.0072, Loss: 0.0279, pre: 2420.0, gt: 2544.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [235/800] Iter:[140/150], Time: 0.59, lr: 8.0051, Loss: 0.0281, pre: 640.4, gt: 544.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [236/800] Iter:[0/150], Time: 2.11, lr: 8.0041, Loss: 0.0205, pre: 1331.8, gt: 1674.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [236/800] Iter:[20/150], Time: 0.66, lr: 8.0020, Loss: 0.0323, pre: 2434.4, gt: 2889.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [236/800] Iter:[40/150], Time: 0.62, lr: 7.9999, Loss: 0.0313, pre: 1356.2, gt: 1557.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [236/800] Iter:[60/150], Time: 0.61, lr: 7.9978, Loss: 0.0294, pre: 1146.4, gt: 1093.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [236/800] Iter:[80/150], Time: 0.60, lr: 7.9957, Loss: 0.0287, pre: 1349.1, gt: 1598.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [236/800] Iter:[100/150], Time: 0.60, lr: 7.9936, Loss: 0.0289, pre: 1863.6, gt: 1683.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [236/800] Iter:[120/150], Time: 0.60, lr: 7.9915, Loss: 0.0285, pre: 443.9, gt: 491.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [236/800] Iter:[140/150], Time: 0.59, lr: 7.9894, Loss: 0.0281, pre: 1808.3, gt: 2378.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  124.89, Best_MAE:  104.1941 MSE:  229.2251,Best_MSE:  164.2538\n","Epoch: [237/800] Iter:[0/150], Time: 4.34, lr: 7.9884, Loss: 0.0238, pre: 1543.6, gt: 1632.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [237/800] Iter:[20/150], Time: 0.77, lr: 7.9863, Loss: 0.0288, pre: 4427.6, gt: 4309.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [237/800] Iter:[40/150], Time: 0.68, lr: 7.9842, Loss: 0.0271, pre: 2804.2, gt: 2950.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [237/800] Iter:[60/150], Time: 0.65, lr: 7.9821, Loss: 0.0264, pre: 2005.4, gt: 2159.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [237/800] Iter:[80/150], Time: 0.63, lr: 7.9800, Loss: 0.0280, pre: 4052.7, gt: 3158.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [237/800] Iter:[100/150], Time: 0.62, lr: 7.9779, Loss: 0.0284, pre: 2375.1, gt: 2063.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [237/800] Iter:[120/150], Time: 0.61, lr: 7.9758, Loss: 0.0286, pre: 669.1, gt: 464.0,acc:0.87, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [237/800] Iter:[140/150], Time: 0.61, lr: 7.9737, Loss: 0.0289, pre: 1143.6, gt: 1216.0,acc:0.87, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [238/800] Iter:[0/150], Time: 2.19, lr: 7.9726, Loss: 0.0161, pre: 747.4, gt: 937.0,acc:0.87, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [238/800] Iter:[20/150], Time: 0.66, lr: 7.9705, Loss: 0.0281, pre: 2388.4, gt: 2637.0,acc:0.87, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [238/800] Iter:[40/150], Time: 0.62, lr: 7.9684, Loss: 0.0273, pre: 1135.2, gt: 1161.0,acc:0.87, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [238/800] Iter:[60/150], Time: 0.61, lr: 7.9663, Loss: 0.0270, pre: 1705.7, gt: 1901.0,acc:0.87, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [238/800] Iter:[80/150], Time: 0.60, lr: 7.9642, Loss: 0.0274, pre: 2825.4, gt: 2296.0,acc:0.87, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [238/800] Iter:[100/150], Time: 0.60, lr: 7.9621, Loss: 0.0281, pre: 592.8, gt: 624.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [238/800] Iter:[120/150], Time: 0.60, lr: 7.9600, Loss: 0.0285, pre: 2290.9, gt: 2754.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [238/800] Iter:[140/150], Time: 0.59, lr: 7.9579, Loss: 0.0302, pre: 878.1, gt: 1102.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [239/800] Iter:[0/150], Time: 2.43, lr: 7.9568, Loss: 0.0437, pre: 2752.7, gt: 3849.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [239/800] Iter:[20/150], Time: 0.67, lr: 7.9547, Loss: 0.0313, pre: 3962.7, gt: 6046.0,acc:0.86, accx8:0.91,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [239/800] Iter:[40/150], Time: 0.63, lr: 7.9526, Loss: 0.0315, pre: 4798.9, gt: 4633.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [239/800] Iter:[60/150], Time: 0.61, lr: 7.9505, Loss: 0.0307, pre: 1164.3, gt: 1185.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [239/800] Iter:[80/150], Time: 0.61, lr: 7.9484, Loss: 0.0292, pre: 1957.0, gt: 1837.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [239/800] Iter:[100/150], Time: 0.60, lr: 7.9463, Loss: 0.0286, pre: 1520.6, gt: 1600.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [239/800] Iter:[120/150], Time: 0.60, lr: 7.9442, Loss: 0.0292, pre: 1003.2, gt: 1440.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [239/800] Iter:[140/150], Time: 0.60, lr: 7.9420, Loss: 0.0290, pre: 740.6, gt: 745.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  145.82, Best_MAE:  104.1941 MSE:  255.7858,Best_MSE:  164.2538\n","Epoch: [240/800] Iter:[0/150], Time: 4.13, lr: 7.9410, Loss: 0.0346, pre: 1511.4, gt: 1763.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [240/800] Iter:[20/150], Time: 0.75, lr: 7.9389, Loss: 0.0274, pre: 788.2, gt: 575.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [240/800] Iter:[40/150], Time: 0.67, lr: 7.9368, Loss: 0.0273, pre: 2060.4, gt: 2493.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [240/800] Iter:[60/150], Time: 0.64, lr: 7.9346, Loss: 0.0266, pre: 1757.0, gt: 2080.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [240/800] Iter:[80/150], Time: 0.63, lr: 7.9325, Loss: 0.0276, pre: 4174.8, gt: 4645.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [240/800] Iter:[100/150], Time: 0.62, lr: 7.9304, Loss: 0.0284, pre: 358.6, gt: 304.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [240/800] Iter:[120/150], Time: 0.61, lr: 7.9283, Loss: 0.0281, pre: 1553.9, gt: 1394.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [240/800] Iter:[140/150], Time: 0.61, lr: 7.9262, Loss: 0.0282, pre: 616.1, gt: 830.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [241/800] Iter:[0/150], Time: 1.90, lr: 7.9251, Loss: 0.0305, pre: 1931.5, gt: 2118.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [241/800] Iter:[20/150], Time: 0.65, lr: 7.9230, Loss: 0.0258, pre: 914.5, gt: 872.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [241/800] Iter:[40/150], Time: 0.62, lr: 7.9209, Loss: 0.0262, pre: 252.4, gt: 829.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [241/800] Iter:[60/150], Time: 0.61, lr: 7.9187, Loss: 0.0277, pre: 2314.0, gt: 2530.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [241/800] Iter:[80/150], Time: 0.60, lr: 7.9166, Loss: 0.0278, pre: 3667.3, gt: 3344.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [241/800] Iter:[100/150], Time: 0.60, lr: 7.9145, Loss: 0.0282, pre: 970.3, gt: 1247.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [241/800] Iter:[120/150], Time: 0.59, lr: 7.9123, Loss: 0.0283, pre: 2156.2, gt: 2090.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [241/800] Iter:[140/150], Time: 0.59, lr: 7.9102, Loss: 0.0286, pre: 1601.8, gt: 1791.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [242/800] Iter:[0/150], Time: 2.31, lr: 7.9092, Loss: 0.0395, pre: 3600.4, gt: 3033.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [242/800] Iter:[20/150], Time: 0.67, lr: 7.9070, Loss: 0.0326, pre: 2659.2, gt: 2746.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [242/800] Iter:[40/150], Time: 0.63, lr: 7.9049, Loss: 0.0295, pre: 875.4, gt: 803.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [242/800] Iter:[60/150], Time: 0.61, lr: 7.9028, Loss: 0.0285, pre: 938.7, gt: 784.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [242/800] Iter:[80/150], Time: 0.60, lr: 7.9006, Loss: 0.0308, pre: 5918.4, gt: 5447.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [242/800] Iter:[100/150], Time: 0.60, lr: 7.8985, Loss: 0.0305, pre: 6242.0, gt: 6311.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [242/800] Iter:[120/150], Time: 0.60, lr: 7.8964, Loss: 0.0299, pre: 1726.4, gt: 1625.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [242/800] Iter:[140/150], Time: 0.59, lr: 7.8942, Loss: 0.0293, pre: 2264.5, gt: 2147.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  113.62, Best_MAE:  104.1941 MSE:  188.2954,Best_MSE:  164.2538\n","Epoch: [243/800] Iter:[0/150], Time: 4.85, lr: 7.8932, Loss: 0.0119, pre: 1179.6, gt: 780.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [243/800] Iter:[20/150], Time: 0.79, lr: 7.8910, Loss: 0.0296, pre: 1731.5, gt: 1161.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [243/800] Iter:[40/150], Time: 0.69, lr: 7.8889, Loss: 0.0287, pre: 2002.7, gt: 1827.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [243/800] Iter:[60/150], Time: 0.66, lr: 7.8868, Loss: 0.0288, pre: 945.7, gt: 1014.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [243/800] Iter:[80/150], Time: 0.64, lr: 7.8846, Loss: 0.0290, pre: 2069.1, gt: 1977.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [243/800] Iter:[100/150], Time: 0.63, lr: 7.8825, Loss: 0.0292, pre: 1120.3, gt: 936.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [243/800] Iter:[120/150], Time: 0.62, lr: 7.8804, Loss: 0.0288, pre: 683.1, gt: 692.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [243/800] Iter:[140/150], Time: 0.61, lr: 7.8782, Loss: 0.0289, pre: 2141.8, gt: 2131.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [244/800] Iter:[0/150], Time: 2.11, lr: 7.8772, Loss: 0.0545, pre: 1906.0, gt: 1970.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [244/800] Iter:[20/150], Time: 0.66, lr: 7.8750, Loss: 0.0307, pre: 1836.7, gt: 1960.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [244/800] Iter:[40/150], Time: 0.62, lr: 7.8729, Loss: 0.0297, pre: 919.1, gt: 991.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [244/800] Iter:[60/150], Time: 0.61, lr: 7.8707, Loss: 0.0298, pre: 1219.1, gt: 1178.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [244/800] Iter:[80/150], Time: 0.60, lr: 7.8686, Loss: 0.0282, pre: 819.8, gt: 979.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [244/800] Iter:[100/150], Time: 0.60, lr: 7.8664, Loss: 0.0276, pre: 831.5, gt: 793.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [244/800] Iter:[120/150], Time: 0.59, lr: 7.8643, Loss: 0.0276, pre: 749.8, gt: 1104.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [244/800] Iter:[140/150], Time: 0.59, lr: 7.8622, Loss: 0.0277, pre: 1453.8, gt: 1288.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [245/800] Iter:[0/150], Time: 1.80, lr: 7.8611, Loss: 0.0186, pre: 694.3, gt: 658.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [245/800] Iter:[20/150], Time: 0.64, lr: 7.8589, Loss: 0.0305, pre: 670.7, gt: 681.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [245/800] Iter:[40/150], Time: 0.61, lr: 7.8568, Loss: 0.0288, pre: 2960.9, gt: 3242.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [245/800] Iter:[60/150], Time: 0.60, lr: 7.8546, Loss: 0.0290, pre: 964.1, gt: 874.0,acc:0.86, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [245/800] Iter:[80/150], Time: 0.60, lr: 7.8525, Loss: 0.0284, pre: 3575.2, gt: 3490.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [245/800] Iter:[100/150], Time: 0.59, lr: 7.8503, Loss: 0.0280, pre: 1570.8, gt: 1432.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [245/800] Iter:[120/150], Time: 0.59, lr: 7.8482, Loss: 0.0278, pre: 413.7, gt: 486.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [245/800] Iter:[140/150], Time: 0.59, lr: 7.8460, Loss: 0.0285, pre: 1634.0, gt: 1920.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  119.67, Best_MAE:  104.1941 MSE:  205.9402,Best_MSE:  164.2538\n","Epoch: [246/800] Iter:[0/150], Time: 4.68, lr: 7.8450, Loss: 0.0112, pre: 450.2, gt: 416.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [246/800] Iter:[20/150], Time: 0.78, lr: 7.8428, Loss: 0.0249, pre: 1297.6, gt: 954.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [246/800] Iter:[40/150], Time: 0.68, lr: 7.8407, Loss: 0.0266, pre: 703.3, gt: 689.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [246/800] Iter:[60/150], Time: 0.65, lr: 7.8385, Loss: 0.0262, pre: 1460.2, gt: 1472.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [246/800] Iter:[80/150], Time: 0.63, lr: 7.8364, Loss: 0.0275, pre: 1079.8, gt: 1409.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [246/800] Iter:[100/150], Time: 0.62, lr: 7.8342, Loss: 0.0284, pre: 2856.1, gt: 2584.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [246/800] Iter:[120/150], Time: 0.62, lr: 7.8320, Loss: 0.0284, pre: 2264.0, gt: 2427.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [246/800] Iter:[140/150], Time: 0.61, lr: 7.8299, Loss: 0.0277, pre: 589.9, gt: 509.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [247/800] Iter:[0/150], Time: 2.14, lr: 7.8288, Loss: 0.0277, pre: 2119.7, gt: 2333.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [247/800] Iter:[20/150], Time: 0.66, lr: 7.8267, Loss: 0.0307, pre: 2404.2, gt: 2585.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [247/800] Iter:[40/150], Time: 0.62, lr: 7.8245, Loss: 0.0278, pre: 1665.1, gt: 1522.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [247/800] Iter:[60/150], Time: 0.61, lr: 7.8223, Loss: 0.0274, pre: 3734.0, gt: 3039.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [247/800] Iter:[80/150], Time: 0.60, lr: 7.8202, Loss: 0.0278, pre: 516.8, gt: 543.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [247/800] Iter:[100/150], Time: 0.60, lr: 7.8180, Loss: 0.0289, pre: 2365.2, gt: 3180.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [247/800] Iter:[120/150], Time: 0.60, lr: 7.8159, Loss: 0.0290, pre: 2778.7, gt: 2526.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [247/800] Iter:[140/150], Time: 0.59, lr: 7.8137, Loss: 0.0284, pre: 3350.8, gt: 4207.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [248/800] Iter:[0/150], Time: 2.02, lr: 7.8126, Loss: 0.0297, pre: 2385.6, gt: 2495.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [248/800] Iter:[20/150], Time: 0.65, lr: 7.8104, Loss: 0.0264, pre: 3088.6, gt: 3858.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [248/800] Iter:[40/150], Time: 0.62, lr: 7.8083, Loss: 0.0256, pre: 732.8, gt: 1000.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [248/800] Iter:[60/150], Time: 0.61, lr: 7.8061, Loss: 0.0282, pre: 890.0, gt: 929.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [248/800] Iter:[80/150], Time: 0.60, lr: 7.8039, Loss: 0.0277, pre: 1359.5, gt: 1370.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [248/800] Iter:[100/150], Time: 0.60, lr: 7.8018, Loss: 0.0272, pre: 1493.5, gt: 1610.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [248/800] Iter:[120/150], Time: 0.59, lr: 7.7996, Loss: 0.0278, pre: 1558.3, gt: 1484.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [248/800] Iter:[140/150], Time: 0.59, lr: 7.7974, Loss: 0.0282, pre: 1359.8, gt: 1514.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  192.09, Best_MAE:  104.1941 MSE:  370.0215,Best_MSE:  164.2538\n","Epoch: [249/800] Iter:[0/150], Time: 4.81, lr: 7.7964, Loss: 0.0114, pre: 462.2, gt: 349.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [249/800] Iter:[20/150], Time: 0.79, lr: 7.7942, Loss: 0.0271, pre: 1024.3, gt: 1126.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [249/800] Iter:[40/150], Time: 0.69, lr: 7.7920, Loss: 0.0282, pre: 755.3, gt: 956.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [249/800] Iter:[60/150], Time: 0.65, lr: 7.7899, Loss: 0.0277, pre: 1007.4, gt: 907.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [249/800] Iter:[80/150], Time: 0.64, lr: 7.7877, Loss: 0.0272, pre: 494.3, gt: 371.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [249/800] Iter:[100/150], Time: 0.63, lr: 7.7855, Loss: 0.0271, pre: 1696.0, gt: 1620.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [249/800] Iter:[120/150], Time: 0.62, lr: 7.7833, Loss: 0.0278, pre: 1292.4, gt: 1875.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [249/800] Iter:[140/150], Time: 0.61, lr: 7.7812, Loss: 0.0281, pre: 1646.4, gt: 1778.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [250/800] Iter:[0/150], Time: 2.24, lr: 7.7801, Loss: 0.0384, pre: 1930.4, gt: 2237.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [250/800] Iter:[20/150], Time: 0.66, lr: 7.7779, Loss: 0.0321, pre: 785.1, gt: 987.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [250/800] Iter:[40/150], Time: 0.62, lr: 7.7757, Loss: 0.0303, pre: 2166.4, gt: 2005.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [250/800] Iter:[60/150], Time: 0.61, lr: 7.7735, Loss: 0.0294, pre: 1013.5, gt: 1222.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [250/800] Iter:[80/150], Time: 0.60, lr: 7.7714, Loss: 0.0287, pre: 834.7, gt: 1201.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [250/800] Iter:[100/150], Time: 0.60, lr: 7.7692, Loss: 0.0282, pre: 2960.6, gt: 3147.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [250/800] Iter:[120/150], Time: 0.60, lr: 7.7670, Loss: 0.0282, pre: 777.8, gt: 579.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [250/800] Iter:[140/150], Time: 0.59, lr: 7.7648, Loss: 0.0279, pre: 342.9, gt: 447.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [251/800] Iter:[0/150], Time: 2.27, lr: 7.7637, Loss: 0.0212, pre: 1014.1, gt: 952.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [251/800] Iter:[20/150], Time: 0.66, lr: 7.7616, Loss: 0.0280, pre: 3316.2, gt: 2817.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [251/800] Iter:[40/150], Time: 0.62, lr: 7.7594, Loss: 0.0281, pre: 1075.4, gt: 904.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [251/800] Iter:[60/150], Time: 0.61, lr: 7.7572, Loss: 0.0273, pre: 1605.6, gt: 1476.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [251/800] Iter:[80/150], Time: 0.60, lr: 7.7550, Loss: 0.0275, pre: 216.0, gt: 187.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [251/800] Iter:[100/150], Time: 0.60, lr: 7.7528, Loss: 0.0278, pre: 995.6, gt: 999.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [251/800] Iter:[120/150], Time: 0.60, lr: 7.7506, Loss: 0.0280, pre: 443.9, gt: 492.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [251/800] Iter:[140/150], Time: 0.59, lr: 7.7485, Loss: 0.0284, pre: 383.5, gt: 321.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.013, MAE:  140.92, Best_MAE:  104.1941 MSE:  265.2656,Best_MSE:  164.2538\n","Epoch: [252/800] Iter:[0/150], Time: 4.67, lr: 7.7474, Loss: 0.0295, pre: 560.5, gt: 649.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [252/800] Iter:[20/150], Time: 0.79, lr: 7.7452, Loss: 0.0310, pre: 2651.5, gt: 2207.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [252/800] Iter:[40/150], Time: 0.69, lr: 7.7430, Loss: 0.0290, pre: 1890.8, gt: 2467.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [252/800] Iter:[60/150], Time: 0.65, lr: 7.7408, Loss: 0.0285, pre: 470.9, gt: 425.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [252/800] Iter:[80/150], Time: 0.64, lr: 7.7386, Loss: 0.0280, pre: 2021.8, gt: 1436.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [252/800] Iter:[100/150], Time: 0.63, lr: 7.7364, Loss: 0.0280, pre: 904.5, gt: 1313.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [252/800] Iter:[120/150], Time: 0.62, lr: 7.7342, Loss: 0.0276, pre: 2144.0, gt: 2328.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [252/800] Iter:[140/150], Time: 0.61, lr: 7.7320, Loss: 0.0275, pre: 686.1, gt: 801.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [253/800] Iter:[0/150], Time: 1.82, lr: 7.7310, Loss: 0.0252, pre: 1593.6, gt: 1407.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [253/800] Iter:[20/150], Time: 0.64, lr: 7.7288, Loss: 0.0236, pre: 1025.6, gt: 1339.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [253/800] Iter:[40/150], Time: 0.61, lr: 7.7266, Loss: 0.0249, pre: 1570.9, gt: 1537.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [253/800] Iter:[60/150], Time: 0.60, lr: 7.7244, Loss: 0.0264, pre: 2748.6, gt: 3190.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [253/800] Iter:[80/150], Time: 0.60, lr: 7.7222, Loss: 0.0264, pre: 1236.4, gt: 1145.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [253/800] Iter:[100/150], Time: 0.59, lr: 7.7200, Loss: 0.0262, pre: 501.3, gt: 527.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [253/800] Iter:[120/150], Time: 0.59, lr: 7.7178, Loss: 0.0264, pre: 627.4, gt: 662.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [253/800] Iter:[140/150], Time: 0.59, lr: 7.7156, Loss: 0.0268, pre: 1451.4, gt: 1438.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [254/800] Iter:[0/150], Time: 2.64, lr: 7.7145, Loss: 0.0613, pre: 5623.8, gt: 5898.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [254/800] Iter:[20/150], Time: 0.68, lr: 7.7123, Loss: 0.0295, pre: 664.7, gt: 622.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [254/800] Iter:[40/150], Time: 0.63, lr: 7.7101, Loss: 0.0298, pre: 602.1, gt: 736.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [254/800] Iter:[60/150], Time: 0.62, lr: 7.7079, Loss: 0.0288, pre: 977.7, gt: 830.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [254/800] Iter:[80/150], Time: 0.61, lr: 7.7057, Loss: 0.0292, pre: 3111.1, gt: 3770.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [254/800] Iter:[100/150], Time: 0.60, lr: 7.7035, Loss: 0.0284, pre: 1446.4, gt: 1920.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [254/800] Iter:[120/150], Time: 0.60, lr: 7.7013, Loss: 0.0286, pre: 441.1, gt: 412.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [254/800] Iter:[140/150], Time: 0.60, lr: 7.6991, Loss: 0.0281, pre: 849.7, gt: 839.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  116.19, Best_MAE:  104.1941 MSE:  181.6388,Best_MSE:  164.2538\n","Epoch: [255/800] Iter:[0/150], Time: 4.11, lr: 7.6980, Loss: 0.0192, pre: 885.3, gt: 710.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [255/800] Iter:[20/150], Time: 0.75, lr: 7.6958, Loss: 0.0246, pre: 1431.2, gt: 1553.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [255/800] Iter:[40/150], Time: 0.67, lr: 7.6936, Loss: 0.0263, pre: 3092.8, gt: 2782.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [255/800] Iter:[60/150], Time: 0.64, lr: 7.6914, Loss: 0.0292, pre: 2684.4, gt: 3250.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [255/800] Iter:[80/150], Time: 0.63, lr: 7.6892, Loss: 0.0280, pre: 1868.7, gt: 2032.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [255/800] Iter:[100/150], Time: 0.62, lr: 7.6870, Loss: 0.0286, pre: 2401.4, gt: 2144.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [255/800] Iter:[120/150], Time: 0.61, lr: 7.6848, Loss: 0.0283, pre: 497.0, gt: 609.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [255/800] Iter:[140/150], Time: 0.61, lr: 7.6826, Loss: 0.0286, pre: 751.6, gt: 867.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [256/800] Iter:[0/150], Time: 2.06, lr: 7.6815, Loss: 0.0264, pre: 1198.0, gt: 1500.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [256/800] Iter:[20/150], Time: 0.66, lr: 7.6792, Loss: 0.0292, pre: 2627.3, gt: 2755.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [256/800] Iter:[40/150], Time: 0.62, lr: 7.6770, Loss: 0.0286, pre: 981.5, gt: 819.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [256/800] Iter:[60/150], Time: 0.61, lr: 7.6748, Loss: 0.0302, pre: 1363.9, gt: 1753.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [256/800] Iter:[80/150], Time: 0.60, lr: 7.6726, Loss: 0.0295, pre: 1894.3, gt: 1118.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [256/800] Iter:[100/150], Time: 0.60, lr: 7.6704, Loss: 0.0286, pre: 2501.1, gt: 2563.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [256/800] Iter:[120/150], Time: 0.59, lr: 7.6682, Loss: 0.0284, pre: 265.6, gt: 284.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [256/800] Iter:[140/150], Time: 0.59, lr: 7.6660, Loss: 0.0281, pre: 2291.5, gt: 2337.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [257/800] Iter:[0/150], Time: 1.61, lr: 7.6649, Loss: 0.0413, pre: 3539.6, gt: 3854.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [257/800] Iter:[20/150], Time: 0.64, lr: 7.6627, Loss: 0.0284, pre: 498.1, gt: 514.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [257/800] Iter:[40/150], Time: 0.61, lr: 7.6604, Loss: 0.0291, pre: 912.2, gt: 1051.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [257/800] Iter:[60/150], Time: 0.60, lr: 7.6582, Loss: 0.0302, pre: 497.5, gt: 498.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [257/800] Iter:[80/150], Time: 0.60, lr: 7.6560, Loss: 0.0305, pre: 1267.0, gt: 1415.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [257/800] Iter:[100/150], Time: 0.59, lr: 7.6538, Loss: 0.0299, pre: 691.5, gt: 801.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [257/800] Iter:[120/150], Time: 0.59, lr: 7.6516, Loss: 0.0295, pre: 800.4, gt: 610.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [257/800] Iter:[140/150], Time: 0.59, lr: 7.6494, Loss: 0.0300, pre: 1035.1, gt: 1354.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  209.01, Best_MAE:  104.1941 MSE:  350.8282,Best_MSE:  164.2538\n","Epoch: [258/800] Iter:[0/150], Time: 3.48, lr: 7.6482, Loss: 0.0222, pre: 1748.3, gt: 1687.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [258/800] Iter:[20/150], Time: 0.72, lr: 7.6460, Loss: 0.0361, pre: 2086.0, gt: 2037.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [258/800] Iter:[40/150], Time: 0.65, lr: 7.6438, Loss: 0.0314, pre: 1039.8, gt: 1409.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [258/800] Iter:[60/150], Time: 0.63, lr: 7.6416, Loss: 0.0314, pre: 1524.5, gt: 1698.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [258/800] Iter:[80/150], Time: 0.62, lr: 7.6394, Loss: 0.0294, pre: 2330.7, gt: 2126.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [258/800] Iter:[100/150], Time: 0.61, lr: 7.6371, Loss: 0.0298, pre: 1546.9, gt: 1700.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [258/800] Iter:[120/150], Time: 0.61, lr: 7.6349, Loss: 0.0289, pre: 1073.9, gt: 1143.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [258/800] Iter:[140/150], Time: 0.60, lr: 7.6327, Loss: 0.0290, pre: 1986.5, gt: 1912.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [259/800] Iter:[0/150], Time: 2.07, lr: 7.6316, Loss: 0.0191, pre: 1493.4, gt: 1296.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [259/800] Iter:[20/150], Time: 0.65, lr: 7.6294, Loss: 0.0284, pre: 1057.0, gt: 971.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [259/800] Iter:[40/150], Time: 0.62, lr: 7.6271, Loss: 0.0272, pre: 1371.2, gt: 1388.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [259/800] Iter:[60/150], Time: 0.61, lr: 7.6249, Loss: 0.0278, pre: 1507.5, gt: 1686.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [259/800] Iter:[80/150], Time: 0.60, lr: 7.6227, Loss: 0.0284, pre: 1368.2, gt: 2068.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [259/800] Iter:[100/150], Time: 0.60, lr: 7.6205, Loss: 0.0279, pre: 1043.5, gt: 1014.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [259/800] Iter:[120/150], Time: 0.59, lr: 7.6182, Loss: 0.0274, pre: 865.4, gt: 934.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [259/800] Iter:[140/150], Time: 0.59, lr: 7.6160, Loss: 0.0274, pre: 1501.0, gt: 1619.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [260/800] Iter:[0/150], Time: 1.77, lr: 7.6149, Loss: 0.0130, pre: 382.0, gt: 383.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [260/800] Iter:[20/150], Time: 0.64, lr: 7.6126, Loss: 0.0240, pre: 865.9, gt: 812.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [260/800] Iter:[40/150], Time: 0.61, lr: 7.6104, Loss: 0.0252, pre: 1444.0, gt: 1864.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [260/800] Iter:[60/150], Time: 0.60, lr: 7.6082, Loss: 0.0249, pre: 472.7, gt: 649.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [260/800] Iter:[80/150], Time: 0.60, lr: 7.6060, Loss: 0.0249, pre: 2784.7, gt: 3040.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [260/800] Iter:[100/150], Time: 0.59, lr: 7.6037, Loss: 0.0263, pre: 1378.7, gt: 1226.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [260/800] Iter:[120/150], Time: 0.59, lr: 7.6015, Loss: 0.0276, pre: 517.0, gt: 547.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [260/800] Iter:[140/150], Time: 0.59, lr: 7.5993, Loss: 0.0277, pre: 3591.6, gt: 3770.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  146.54, Best_MAE:  104.1941 MSE:  261.7342,Best_MSE:  164.2538\n","Epoch: [261/800] Iter:[0/150], Time: 4.91, lr: 7.5981, Loss: 0.0392, pre: 2119.1, gt: 2602.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [261/800] Iter:[20/150], Time: 0.79, lr: 7.5959, Loss: 0.0292, pre: 1336.4, gt: 1124.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [261/800] Iter:[40/150], Time: 0.69, lr: 7.5937, Loss: 0.0263, pre: 2689.9, gt: 2140.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [261/800] Iter:[60/150], Time: 0.65, lr: 7.5914, Loss: 0.0272, pre: 631.9, gt: 553.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [261/800] Iter:[80/150], Time: 0.64, lr: 7.5892, Loss: 0.0283, pre: 947.2, gt: 1008.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [261/800] Iter:[100/150], Time: 0.62, lr: 7.5869, Loss: 0.0286, pre: 2295.4, gt: 2312.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [261/800] Iter:[120/150], Time: 0.62, lr: 7.5847, Loss: 0.0281, pre: 1127.5, gt: 1252.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [261/800] Iter:[140/150], Time: 0.61, lr: 7.5825, Loss: 0.0284, pre: 1147.6, gt: 1340.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [262/800] Iter:[0/150], Time: 2.05, lr: 7.5814, Loss: 0.0530, pre: 3696.5, gt: 4141.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [262/800] Iter:[20/150], Time: 0.65, lr: 7.5791, Loss: 0.0271, pre: 467.9, gt: 615.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [262/800] Iter:[40/150], Time: 0.62, lr: 7.5769, Loss: 0.0267, pre: 2325.3, gt: 2574.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [262/800] Iter:[60/150], Time: 0.61, lr: 7.5746, Loss: 0.0280, pre: 2102.8, gt: 2227.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [262/800] Iter:[80/150], Time: 0.60, lr: 7.5724, Loss: 0.0282, pre: 1137.5, gt: 992.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [262/800] Iter:[100/150], Time: 0.60, lr: 7.5701, Loss: 0.0285, pre: 1140.1, gt: 1207.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [262/800] Iter:[120/150], Time: 0.59, lr: 7.5679, Loss: 0.0284, pre: 2220.9, gt: 2187.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [262/800] Iter:[140/150], Time: 0.59, lr: 7.5656, Loss: 0.0293, pre: 605.3, gt: 926.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [263/800] Iter:[0/150], Time: 2.12, lr: 7.5645, Loss: 0.0225, pre: 892.5, gt: 1228.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [263/800] Iter:[20/150], Time: 0.66, lr: 7.5623, Loss: 0.0299, pre: 5870.6, gt: 4584.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [263/800] Iter:[40/150], Time: 0.62, lr: 7.5600, Loss: 0.0277, pre: 1572.4, gt: 1505.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [263/800] Iter:[60/150], Time: 0.61, lr: 7.5578, Loss: 0.0278, pre: 3571.7, gt: 4172.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [263/800] Iter:[80/150], Time: 0.60, lr: 7.5555, Loss: 0.0273, pre: 1111.6, gt: 837.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [263/800] Iter:[100/150], Time: 0.60, lr: 7.5533, Loss: 0.0271, pre: 702.2, gt: 441.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [263/800] Iter:[120/150], Time: 0.60, lr: 7.5510, Loss: 0.0272, pre: 1568.1, gt: 1604.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [263/800] Iter:[140/150], Time: 0.59, lr: 7.5488, Loss: 0.0276, pre: 1620.8, gt: 1590.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  94.07, Best_MAE:  94.0695 MSE:  154.4884,Best_MSE:  154.4884\n","Epoch: [264/800] Iter:[0/150], Time: 4.93, lr: 7.5477, Loss: 0.0206, pre: 1284.4, gt: 1368.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [264/800] Iter:[20/150], Time: 0.80, lr: 7.5454, Loss: 0.0257, pre: 1461.9, gt: 1343.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [264/800] Iter:[40/150], Time: 0.69, lr: 7.5432, Loss: 0.0259, pre: 728.1, gt: 765.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [264/800] Iter:[60/150], Time: 0.66, lr: 7.5409, Loss: 0.0275, pre: 1259.3, gt: 1111.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [264/800] Iter:[80/150], Time: 0.64, lr: 7.5387, Loss: 0.0284, pre: 2691.7, gt: 3272.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [264/800] Iter:[100/150], Time: 0.63, lr: 7.5364, Loss: 0.0282, pre: 2300.4, gt: 2106.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [264/800] Iter:[120/150], Time: 0.62, lr: 7.5341, Loss: 0.0284, pre: 2064.4, gt: 2096.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [264/800] Iter:[140/150], Time: 0.61, lr: 7.5319, Loss: 0.0284, pre: 1421.2, gt: 1678.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [265/800] Iter:[0/150], Time: 1.97, lr: 7.5308, Loss: 0.0245, pre: 2026.5, gt: 2587.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [265/800] Iter:[20/150], Time: 0.65, lr: 7.5285, Loss: 0.0269, pre: 731.3, gt: 822.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [265/800] Iter:[40/150], Time: 0.62, lr: 7.5262, Loss: 0.0260, pre: 2777.6, gt: 2602.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [265/800] Iter:[60/150], Time: 0.61, lr: 7.5240, Loss: 0.0265, pre: 1818.1, gt: 1734.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [265/800] Iter:[80/150], Time: 0.60, lr: 7.5217, Loss: 0.0269, pre: 1271.1, gt: 1454.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [265/800] Iter:[100/150], Time: 0.60, lr: 7.5195, Loss: 0.0271, pre: 1932.5, gt: 2349.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [265/800] Iter:[120/150], Time: 0.60, lr: 7.5172, Loss: 0.0272, pre: 692.3, gt: 911.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [265/800] Iter:[140/150], Time: 0.59, lr: 7.5149, Loss: 0.0275, pre: 885.9, gt: 769.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [266/800] Iter:[0/150], Time: 2.20, lr: 7.5138, Loss: 0.0239, pre: 1258.2, gt: 1326.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [266/800] Iter:[20/150], Time: 0.66, lr: 7.5116, Loss: 0.0261, pre: 1693.1, gt: 1936.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [266/800] Iter:[40/150], Time: 0.62, lr: 7.5093, Loss: 0.0274, pre: 3018.3, gt: 2532.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.94,acc1:0.00\n","Epoch: [266/800] Iter:[60/150], Time: 0.61, lr: 7.5070, Loss: 0.0261, pre: 1272.2, gt: 1489.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [266/800] Iter:[80/150], Time: 0.60, lr: 7.5048, Loss: 0.0262, pre: 1867.4, gt: 1977.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [266/800] Iter:[100/150], Time: 0.60, lr: 7.5025, Loss: 0.0278, pre: 3484.4, gt: 3661.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [266/800] Iter:[120/150], Time: 0.60, lr: 7.5002, Loss: 0.0280, pre: 1521.3, gt: 1343.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [266/800] Iter:[140/150], Time: 0.59, lr: 7.4980, Loss: 0.0281, pre: 1636.8, gt: 2398.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  361.50, Best_MAE:  94.0695 MSE:  550.3902,Best_MSE:  154.4884\n","Epoch: [267/800] Iter:[0/150], Time: 4.70, lr: 7.4968, Loss: 0.0139, pre: 1311.3, gt: 1074.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [267/800] Iter:[20/150], Time: 0.78, lr: 7.4946, Loss: 0.0262, pre: 881.3, gt: 678.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [267/800] Iter:[40/150], Time: 0.68, lr: 7.4923, Loss: 0.0268, pre: 2120.3, gt: 1680.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [267/800] Iter:[60/150], Time: 0.65, lr: 7.4900, Loss: 0.0269, pre: 564.3, gt: 478.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [267/800] Iter:[80/150], Time: 0.63, lr: 7.4878, Loss: 0.0271, pre: 2206.3, gt: 1959.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [267/800] Iter:[100/150], Time: 0.62, lr: 7.4855, Loss: 0.0281, pre: 2050.9, gt: 2140.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [267/800] Iter:[120/150], Time: 0.62, lr: 7.4832, Loss: 0.0280, pre: 1661.9, gt: 945.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [267/800] Iter:[140/150], Time: 0.61, lr: 7.4810, Loss: 0.0284, pre: 1742.2, gt: 1495.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [268/800] Iter:[0/150], Time: 2.27, lr: 7.4798, Loss: 0.0234, pre: 1509.4, gt: 1733.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [268/800] Iter:[20/150], Time: 0.66, lr: 7.4775, Loss: 0.0245, pre: 1122.9, gt: 1158.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [268/800] Iter:[40/150], Time: 0.62, lr: 7.4753, Loss: 0.0266, pre: 1062.9, gt: 1148.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [268/800] Iter:[60/150], Time: 0.61, lr: 7.4730, Loss: 0.0262, pre: 907.4, gt: 1238.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [268/800] Iter:[80/150], Time: 0.60, lr: 7.4707, Loss: 0.0272, pre: 2138.0, gt: 1921.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [268/800] Iter:[100/150], Time: 0.60, lr: 7.4684, Loss: 0.0268, pre: 1556.4, gt: 1780.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [268/800] Iter:[120/150], Time: 0.60, lr: 7.4662, Loss: 0.0270, pre: 1884.8, gt: 2172.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [268/800] Iter:[140/150], Time: 0.59, lr: 7.4639, Loss: 0.0276, pre: 1752.2, gt: 1878.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [269/800] Iter:[0/150], Time: 1.84, lr: 7.4628, Loss: 0.0277, pre: 2502.6, gt: 2355.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [269/800] Iter:[20/150], Time: 0.65, lr: 7.4605, Loss: 0.0266, pre: 1719.1, gt: 1777.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [269/800] Iter:[40/150], Time: 0.62, lr: 7.4582, Loss: 0.0291, pre: 361.4, gt: 442.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [269/800] Iter:[60/150], Time: 0.61, lr: 7.4559, Loss: 0.0277, pre: 662.7, gt: 818.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [269/800] Iter:[80/150], Time: 0.60, lr: 7.4536, Loss: 0.0271, pre: 2361.7, gt: 1596.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [269/800] Iter:[100/150], Time: 0.60, lr: 7.4514, Loss: 0.0267, pre: 3863.0, gt: 4956.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.94,acc1:0.00\n","Epoch: [269/800] Iter:[120/150], Time: 0.59, lr: 7.4491, Loss: 0.0272, pre: 989.0, gt: 1217.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [269/800] Iter:[140/150], Time: 0.59, lr: 7.4468, Loss: 0.0276, pre: 3801.4, gt: 5338.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  140.88, Best_MAE:  94.0695 MSE:  267.7326,Best_MSE:  154.4884\n","Epoch: [270/800] Iter:[0/150], Time: 4.38, lr: 7.4457, Loss: 0.0448, pre: 3331.1, gt: 3099.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [270/800] Iter:[20/150], Time: 0.76, lr: 7.4434, Loss: 0.0260, pre: 2023.0, gt: 2077.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [270/800] Iter:[40/150], Time: 0.68, lr: 7.4411, Loss: 0.0287, pre: 1542.8, gt: 2023.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.94,acc1:0.00\n","Epoch: [270/800] Iter:[60/150], Time: 0.64, lr: 7.4388, Loss: 0.0288, pre: 3369.2, gt: 4313.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [270/800] Iter:[80/150], Time: 0.63, lr: 7.4365, Loss: 0.0295, pre: 1115.9, gt: 1174.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [270/800] Iter:[100/150], Time: 0.62, lr: 7.4342, Loss: 0.0286, pre: 1026.5, gt: 993.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.94,acc1:0.00\n","Epoch: [270/800] Iter:[120/150], Time: 0.61, lr: 7.4320, Loss: 0.0285, pre: 2659.4, gt: 2523.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [270/800] Iter:[140/150], Time: 0.61, lr: 7.4297, Loss: 0.0275, pre: 1736.1, gt: 2111.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [271/800] Iter:[0/150], Time: 2.28, lr: 7.4285, Loss: 0.0640, pre: 4376.2, gt: 5072.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [271/800] Iter:[20/150], Time: 0.66, lr: 7.4262, Loss: 0.0276, pre: 2083.2, gt: 2612.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [271/800] Iter:[40/150], Time: 0.62, lr: 7.4240, Loss: 0.0271, pre: 3701.8, gt: 3359.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [271/800] Iter:[60/150], Time: 0.61, lr: 7.4217, Loss: 0.0284, pre: 1250.5, gt: 1221.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [271/800] Iter:[80/150], Time: 0.60, lr: 7.4194, Loss: 0.0286, pre: 1612.8, gt: 1576.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [271/800] Iter:[100/150], Time: 0.60, lr: 7.4171, Loss: 0.0286, pre: 1354.3, gt: 1522.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [271/800] Iter:[120/150], Time: 0.60, lr: 7.4148, Loss: 0.0292, pre: 1119.1, gt: 1196.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [271/800] Iter:[140/150], Time: 0.59, lr: 7.4125, Loss: 0.0292, pre: 813.6, gt: 810.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [272/800] Iter:[0/150], Time: 1.75, lr: 7.4114, Loss: 0.0315, pre: 1565.1, gt: 2054.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [272/800] Iter:[20/150], Time: 0.64, lr: 7.4091, Loss: 0.0297, pre: 983.3, gt: 1179.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [272/800] Iter:[40/150], Time: 0.61, lr: 7.4068, Loss: 0.0257, pre: 755.5, gt: 817.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [272/800] Iter:[60/150], Time: 0.60, lr: 7.4045, Loss: 0.0257, pre: 1139.8, gt: 1103.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [272/800] Iter:[80/150], Time: 0.60, lr: 7.4022, Loss: 0.0274, pre: 2340.2, gt: 2434.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [272/800] Iter:[100/150], Time: 0.59, lr: 7.3999, Loss: 0.0267, pre: 1617.3, gt: 1628.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [272/800] Iter:[120/150], Time: 0.59, lr: 7.3976, Loss: 0.0270, pre: 1781.3, gt: 2063.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [272/800] Iter:[140/150], Time: 0.59, lr: 7.3953, Loss: 0.0273, pre: 356.7, gt: 328.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  158.43, Best_MAE:  94.0695 MSE:  284.7347,Best_MSE:  154.4884\n","Epoch: [273/800] Iter:[0/150], Time: 4.09, lr: 7.3942, Loss: 0.0336, pre: 2572.2, gt: 2514.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [273/800] Iter:[20/150], Time: 0.75, lr: 7.3919, Loss: 0.0313, pre: 2541.7, gt: 2939.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [273/800] Iter:[40/150], Time: 0.67, lr: 7.3896, Loss: 0.0292, pre: 1456.2, gt: 1382.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [273/800] Iter:[60/150], Time: 0.64, lr: 7.3873, Loss: 0.0294, pre: 1703.2, gt: 1973.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [273/800] Iter:[80/150], Time: 0.63, lr: 7.3850, Loss: 0.0282, pre: 610.9, gt: 582.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [273/800] Iter:[100/150], Time: 0.62, lr: 7.3827, Loss: 0.0281, pre: 1265.9, gt: 1274.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [273/800] Iter:[120/150], Time: 0.61, lr: 7.3804, Loss: 0.0278, pre: 2704.5, gt: 2954.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [273/800] Iter:[140/150], Time: 0.61, lr: 7.3781, Loss: 0.0282, pre: 1681.1, gt: 1370.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [274/800] Iter:[0/150], Time: 2.25, lr: 7.3769, Loss: 0.0232, pre: 1796.5, gt: 1885.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [274/800] Iter:[20/150], Time: 0.66, lr: 7.3746, Loss: 0.0271, pre: 5543.6, gt: 5532.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [274/800] Iter:[40/150], Time: 0.62, lr: 7.3723, Loss: 0.0265, pre: 4109.7, gt: 2547.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [274/800] Iter:[60/150], Time: 0.61, lr: 7.3700, Loss: 0.0282, pre: 6512.1, gt: 4753.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [274/800] Iter:[80/150], Time: 0.60, lr: 7.3677, Loss: 0.0277, pre: 2000.9, gt: 2149.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [274/800] Iter:[100/150], Time: 0.60, lr: 7.3654, Loss: 0.0280, pre: 3784.4, gt: 4781.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [274/800] Iter:[120/150], Time: 0.60, lr: 7.3631, Loss: 0.0282, pre: 5922.4, gt: 5992.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [274/800] Iter:[140/150], Time: 0.59, lr: 7.3608, Loss: 0.0284, pre: 1044.3, gt: 929.0,acc:0.88, accx8:0.93,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [275/800] Iter:[0/150], Time: 2.13, lr: 7.3596, Loss: 0.0387, pre: 1800.8, gt: 1980.0,acc:0.88, accx8:0.93,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [275/800] Iter:[20/150], Time: 0.66, lr: 7.3573, Loss: 0.0277, pre: 3977.8, gt: 3946.0,acc:0.88, accx8:0.93,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [275/800] Iter:[40/150], Time: 0.62, lr: 7.3550, Loss: 0.0294, pre: 353.7, gt: 408.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [275/800] Iter:[60/150], Time: 0.61, lr: 7.3527, Loss: 0.0291, pre: 2530.5, gt: 2765.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [275/800] Iter:[80/150], Time: 0.60, lr: 7.3504, Loss: 0.0284, pre: 471.4, gt: 445.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [275/800] Iter:[100/150], Time: 0.60, lr: 7.3481, Loss: 0.0274, pre: 368.2, gt: 461.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [275/800] Iter:[120/150], Time: 0.60, lr: 7.3458, Loss: 0.0270, pre: 733.7, gt: 900.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [275/800] Iter:[140/150], Time: 0.59, lr: 7.3435, Loss: 0.0269, pre: 1205.3, gt: 1018.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  122.42, Best_MAE:  94.0695 MSE:  225.9049,Best_MSE:  154.4884\n","Epoch: [276/800] Iter:[0/150], Time: 4.40, lr: 7.3423, Loss: 0.0176, pre: 364.4, gt: 377.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [276/800] Iter:[20/150], Time: 0.77, lr: 7.3400, Loss: 0.0253, pre: 1478.1, gt: 1689.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [276/800] Iter:[40/150], Time: 0.68, lr: 7.3377, Loss: 0.0268, pre: 1209.8, gt: 1319.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [276/800] Iter:[60/150], Time: 0.65, lr: 7.3354, Loss: 0.0276, pre: 1150.4, gt: 1233.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [276/800] Iter:[80/150], Time: 0.63, lr: 7.3331, Loss: 0.0275, pre: 314.0, gt: 293.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.94,acc1:0.00\n","Epoch: [276/800] Iter:[100/150], Time: 0.62, lr: 7.3307, Loss: 0.0270, pre: 1522.0, gt: 1322.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.94,acc1:0.00\n","Epoch: [276/800] Iter:[120/150], Time: 0.61, lr: 7.3284, Loss: 0.0278, pre: 1191.4, gt: 1129.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.94,acc1:0.00\n","Epoch: [276/800] Iter:[140/150], Time: 0.61, lr: 7.3261, Loss: 0.0280, pre: 1822.4, gt: 2111.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.94,acc1:0.00\n","Epoch: [277/800] Iter:[0/150], Time: 1.94, lr: 7.3250, Loss: 0.0233, pre: 911.6, gt: 1111.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.94,acc1:0.00\n","Epoch: [277/800] Iter:[20/150], Time: 0.66, lr: 7.3226, Loss: 0.0276, pre: 756.1, gt: 945.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [277/800] Iter:[40/150], Time: 0.62, lr: 7.3203, Loss: 0.0304, pre: 3174.5, gt: 2950.0,acc:0.88, accx8:0.92,  accx16:0.93,accx32:0.94,acc1:0.00\n","Epoch: [277/800] Iter:[60/150], Time: 0.61, lr: 7.3180, Loss: 0.0322, pre: 357.3, gt: 330.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.94,acc1:0.00\n","Epoch: [277/800] Iter:[80/150], Time: 0.60, lr: 7.3157, Loss: 0.0321, pre: 2853.9, gt: 3187.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.94,acc1:0.00\n","Epoch: [277/800] Iter:[100/150], Time: 0.60, lr: 7.3134, Loss: 0.0320, pre: 769.2, gt: 696.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.94,acc1:0.00\n","Epoch: [277/800] Iter:[120/150], Time: 0.60, lr: 7.3110, Loss: 0.0310, pre: 1849.4, gt: 1786.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.94,acc1:0.00\n","Epoch: [277/800] Iter:[140/150], Time: 0.59, lr: 7.3087, Loss: 0.0306, pre: 971.3, gt: 934.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.94,acc1:0.00\n","Epoch: [278/800] Iter:[0/150], Time: 1.80, lr: 7.3076, Loss: 0.0234, pre: 929.8, gt: 938.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.94,acc1:0.00\n","Epoch: [278/800] Iter:[20/150], Time: 0.65, lr: 7.3052, Loss: 0.0368, pre: 4517.8, gt: 7045.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [278/800] Iter:[40/150], Time: 0.62, lr: 7.3029, Loss: 0.0324, pre: 1766.1, gt: 1962.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [278/800] Iter:[60/150], Time: 0.61, lr: 7.3006, Loss: 0.0302, pre: 1202.1, gt: 1219.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.93,acc1:0.00\n","Epoch: [278/800] Iter:[80/150], Time: 0.60, lr: 7.2983, Loss: 0.0299, pre: 1078.0, gt: 1068.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.94,acc1:0.00\n","Epoch: [278/800] Iter:[100/150], Time: 0.60, lr: 7.2960, Loss: 0.0299, pre: 1468.2, gt: 1620.0,acc:0.87, accx8:0.92,  accx16:0.93,accx32:0.94,acc1:0.00\n","Epoch: [278/800] Iter:[120/150], Time: 0.59, lr: 7.2936, Loss: 0.0301, pre: 1164.7, gt: 1445.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [278/800] Iter:[140/150], Time: 0.59, lr: 7.2913, Loss: 0.0293, pre: 932.8, gt: 955.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  104.08, Best_MAE:  94.0695 MSE:  184.7782,Best_MSE:  154.4884\n","Epoch: [279/800] Iter:[0/150], Time: 4.05, lr: 7.2901, Loss: 0.0492, pre: 3018.7, gt: 2848.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [279/800] Iter:[20/150], Time: 0.75, lr: 7.2878, Loss: 0.0281, pre: 2628.1, gt: 2947.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [279/800] Iter:[40/150], Time: 0.67, lr: 7.2855, Loss: 0.0288, pre: 3130.9, gt: 3039.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [279/800] Iter:[60/150], Time: 0.64, lr: 7.2832, Loss: 0.0301, pre: 1290.4, gt: 1451.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [279/800] Iter:[80/150], Time: 0.63, lr: 7.2808, Loss: 0.0294, pre: 972.5, gt: 1284.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [279/800] Iter:[100/150], Time: 0.62, lr: 7.2785, Loss: 0.0287, pre: 1774.7, gt: 1709.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [279/800] Iter:[120/150], Time: 0.61, lr: 7.2762, Loss: 0.0284, pre: 1582.3, gt: 1722.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [279/800] Iter:[140/150], Time: 0.61, lr: 7.2738, Loss: 0.0281, pre: 2190.4, gt: 2288.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [280/800] Iter:[0/150], Time: 1.90, lr: 7.2727, Loss: 0.0291, pre: 1439.9, gt: 1466.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [280/800] Iter:[20/150], Time: 0.65, lr: 7.2704, Loss: 0.0279, pre: 4655.3, gt: 4482.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [280/800] Iter:[40/150], Time: 0.62, lr: 7.2680, Loss: 0.0280, pre: 1147.5, gt: 995.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [280/800] Iter:[60/150], Time: 0.61, lr: 7.2657, Loss: 0.0284, pre: 660.3, gt: 895.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [280/800] Iter:[80/150], Time: 0.60, lr: 7.2634, Loss: 0.0278, pre: 1875.8, gt: 2028.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [280/800] Iter:[100/150], Time: 0.60, lr: 7.2610, Loss: 0.0274, pre: 1355.3, gt: 1245.0,acc:0.87, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [280/800] Iter:[120/150], Time: 0.59, lr: 7.2587, Loss: 0.0277, pre: 1190.8, gt: 994.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [280/800] Iter:[140/150], Time: 0.59, lr: 7.2564, Loss: 0.0277, pre: 2383.0, gt: 2663.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [281/800] Iter:[0/150], Time: 1.96, lr: 7.2552, Loss: 0.0435, pre: 2974.2, gt: 2798.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [281/800] Iter:[20/150], Time: 0.65, lr: 7.2529, Loss: 0.0282, pre: 698.9, gt: 445.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [281/800] Iter:[40/150], Time: 0.62, lr: 7.2505, Loss: 0.0271, pre: 962.0, gt: 920.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [281/800] Iter:[60/150], Time: 0.61, lr: 7.2482, Loss: 0.0296, pre: 1072.4, gt: 882.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [281/800] Iter:[80/150], Time: 0.60, lr: 7.2458, Loss: 0.0297, pre: 1615.0, gt: 1560.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [281/800] Iter:[100/150], Time: 0.60, lr: 7.2435, Loss: 0.0292, pre: 677.4, gt: 745.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [281/800] Iter:[120/150], Time: 0.60, lr: 7.2412, Loss: 0.0284, pre: 620.2, gt: 641.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [281/800] Iter:[140/150], Time: 0.59, lr: 7.2388, Loss: 0.0279, pre: 456.6, gt: 309.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  121.59, Best_MAE:  94.0695 MSE:  224.4038,Best_MSE:  154.4884\n","Epoch: [282/800] Iter:[0/150], Time: 4.34, lr: 7.2377, Loss: 0.0215, pre: 1271.3, gt: 1132.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [282/800] Iter:[20/150], Time: 0.77, lr: 7.2353, Loss: 0.0283, pre: 1098.7, gt: 1247.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [282/800] Iter:[40/150], Time: 0.68, lr: 7.2330, Loss: 0.0280, pre: 466.0, gt: 409.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [282/800] Iter:[60/150], Time: 0.65, lr: 7.2306, Loss: 0.0269, pre: 1045.5, gt: 1121.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [282/800] Iter:[80/150], Time: 0.63, lr: 7.2283, Loss: 0.0255, pre: 602.6, gt: 562.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [282/800] Iter:[100/150], Time: 0.62, lr: 7.2260, Loss: 0.0266, pre: 856.8, gt: 738.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [282/800] Iter:[120/150], Time: 0.61, lr: 7.2236, Loss: 0.0261, pre: 1437.5, gt: 1406.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [282/800] Iter:[140/150], Time: 0.61, lr: 7.2213, Loss: 0.0263, pre: 448.1, gt: 386.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [283/800] Iter:[0/150], Time: 2.25, lr: 7.2201, Loss: 0.0263, pre: 884.6, gt: 1135.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [283/800] Iter:[20/150], Time: 0.66, lr: 7.2177, Loss: 0.0288, pre: 1003.4, gt: 923.0,acc:0.88, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [283/800] Iter:[40/150], Time: 0.62, lr: 7.2154, Loss: 0.0280, pre: 1230.8, gt: 1151.0,acc:0.89, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [283/800] Iter:[60/150], Time: 0.61, lr: 7.2131, Loss: 0.0280, pre: 2070.7, gt: 2154.0,acc:0.89, accx8:0.92,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [283/800] Iter:[80/150], Time: 0.60, lr: 7.2107, Loss: 0.0273, pre: 1516.1, gt: 1672.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [283/800] Iter:[100/150], Time: 0.60, lr: 7.2084, Loss: 0.0275, pre: 2500.7, gt: 2324.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [283/800] Iter:[120/150], Time: 0.60, lr: 7.2060, Loss: 0.0276, pre: 2094.9, gt: 2265.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [283/800] Iter:[140/150], Time: 0.59, lr: 7.2037, Loss: 0.0281, pre: 3521.8, gt: 3288.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [284/800] Iter:[0/150], Time: 1.98, lr: 7.2025, Loss: 0.0260, pre: 1283.5, gt: 1305.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [284/800] Iter:[20/150], Time: 0.65, lr: 7.2001, Loss: 0.0277, pre: 3111.5, gt: 3271.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [284/800] Iter:[40/150], Time: 0.62, lr: 7.1978, Loss: 0.0283, pre: 896.3, gt: 874.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [284/800] Iter:[60/150], Time: 0.60, lr: 7.1954, Loss: 0.0271, pre: 5309.7, gt: 4121.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [284/800] Iter:[80/150], Time: 0.60, lr: 7.1931, Loss: 0.0267, pre: 2194.8, gt: 2535.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [284/800] Iter:[100/150], Time: 0.59, lr: 7.1907, Loss: 0.0270, pre: 487.4, gt: 592.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [284/800] Iter:[120/150], Time: 0.59, lr: 7.1884, Loss: 0.0277, pre: 3248.9, gt: 3161.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [284/800] Iter:[140/150], Time: 0.59, lr: 7.1860, Loss: 0.0280, pre: 973.1, gt: 891.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  93.36, Best_MAE:  93.3597 MSE:  157.4444,Best_MSE:  154.4884\n","Epoch: [285/800] Iter:[0/150], Time: 5.32, lr: 7.1849, Loss: 0.0190, pre: 1034.9, gt: 1127.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [285/800] Iter:[20/150], Time: 0.81, lr: 7.1825, Loss: 0.0282, pre: 1885.5, gt: 2388.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [285/800] Iter:[40/150], Time: 0.70, lr: 7.1802, Loss: 0.0289, pre: 3108.6, gt: 3094.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [285/800] Iter:[60/150], Time: 0.66, lr: 7.1778, Loss: 0.0295, pre: 2168.5, gt: 2251.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [285/800] Iter:[80/150], Time: 0.64, lr: 7.1754, Loss: 0.0298, pre: 1620.9, gt: 1483.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [285/800] Iter:[100/150], Time: 0.63, lr: 7.1731, Loss: 0.0295, pre: 337.9, gt: 261.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [285/800] Iter:[120/150], Time: 0.62, lr: 7.1707, Loss: 0.0292, pre: 1965.6, gt: 2242.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [285/800] Iter:[140/150], Time: 0.62, lr: 7.1684, Loss: 0.0293, pre: 363.5, gt: 413.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [286/800] Iter:[0/150], Time: 2.04, lr: 7.1672, Loss: 0.0267, pre: 2408.0, gt: 2571.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [286/800] Iter:[20/150], Time: 0.65, lr: 7.1648, Loss: 0.0290, pre: 1133.4, gt: 1016.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [286/800] Iter:[40/150], Time: 0.62, lr: 7.1625, Loss: 0.0272, pre: 999.4, gt: 919.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [286/800] Iter:[60/150], Time: 0.61, lr: 7.1601, Loss: 0.0271, pre: 883.5, gt: 841.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [286/800] Iter:[80/150], Time: 0.60, lr: 7.1578, Loss: 0.0274, pre: 787.2, gt: 660.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [286/800] Iter:[100/150], Time: 0.60, lr: 7.1554, Loss: 0.0278, pre: 1264.3, gt: 1377.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [286/800] Iter:[120/150], Time: 0.59, lr: 7.1530, Loss: 0.0275, pre: 1304.9, gt: 1729.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [286/800] Iter:[140/150], Time: 0.59, lr: 7.1507, Loss: 0.0272, pre: 1198.8, gt: 1317.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [287/800] Iter:[0/150], Time: 1.80, lr: 7.1495, Loss: 0.0229, pre: 1549.8, gt: 1750.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [287/800] Iter:[20/150], Time: 0.64, lr: 7.1471, Loss: 0.0331, pre: 1379.0, gt: 1493.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [287/800] Iter:[40/150], Time: 0.61, lr: 7.1448, Loss: 0.0294, pre: 2081.8, gt: 1986.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [287/800] Iter:[60/150], Time: 0.60, lr: 7.1424, Loss: 0.0306, pre: 2106.8, gt: 2470.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [287/800] Iter:[80/150], Time: 0.60, lr: 7.1400, Loss: 0.0294, pre: 691.5, gt: 769.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [287/800] Iter:[100/150], Time: 0.59, lr: 7.1377, Loss: 0.0293, pre: 1366.1, gt: 1417.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [287/800] Iter:[120/150], Time: 0.59, lr: 7.1353, Loss: 0.0287, pre: 2171.6, gt: 2125.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [287/800] Iter:[140/150], Time: 0.59, lr: 7.1330, Loss: 0.0295, pre: 5005.5, gt: 5821.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  117.16, Best_MAE:  93.3597 MSE:  186.6778,Best_MSE:  154.4884\n","Epoch: [288/800] Iter:[0/150], Time: 4.57, lr: 7.1318, Loss: 0.0376, pre: 2394.1, gt: 2586.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [288/800] Iter:[20/150], Time: 0.78, lr: 7.1294, Loss: 0.0266, pre: 1547.2, gt: 1399.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [288/800] Iter:[40/150], Time: 0.68, lr: 7.1270, Loss: 0.0293, pre: 3590.3, gt: 3547.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [288/800] Iter:[60/150], Time: 0.65, lr: 7.1247, Loss: 0.0274, pre: 771.3, gt: 739.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [288/800] Iter:[80/150], Time: 0.63, lr: 7.1223, Loss: 0.0272, pre: 1210.7, gt: 1652.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [288/800] Iter:[100/150], Time: 0.62, lr: 7.1199, Loss: 0.0277, pre: 1444.6, gt: 1830.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [288/800] Iter:[120/150], Time: 0.62, lr: 7.1176, Loss: 0.0280, pre: 658.3, gt: 392.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [288/800] Iter:[140/150], Time: 0.61, lr: 7.1152, Loss: 0.0285, pre: 808.2, gt: 780.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [289/800] Iter:[0/150], Time: 1.79, lr: 7.1140, Loss: 0.0186, pre: 1375.8, gt: 1490.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [289/800] Iter:[20/150], Time: 0.64, lr: 7.1116, Loss: 0.0268, pre: 1750.0, gt: 2362.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [289/800] Iter:[40/150], Time: 0.61, lr: 7.1093, Loss: 0.0263, pre: 1846.0, gt: 1833.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [289/800] Iter:[60/150], Time: 0.60, lr: 7.1069, Loss: 0.0264, pre: 682.6, gt: 887.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [289/800] Iter:[80/150], Time: 0.60, lr: 7.1045, Loss: 0.0266, pre: 1374.3, gt: 1400.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [289/800] Iter:[100/150], Time: 0.59, lr: 7.1021, Loss: 0.0268, pre: 1040.8, gt: 930.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [289/800] Iter:[120/150], Time: 0.59, lr: 7.0998, Loss: 0.0272, pre: 1452.2, gt: 1512.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [289/800] Iter:[140/150], Time: 0.59, lr: 7.0974, Loss: 0.0276, pre: 816.7, gt: 809.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [290/800] Iter:[0/150], Time: 1.89, lr: 7.0962, Loss: 0.0211, pre: 780.6, gt: 870.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [290/800] Iter:[20/150], Time: 0.64, lr: 7.0938, Loss: 0.0281, pre: 1403.9, gt: 1605.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [290/800] Iter:[40/150], Time: 0.61, lr: 7.0915, Loss: 0.0273, pre: 802.6, gt: 674.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [290/800] Iter:[60/150], Time: 0.60, lr: 7.0891, Loss: 0.0277, pre: 4085.4, gt: 4264.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [290/800] Iter:[80/150], Time: 0.60, lr: 7.0867, Loss: 0.0285, pre: 1113.8, gt: 1194.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [290/800] Iter:[100/150], Time: 0.59, lr: 7.0843, Loss: 0.0295, pre: 1278.4, gt: 1179.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [290/800] Iter:[120/150], Time: 0.59, lr: 7.0819, Loss: 0.0293, pre: 827.9, gt: 857.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [290/800] Iter:[140/150], Time: 0.59, lr: 7.0796, Loss: 0.0297, pre: 2578.3, gt: 2501.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  121.15, Best_MAE:  93.3597 MSE:  192.7825,Best_MSE:  154.4884\n","Epoch: [291/800] Iter:[0/150], Time: 4.77, lr: 7.0784, Loss: 0.0141, pre: 536.0, gt: 589.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [291/800] Iter:[20/150], Time: 0.79, lr: 7.0760, Loss: 0.0284, pre: 506.3, gt: 409.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [291/800] Iter:[40/150], Time: 0.69, lr: 7.0736, Loss: 0.0278, pre: 606.8, gt: 758.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [291/800] Iter:[60/150], Time: 0.65, lr: 7.0712, Loss: 0.0270, pre: 2068.2, gt: 2190.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [291/800] Iter:[80/150], Time: 0.64, lr: 7.0689, Loss: 0.0268, pre: 820.2, gt: 790.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [291/800] Iter:[100/150], Time: 0.63, lr: 7.0665, Loss: 0.0267, pre: 1147.7, gt: 870.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [291/800] Iter:[120/150], Time: 0.62, lr: 7.0641, Loss: 0.0268, pre: 856.0, gt: 838.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [291/800] Iter:[140/150], Time: 0.61, lr: 7.0617, Loss: 0.0268, pre: 1340.4, gt: 1535.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [292/800] Iter:[0/150], Time: 2.18, lr: 7.0605, Loss: 0.0168, pre: 941.4, gt: 1086.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [292/800] Iter:[20/150], Time: 0.66, lr: 7.0581, Loss: 0.0290, pre: 426.1, gt: 421.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [292/800] Iter:[40/150], Time: 0.62, lr: 7.0557, Loss: 0.0280, pre: 994.3, gt: 1290.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [292/800] Iter:[60/150], Time: 0.61, lr: 7.0534, Loss: 0.0271, pre: 1502.7, gt: 1468.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [292/800] Iter:[80/150], Time: 0.60, lr: 7.0510, Loss: 0.0263, pre: 573.4, gt: 489.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [292/800] Iter:[100/150], Time: 0.60, lr: 7.0486, Loss: 0.0272, pre: 612.1, gt: 779.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [292/800] Iter:[120/150], Time: 0.60, lr: 7.0462, Loss: 0.0266, pre: 1390.1, gt: 1411.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [292/800] Iter:[140/150], Time: 0.60, lr: 7.0438, Loss: 0.0269, pre: 1293.8, gt: 1201.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [293/800] Iter:[0/150], Time: 2.25, lr: 7.0426, Loss: 0.0218, pre: 1140.2, gt: 1206.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [293/800] Iter:[20/150], Time: 0.66, lr: 7.0402, Loss: 0.0244, pre: 1222.2, gt: 994.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [293/800] Iter:[40/150], Time: 0.62, lr: 7.0378, Loss: 0.0256, pre: 1841.8, gt: 2035.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [293/800] Iter:[60/150], Time: 0.61, lr: 7.0355, Loss: 0.0260, pre: 394.4, gt: 424.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [293/800] Iter:[80/150], Time: 0.60, lr: 7.0331, Loss: 0.0265, pre: 1323.9, gt: 1245.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [293/800] Iter:[100/150], Time: 0.60, lr: 7.0307, Loss: 0.0268, pre: 1155.2, gt: 1241.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [293/800] Iter:[120/150], Time: 0.60, lr: 7.0283, Loss: 0.0268, pre: 3866.6, gt: 3767.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [293/800] Iter:[140/150], Time: 0.59, lr: 7.0259, Loss: 0.0265, pre: 326.0, gt: 293.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  113.26, Best_MAE:  93.3597 MSE:  321.3831,Best_MSE:  154.4884\n","Epoch: [294/800] Iter:[0/150], Time: 4.16, lr: 7.0247, Loss: 0.0282, pre: 1355.6, gt: 1257.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [294/800] Iter:[20/150], Time: 0.76, lr: 7.0223, Loss: 0.0287, pre: 660.3, gt: 490.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [294/800] Iter:[40/150], Time: 0.67, lr: 7.0199, Loss: 0.0293, pre: 1787.0, gt: 1627.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [294/800] Iter:[60/150], Time: 0.64, lr: 7.0175, Loss: 0.0286, pre: 850.6, gt: 930.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [294/800] Iter:[80/150], Time: 0.63, lr: 7.0151, Loss: 0.0283, pre: 550.9, gt: 418.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [294/800] Iter:[100/150], Time: 0.62, lr: 7.0127, Loss: 0.0284, pre: 678.7, gt: 668.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [294/800] Iter:[120/150], Time: 0.61, lr: 7.0103, Loss: 0.0283, pre: 1507.1, gt: 1780.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [294/800] Iter:[140/150], Time: 0.61, lr: 7.0079, Loss: 0.0282, pre: 3270.7, gt: 2897.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [295/800] Iter:[0/150], Time: 2.05, lr: 7.0067, Loss: 0.0246, pre: 1311.0, gt: 1235.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [295/800] Iter:[20/150], Time: 0.65, lr: 7.0043, Loss: 0.0289, pre: 943.2, gt: 869.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [295/800] Iter:[40/150], Time: 0.62, lr: 7.0019, Loss: 0.0288, pre: 725.9, gt: 743.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [295/800] Iter:[60/150], Time: 0.61, lr: 6.9995, Loss: 0.0270, pre: 773.9, gt: 693.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [295/800] Iter:[80/150], Time: 0.60, lr: 6.9972, Loss: 0.0269, pre: 811.1, gt: 857.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [295/800] Iter:[100/150], Time: 0.60, lr: 6.9948, Loss: 0.0272, pre: 810.0, gt: 699.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [295/800] Iter:[120/150], Time: 0.59, lr: 6.9924, Loss: 0.0265, pre: 939.5, gt: 991.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [295/800] Iter:[140/150], Time: 0.59, lr: 6.9900, Loss: 0.0270, pre: 613.1, gt: 619.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [296/800] Iter:[0/150], Time: 1.81, lr: 6.9888, Loss: 0.0222, pre: 686.3, gt: 783.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [296/800] Iter:[20/150], Time: 0.64, lr: 6.9864, Loss: 0.0288, pre: 1975.3, gt: 1422.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [296/800] Iter:[40/150], Time: 0.61, lr: 6.9840, Loss: 0.0295, pre: 1463.8, gt: 1481.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [296/800] Iter:[60/150], Time: 0.60, lr: 6.9816, Loss: 0.0282, pre: 1976.7, gt: 1970.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [296/800] Iter:[80/150], Time: 0.60, lr: 6.9791, Loss: 0.0289, pre: 2891.9, gt: 2853.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [296/800] Iter:[100/150], Time: 0.59, lr: 6.9767, Loss: 0.0289, pre: 841.6, gt: 1112.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [296/800] Iter:[120/150], Time: 0.59, lr: 6.9743, Loss: 0.0288, pre: 1643.2, gt: 1658.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [296/800] Iter:[140/150], Time: 0.59, lr: 6.9719, Loss: 0.0293, pre: 1612.0, gt: 1719.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  161.03, Best_MAE:  93.3597 MSE:  279.0414,Best_MSE:  154.4884\n","Epoch: [297/800] Iter:[0/150], Time: 4.28, lr: 6.9707, Loss: 0.0105, pre: 622.2, gt: 581.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [297/800] Iter:[20/150], Time: 0.76, lr: 6.9683, Loss: 0.0320, pre: 773.3, gt: 589.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [297/800] Iter:[40/150], Time: 0.67, lr: 6.9659, Loss: 0.0282, pre: 200.7, gt: 202.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [297/800] Iter:[60/150], Time: 0.64, lr: 6.9635, Loss: 0.0287, pre: 4346.4, gt: 3406.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [297/800] Iter:[80/150], Time: 0.63, lr: 6.9611, Loss: 0.0295, pre: 2220.1, gt: 2314.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [297/800] Iter:[100/150], Time: 0.62, lr: 6.9587, Loss: 0.0299, pre: 1637.2, gt: 2045.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [297/800] Iter:[120/150], Time: 0.61, lr: 6.9563, Loss: 0.0295, pre: 2041.2, gt: 2220.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [297/800] Iter:[140/150], Time: 0.61, lr: 6.9539, Loss: 0.0292, pre: 1054.7, gt: 1193.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [298/800] Iter:[0/150], Time: 2.44, lr: 6.9527, Loss: 0.0631, pre: 4877.7, gt: 5161.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [298/800] Iter:[20/150], Time: 0.67, lr: 6.9503, Loss: 0.0306, pre: 1157.2, gt: 1633.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [298/800] Iter:[40/150], Time: 0.63, lr: 6.9479, Loss: 0.0288, pre: 1287.1, gt: 1296.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [298/800] Iter:[60/150], Time: 0.61, lr: 6.9455, Loss: 0.0303, pre: 1446.1, gt: 1659.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [298/800] Iter:[80/150], Time: 0.60, lr: 6.9431, Loss: 0.0294, pre: 3610.7, gt: 4329.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [298/800] Iter:[100/150], Time: 0.60, lr: 6.9406, Loss: 0.0282, pre: 1452.8, gt: 1807.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [298/800] Iter:[120/150], Time: 0.60, lr: 6.9382, Loss: 0.0284, pre: 3881.6, gt: 4145.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [298/800] Iter:[140/150], Time: 0.59, lr: 6.9358, Loss: 0.0283, pre: 402.1, gt: 405.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [299/800] Iter:[0/150], Time: 2.12, lr: 6.9346, Loss: 0.0265, pre: 1064.0, gt: 999.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [299/800] Iter:[20/150], Time: 0.66, lr: 6.9322, Loss: 0.0305, pre: 5376.7, gt: 4736.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [299/800] Iter:[40/150], Time: 0.62, lr: 6.9298, Loss: 0.0272, pre: 477.0, gt: 443.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [299/800] Iter:[60/150], Time: 0.61, lr: 6.9274, Loss: 0.0271, pre: 1182.4, gt: 1263.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [299/800] Iter:[80/150], Time: 0.60, lr: 6.9250, Loss: 0.0270, pre: 1029.6, gt: 1179.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [299/800] Iter:[100/150], Time: 0.60, lr: 6.9225, Loss: 0.0266, pre: 2971.6, gt: 3058.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [299/800] Iter:[120/150], Time: 0.59, lr: 6.9201, Loss: 0.0266, pre: 3541.0, gt: 4308.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [299/800] Iter:[140/150], Time: 0.59, lr: 6.9177, Loss: 0.0278, pre: 3595.6, gt: 3145.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  107.07, Best_MAE:  93.3597 MSE:  221.7614,Best_MSE:  154.4884\n","Epoch: [300/800] Iter:[0/150], Time: 4.33, lr: 6.9165, Loss: 0.0120, pre: 818.6, gt: 904.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [300/800] Iter:[20/150], Time: 0.77, lr: 6.9141, Loss: 0.0244, pre: 424.3, gt: 446.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [300/800] Iter:[40/150], Time: 0.68, lr: 6.9117, Loss: 0.0258, pre: 751.8, gt: 826.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [300/800] Iter:[60/150], Time: 0.65, lr: 6.9093, Loss: 0.0282, pre: 1767.4, gt: 2213.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [300/800] Iter:[80/150], Time: 0.63, lr: 6.9068, Loss: 0.0291, pre: 1355.8, gt: 1470.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [300/800] Iter:[100/150], Time: 0.62, lr: 6.9044, Loss: 0.0292, pre: 3786.1, gt: 3443.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [300/800] Iter:[120/150], Time: 0.61, lr: 6.9020, Loss: 0.0299, pre: 5687.1, gt: 6666.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [300/800] Iter:[140/150], Time: 0.61, lr: 6.8996, Loss: 0.0296, pre: 1177.3, gt: 1761.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [301/800] Iter:[0/150], Time: 1.76, lr: 6.8984, Loss: 0.0247, pre: 848.5, gt: 900.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [301/800] Iter:[20/150], Time: 0.64, lr: 6.8959, Loss: 0.0314, pre: 2639.1, gt: 2611.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [301/800] Iter:[40/150], Time: 0.61, lr: 6.8935, Loss: 0.0286, pre: 1791.7, gt: 1626.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [301/800] Iter:[60/150], Time: 0.60, lr: 6.8911, Loss: 0.0281, pre: 1055.9, gt: 1358.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [301/800] Iter:[80/150], Time: 0.60, lr: 6.8887, Loss: 0.0281, pre: 1380.5, gt: 1555.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [301/800] Iter:[100/150], Time: 0.59, lr: 6.8863, Loss: 0.0280, pre: 1272.1, gt: 1219.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [301/800] Iter:[120/150], Time: 0.59, lr: 6.8838, Loss: 0.0277, pre: 2144.5, gt: 1976.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [301/800] Iter:[140/150], Time: 0.59, lr: 6.8814, Loss: 0.0276, pre: 3818.3, gt: 3668.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [302/800] Iter:[0/150], Time: 2.03, lr: 6.8802, Loss: 0.0138, pre: 700.4, gt: 685.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [302/800] Iter:[20/150], Time: 0.65, lr: 6.8778, Loss: 0.0279, pre: 1305.3, gt: 1743.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [302/800] Iter:[40/150], Time: 0.62, lr: 6.8754, Loss: 0.0275, pre: 3073.5, gt: 3287.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [302/800] Iter:[60/150], Time: 0.61, lr: 6.8729, Loss: 0.0275, pre: 464.7, gt: 573.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [302/800] Iter:[80/150], Time: 0.60, lr: 6.8705, Loss: 0.0270, pre: 3946.3, gt: 4030.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [302/800] Iter:[100/150], Time: 0.60, lr: 6.8681, Loss: 0.0272, pre: 1096.2, gt: 1105.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [302/800] Iter:[120/150], Time: 0.59, lr: 6.8656, Loss: 0.0274, pre: 332.7, gt: 379.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [302/800] Iter:[140/150], Time: 0.59, lr: 6.8632, Loss: 0.0274, pre: 3164.3, gt: 2768.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  113.62, Best_MAE:  93.3597 MSE:  186.2553,Best_MSE:  154.4884\n","Epoch: [303/800] Iter:[0/150], Time: 4.10, lr: 6.8620, Loss: 0.0295, pre: 2794.4, gt: 2570.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [303/800] Iter:[20/150], Time: 0.75, lr: 6.8596, Loss: 0.0283, pre: 1490.7, gt: 1109.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [303/800] Iter:[40/150], Time: 0.67, lr: 6.8571, Loss: 0.0277, pre: 673.1, gt: 611.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [303/800] Iter:[60/150], Time: 0.64, lr: 6.8547, Loss: 0.0267, pre: 1866.3, gt: 1991.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [303/800] Iter:[80/150], Time: 0.63, lr: 6.8523, Loss: 0.0262, pre: 597.8, gt: 801.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [303/800] Iter:[100/150], Time: 0.62, lr: 6.8499, Loss: 0.0270, pre: 1140.6, gt: 1247.0,acc:0.88, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [303/800] Iter:[120/150], Time: 0.61, lr: 6.8474, Loss: 0.0265, pre: 2692.5, gt: 2585.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [303/800] Iter:[140/150], Time: 0.61, lr: 6.8450, Loss: 0.0268, pre: 1524.9, gt: 1326.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [304/800] Iter:[0/150], Time: 2.55, lr: 6.8438, Loss: 0.0254, pre: 1550.2, gt: 1682.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.93,acc1:0.00\n","Epoch: [304/800] Iter:[20/150], Time: 0.68, lr: 6.8414, Loss: 0.0286, pre: 747.6, gt: 641.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [304/800] Iter:[40/150], Time: 0.63, lr: 6.8389, Loss: 0.0276, pre: 1218.9, gt: 1280.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [304/800] Iter:[60/150], Time: 0.62, lr: 6.8365, Loss: 0.0287, pre: 615.0, gt: 648.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [304/800] Iter:[80/150], Time: 0.61, lr: 6.8341, Loss: 0.0284, pre: 1775.1, gt: 1377.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [304/800] Iter:[100/150], Time: 0.60, lr: 6.8316, Loss: 0.0287, pre: 1445.9, gt: 1593.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [304/800] Iter:[120/150], Time: 0.60, lr: 6.8292, Loss: 0.0280, pre: 643.9, gt: 622.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [304/800] Iter:[140/150], Time: 0.60, lr: 6.8267, Loss: 0.0287, pre: 1496.0, gt: 1279.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [305/800] Iter:[0/150], Time: 2.15, lr: 6.8255, Loss: 0.0245, pre: 1735.2, gt: 1545.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [305/800] Iter:[20/150], Time: 0.66, lr: 6.8231, Loss: 0.0311, pre: 348.0, gt: 326.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [305/800] Iter:[40/150], Time: 0.62, lr: 6.8207, Loss: 0.0281, pre: 1533.9, gt: 1738.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [305/800] Iter:[60/150], Time: 0.61, lr: 6.8182, Loss: 0.0293, pre: 582.8, gt: 522.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [305/800] Iter:[80/150], Time: 0.60, lr: 6.8158, Loss: 0.0287, pre: 935.6, gt: 812.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [305/800] Iter:[100/150], Time: 0.60, lr: 6.8133, Loss: 0.0287, pre: 2793.2, gt: 2866.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [305/800] Iter:[120/150], Time: 0.60, lr: 6.8109, Loss: 0.0277, pre: 759.5, gt: 823.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [305/800] Iter:[140/150], Time: 0.59, lr: 6.8085, Loss: 0.0279, pre: 2278.5, gt: 2487.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  141.80, Best_MAE:  93.3597 MSE:  252.6812,Best_MSE:  154.4884\n","Epoch: [306/800] Iter:[0/150], Time: 4.71, lr: 6.8073, Loss: 0.0319, pre: 2577.4, gt: 2278.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [306/800] Iter:[20/150], Time: 0.79, lr: 6.8048, Loss: 0.0286, pre: 526.8, gt: 612.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [306/800] Iter:[40/150], Time: 0.69, lr: 6.8024, Loss: 0.0264, pre: 253.0, gt: 253.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [306/800] Iter:[60/150], Time: 0.65, lr: 6.7999, Loss: 0.0262, pre: 206.1, gt: 353.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [306/800] Iter:[80/150], Time: 0.64, lr: 6.7975, Loss: 0.0279, pre: 3937.6, gt: 4580.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [306/800] Iter:[100/150], Time: 0.63, lr: 6.7950, Loss: 0.0278, pre: 1610.2, gt: 1571.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [306/800] Iter:[120/150], Time: 0.62, lr: 6.7926, Loss: 0.0276, pre: 570.0, gt: 634.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [306/800] Iter:[140/150], Time: 0.61, lr: 6.7902, Loss: 0.0279, pre: 1441.1, gt: 1417.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [307/800] Iter:[0/150], Time: 1.98, lr: 6.7889, Loss: 0.0257, pre: 1052.1, gt: 1029.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [307/800] Iter:[20/150], Time: 0.65, lr: 6.7865, Loss: 0.0265, pre: 3594.0, gt: 3609.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [307/800] Iter:[40/150], Time: 0.62, lr: 6.7841, Loss: 0.0246, pre: 420.1, gt: 360.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [307/800] Iter:[60/150], Time: 0.61, lr: 6.7816, Loss: 0.0268, pre: 6095.2, gt: 6657.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [307/800] Iter:[80/150], Time: 0.60, lr: 6.7792, Loss: 0.0275, pre: 1417.3, gt: 1412.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [307/800] Iter:[100/150], Time: 0.60, lr: 6.7767, Loss: 0.0274, pre: 1406.9, gt: 1213.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [307/800] Iter:[120/150], Time: 0.59, lr: 6.7743, Loss: 0.0275, pre: 1641.3, gt: 1371.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [307/800] Iter:[140/150], Time: 0.59, lr: 6.7718, Loss: 0.0267, pre: 2171.3, gt: 2077.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [308/800] Iter:[0/150], Time: 1.91, lr: 6.7706, Loss: 0.0246, pre: 991.5, gt: 1243.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [308/800] Iter:[20/150], Time: 0.65, lr: 6.7682, Loss: 0.0234, pre: 473.2, gt: 536.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [308/800] Iter:[40/150], Time: 0.62, lr: 6.7657, Loss: 0.0279, pre: 1421.1, gt: 1682.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [308/800] Iter:[60/150], Time: 0.61, lr: 6.7633, Loss: 0.0282, pre: 1101.8, gt: 1503.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [308/800] Iter:[80/150], Time: 0.60, lr: 6.7608, Loss: 0.0277, pre: 1043.5, gt: 1169.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [308/800] Iter:[100/150], Time: 0.60, lr: 6.7584, Loss: 0.0276, pre: 2301.2, gt: 2209.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [308/800] Iter:[120/150], Time: 0.59, lr: 6.7559, Loss: 0.0285, pre: 2025.3, gt: 1726.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [308/800] Iter:[140/150], Time: 0.59, lr: 6.7535, Loss: 0.0288, pre: 7826.6, gt: 7904.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  107.12, Best_MAE:  93.3597 MSE:  217.3890,Best_MSE:  154.4884\n","Epoch: [309/800] Iter:[0/150], Time: 4.09, lr: 6.7522, Loss: 0.0352, pre: 2387.5, gt: 2416.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [309/800] Iter:[20/150], Time: 0.75, lr: 6.7498, Loss: 0.0291, pre: 1566.8, gt: 1699.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [309/800] Iter:[40/150], Time: 0.67, lr: 6.7473, Loss: 0.0256, pre: 1539.9, gt: 1781.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [309/800] Iter:[60/150], Time: 0.64, lr: 6.7449, Loss: 0.0262, pre: 992.9, gt: 916.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [309/800] Iter:[80/150], Time: 0.63, lr: 6.7424, Loss: 0.0275, pre: 2168.1, gt: 2580.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [309/800] Iter:[100/150], Time: 0.62, lr: 6.7400, Loss: 0.0276, pre: 2349.8, gt: 2819.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [309/800] Iter:[120/150], Time: 0.61, lr: 6.7375, Loss: 0.0276, pre: 723.0, gt: 1203.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [309/800] Iter:[140/150], Time: 0.61, lr: 6.7351, Loss: 0.0269, pre: 815.7, gt: 813.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [310/800] Iter:[0/150], Time: 2.11, lr: 6.7339, Loss: 0.0330, pre: 2190.2, gt: 2428.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [310/800] Iter:[20/150], Time: 0.66, lr: 6.7314, Loss: 0.0264, pre: 1219.2, gt: 1236.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [310/800] Iter:[40/150], Time: 0.62, lr: 6.7289, Loss: 0.0279, pre: 3388.1, gt: 3425.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [310/800] Iter:[60/150], Time: 0.61, lr: 6.7265, Loss: 0.0270, pre: 1571.5, gt: 1408.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [310/800] Iter:[80/150], Time: 0.60, lr: 6.7240, Loss: 0.0281, pre: 1682.7, gt: 1882.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [310/800] Iter:[100/150], Time: 0.60, lr: 6.7216, Loss: 0.0290, pre: 891.8, gt: 952.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [310/800] Iter:[120/150], Time: 0.60, lr: 6.7191, Loss: 0.0283, pre: 616.3, gt: 613.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [310/800] Iter:[140/150], Time: 0.59, lr: 6.7167, Loss: 0.0286, pre: 398.5, gt: 398.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [311/800] Iter:[0/150], Time: 2.24, lr: 6.7154, Loss: 0.0338, pre: 3979.3, gt: 4067.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [311/800] Iter:[20/150], Time: 0.66, lr: 6.7130, Loss: 0.0273, pre: 1222.1, gt: 1271.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [311/800] Iter:[40/150], Time: 0.62, lr: 6.7105, Loss: 0.0275, pre: 3009.4, gt: 2678.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [311/800] Iter:[60/150], Time: 0.61, lr: 6.7081, Loss: 0.0275, pre: 1172.8, gt: 1266.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [311/800] Iter:[80/150], Time: 0.60, lr: 6.7056, Loss: 0.0277, pre: 1732.0, gt: 1712.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [311/800] Iter:[100/150], Time: 0.60, lr: 6.7031, Loss: 0.0275, pre: 2349.7, gt: 2283.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [311/800] Iter:[120/150], Time: 0.59, lr: 6.7007, Loss: 0.0268, pre: 1961.4, gt: 1952.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [311/800] Iter:[140/150], Time: 0.59, lr: 6.6982, Loss: 0.0266, pre: 872.3, gt: 877.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  92.42, Best_MAE:  92.4190 MSE:  153.1174,Best_MSE:  153.1174\n","Epoch: [312/800] Iter:[0/150], Time: 2.80, lr: 6.6970, Loss: 0.0267, pre: 1042.9, gt: 997.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [312/800] Iter:[20/150], Time: 0.69, lr: 6.6945, Loss: 0.0262, pre: 1890.2, gt: 2166.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [312/800] Iter:[40/150], Time: 0.64, lr: 6.6921, Loss: 0.0281, pre: 6944.3, gt: 6999.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [312/800] Iter:[60/150], Time: 0.62, lr: 6.6896, Loss: 0.0278, pre: 529.5, gt: 452.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [312/800] Iter:[80/150], Time: 0.61, lr: 6.6871, Loss: 0.0279, pre: 729.9, gt: 766.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [312/800] Iter:[100/150], Time: 0.60, lr: 6.6847, Loss: 0.0285, pre: 908.7, gt: 1031.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [312/800] Iter:[120/150], Time: 0.60, lr: 6.6822, Loss: 0.0280, pre: 1952.4, gt: 2032.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [312/800] Iter:[140/150], Time: 0.60, lr: 6.6798, Loss: 0.0282, pre: 3162.4, gt: 4181.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [313/800] Iter:[0/150], Time: 2.13, lr: 6.6785, Loss: 0.0319, pre: 1728.0, gt: 1346.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [313/800] Iter:[20/150], Time: 0.66, lr: 6.6761, Loss: 0.0273, pre: 2354.4, gt: 2288.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [313/800] Iter:[40/150], Time: 0.62, lr: 6.6736, Loss: 0.0294, pre: 1902.6, gt: 2043.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [313/800] Iter:[60/150], Time: 0.61, lr: 6.6711, Loss: 0.0295, pre: 760.0, gt: 830.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [313/800] Iter:[80/150], Time: 0.60, lr: 6.6687, Loss: 0.0291, pre: 621.1, gt: 676.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [313/800] Iter:[100/150], Time: 0.60, lr: 6.6662, Loss: 0.0289, pre: 1574.9, gt: 1629.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [313/800] Iter:[120/150], Time: 0.59, lr: 6.6637, Loss: 0.0285, pre: 211.4, gt: 229.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [313/800] Iter:[140/150], Time: 0.59, lr: 6.6613, Loss: 0.0281, pre: 491.3, gt: 548.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [314/800] Iter:[0/150], Time: 1.94, lr: 6.6600, Loss: 0.0260, pre: 2559.6, gt: 2626.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [314/800] Iter:[20/150], Time: 0.65, lr: 6.6576, Loss: 0.0272, pre: 415.6, gt: 378.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [314/800] Iter:[40/150], Time: 0.62, lr: 6.6551, Loss: 0.0260, pre: 1191.7, gt: 1156.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [314/800] Iter:[60/150], Time: 0.60, lr: 6.6526, Loss: 0.0273, pre: 2117.4, gt: 2678.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [314/800] Iter:[80/150], Time: 0.60, lr: 6.6502, Loss: 0.0269, pre: 2081.7, gt: 1712.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [314/800] Iter:[100/150], Time: 0.60, lr: 6.6477, Loss: 0.0271, pre: 1258.9, gt: 1057.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [314/800] Iter:[120/150], Time: 0.59, lr: 6.6452, Loss: 0.0276, pre: 335.6, gt: 378.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [314/800] Iter:[140/150], Time: 0.59, lr: 6.6427, Loss: 0.0276, pre: 739.1, gt: 762.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  100.84, Best_MAE:  92.4190 MSE:  167.9213,Best_MSE:  153.1174\n","Epoch: [315/800] Iter:[0/150], Time: 4.28, lr: 6.6415, Loss: 0.0214, pre: 883.6, gt: 832.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [315/800] Iter:[20/150], Time: 0.76, lr: 6.6390, Loss: 0.0274, pre: 1355.2, gt: 1188.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [315/800] Iter:[40/150], Time: 0.67, lr: 6.6366, Loss: 0.0284, pre: 748.6, gt: 654.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [315/800] Iter:[60/150], Time: 0.64, lr: 6.6341, Loss: 0.0276, pre: 3127.3, gt: 2979.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [315/800] Iter:[80/150], Time: 0.63, lr: 6.6316, Loss: 0.0271, pre: 572.5, gt: 575.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [315/800] Iter:[100/150], Time: 0.62, lr: 6.6292, Loss: 0.0267, pre: 1292.0, gt: 1336.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [315/800] Iter:[120/150], Time: 0.61, lr: 6.6267, Loss: 0.0271, pre: 2524.8, gt: 2749.0,acc:0.89, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [315/800] Iter:[140/150], Time: 0.61, lr: 6.6242, Loss: 0.0267, pre: 1277.4, gt: 1331.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [316/800] Iter:[0/150], Time: 2.02, lr: 6.6230, Loss: 0.0201, pre: 696.0, gt: 696.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [316/800] Iter:[20/150], Time: 0.65, lr: 6.6205, Loss: 0.0230, pre: 869.1, gt: 802.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [316/800] Iter:[40/150], Time: 0.62, lr: 6.6180, Loss: 0.0251, pre: 3421.4, gt: 2749.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [316/800] Iter:[60/150], Time: 0.61, lr: 6.6155, Loss: 0.0269, pre: 1385.8, gt: 1809.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [316/800] Iter:[80/150], Time: 0.60, lr: 6.6131, Loss: 0.0268, pre: 1665.2, gt: 1726.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [316/800] Iter:[100/150], Time: 0.60, lr: 6.6106, Loss: 0.0262, pre: 1453.3, gt: 1372.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [316/800] Iter:[120/150], Time: 0.60, lr: 6.6081, Loss: 0.0269, pre: 1205.1, gt: 1363.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [316/800] Iter:[140/150], Time: 0.59, lr: 6.6056, Loss: 0.0276, pre: 587.4, gt: 662.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [317/800] Iter:[0/150], Time: 1.85, lr: 6.6044, Loss: 0.0444, pre: 3437.1, gt: 2858.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [317/800] Iter:[20/150], Time: 0.64, lr: 6.6019, Loss: 0.0291, pre: 725.8, gt: 868.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [317/800] Iter:[40/150], Time: 0.61, lr: 6.5994, Loss: 0.0271, pre: 847.2, gt: 854.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [317/800] Iter:[60/150], Time: 0.60, lr: 6.5970, Loss: 0.0265, pre: 2095.6, gt: 2490.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [317/800] Iter:[80/150], Time: 0.60, lr: 6.5945, Loss: 0.0267, pre: 930.3, gt: 1014.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [317/800] Iter:[100/150], Time: 0.59, lr: 6.5920, Loss: 0.0271, pre: 941.0, gt: 1044.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [317/800] Iter:[120/150], Time: 0.59, lr: 6.5895, Loss: 0.0275, pre: 1525.1, gt: 1765.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [317/800] Iter:[140/150], Time: 0.59, lr: 6.5870, Loss: 0.0273, pre: 581.6, gt: 530.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  117.88, Best_MAE:  92.4190 MSE:  200.1094,Best_MSE:  153.1174\n","Epoch: [318/800] Iter:[0/150], Time: 4.71, lr: 6.5858, Loss: 0.0198, pre: 1331.1, gt: 1454.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [318/800] Iter:[20/150], Time: 0.78, lr: 6.5833, Loss: 0.0267, pre: 1127.2, gt: 1283.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [318/800] Iter:[40/150], Time: 0.69, lr: 6.5808, Loss: 0.0267, pre: 1556.3, gt: 1791.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [318/800] Iter:[60/150], Time: 0.65, lr: 6.5784, Loss: 0.0267, pre: 531.9, gt: 532.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [318/800] Iter:[80/150], Time: 0.64, lr: 6.5759, Loss: 0.0273, pre: 2588.5, gt: 3130.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [318/800] Iter:[100/150], Time: 0.63, lr: 6.5734, Loss: 0.0277, pre: 884.2, gt: 1538.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [318/800] Iter:[120/150], Time: 0.62, lr: 6.5709, Loss: 0.0280, pre: 1305.8, gt: 1474.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [318/800] Iter:[140/150], Time: 0.61, lr: 6.5684, Loss: 0.0280, pre: 520.3, gt: 428.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [319/800] Iter:[0/150], Time: 2.36, lr: 6.5672, Loss: 0.0286, pre: 2553.1, gt: 2536.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [319/800] Iter:[20/150], Time: 0.67, lr: 6.5647, Loss: 0.0309, pre: 860.7, gt: 490.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [319/800] Iter:[40/150], Time: 0.63, lr: 6.5622, Loss: 0.0339, pre: 671.8, gt: 688.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [319/800] Iter:[60/150], Time: 0.61, lr: 6.5597, Loss: 0.0319, pre: 1984.4, gt: 1906.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [319/800] Iter:[80/150], Time: 0.61, lr: 6.5572, Loss: 0.0304, pre: 1215.5, gt: 1551.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [319/800] Iter:[100/150], Time: 0.60, lr: 6.5548, Loss: 0.0303, pre: 1655.8, gt: 1461.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [319/800] Iter:[120/150], Time: 0.60, lr: 6.5523, Loss: 0.0299, pre: 766.4, gt: 729.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [319/800] Iter:[140/150], Time: 0.60, lr: 6.5498, Loss: 0.0294, pre: 1443.3, gt: 1344.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [320/800] Iter:[0/150], Time: 1.95, lr: 6.5485, Loss: 0.0220, pre: 918.7, gt: 1207.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [320/800] Iter:[20/150], Time: 0.65, lr: 6.5461, Loss: 0.0252, pre: 1247.2, gt: 1358.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [320/800] Iter:[40/150], Time: 0.62, lr: 6.5436, Loss: 0.0258, pre: 1564.4, gt: 1869.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [320/800] Iter:[60/150], Time: 0.61, lr: 6.5411, Loss: 0.0259, pre: 2826.0, gt: 2723.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [320/800] Iter:[80/150], Time: 0.60, lr: 6.5386, Loss: 0.0256, pre: 109.2, gt: 140.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [320/800] Iter:[100/150], Time: 0.60, lr: 6.5361, Loss: 0.0264, pre: 3061.8, gt: 3037.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [320/800] Iter:[120/150], Time: 0.59, lr: 6.5336, Loss: 0.0281, pre: 2799.9, gt: 1784.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [320/800] Iter:[140/150], Time: 0.59, lr: 6.5311, Loss: 0.0287, pre: 690.1, gt: 814.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  143.23, Best_MAE:  92.4190 MSE:  255.5416,Best_MSE:  153.1174\n","Epoch: [321/800] Iter:[0/150], Time: 4.60, lr: 6.5299, Loss: 0.0388, pre: 2359.2, gt: 2344.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [321/800] Iter:[20/150], Time: 0.78, lr: 6.5274, Loss: 0.0267, pre: 1301.9, gt: 1230.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [321/800] Iter:[40/150], Time: 0.68, lr: 6.5249, Loss: 0.0267, pre: 1328.2, gt: 1553.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [321/800] Iter:[60/150], Time: 0.65, lr: 6.5224, Loss: 0.0286, pre: 2275.9, gt: 1972.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [321/800] Iter:[80/150], Time: 0.63, lr: 6.5199, Loss: 0.0277, pre: 806.4, gt: 955.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [321/800] Iter:[100/150], Time: 0.62, lr: 6.5174, Loss: 0.0267, pre: 705.0, gt: 557.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [321/800] Iter:[120/150], Time: 0.62, lr: 6.5149, Loss: 0.0269, pre: 4083.1, gt: 3583.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [321/800] Iter:[140/150], Time: 0.61, lr: 6.5124, Loss: 0.0276, pre: 1139.4, gt: 1124.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [322/800] Iter:[0/150], Time: 2.79, lr: 6.5112, Loss: 0.0524, pre: 7422.2, gt: 6622.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [322/800] Iter:[20/150], Time: 0.69, lr: 6.5087, Loss: 0.0271, pre: 2266.1, gt: 2675.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [322/800] Iter:[40/150], Time: 0.64, lr: 6.5062, Loss: 0.0273, pre: 2596.9, gt: 2584.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [322/800] Iter:[60/150], Time: 0.62, lr: 6.5037, Loss: 0.0275, pre: 3829.5, gt: 4411.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [322/800] Iter:[80/150], Time: 0.61, lr: 6.5012, Loss: 0.0270, pre: 668.1, gt: 719.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [322/800] Iter:[100/150], Time: 0.60, lr: 6.4987, Loss: 0.0270, pre: 5191.1, gt: 5284.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [322/800] Iter:[120/150], Time: 0.60, lr: 6.4962, Loss: 0.0273, pre: 1539.8, gt: 1818.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [322/800] Iter:[140/150], Time: 0.60, lr: 6.4937, Loss: 0.0274, pre: 419.7, gt: 485.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [323/800] Iter:[0/150], Time: 1.98, lr: 6.4925, Loss: 0.0099, pre: 403.5, gt: 444.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [323/800] Iter:[20/150], Time: 0.65, lr: 6.4900, Loss: 0.0276, pre: 649.1, gt: 843.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [323/800] Iter:[40/150], Time: 0.62, lr: 6.4875, Loss: 0.0255, pre: 252.6, gt: 421.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [323/800] Iter:[60/150], Time: 0.61, lr: 6.4850, Loss: 0.0261, pre: 951.1, gt: 1241.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [323/800] Iter:[80/150], Time: 0.60, lr: 6.4825, Loss: 0.0259, pre: 4012.9, gt: 4636.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [323/800] Iter:[100/150], Time: 0.60, lr: 6.4800, Loss: 0.0266, pre: 493.2, gt: 601.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [323/800] Iter:[120/150], Time: 0.59, lr: 6.4775, Loss: 0.0270, pre: 801.3, gt: 814.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [323/800] Iter:[140/150], Time: 0.59, lr: 6.4750, Loss: 0.0269, pre: 1317.1, gt: 1321.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  115.03, Best_MAE:  92.4190 MSE:  199.2247,Best_MSE:  153.1174\n","Epoch: [324/800] Iter:[0/150], Time: 4.26, lr: 6.4737, Loss: 0.0345, pre: 2165.6, gt: 2215.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [324/800] Iter:[20/150], Time: 0.76, lr: 6.4712, Loss: 0.0281, pre: 1447.6, gt: 1595.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [324/800] Iter:[40/150], Time: 0.67, lr: 6.4687, Loss: 0.0295, pre: 1597.5, gt: 1530.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [324/800] Iter:[60/150], Time: 0.64, lr: 6.4662, Loss: 0.0296, pre: 5326.9, gt: 4717.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [324/800] Iter:[80/150], Time: 0.63, lr: 6.4637, Loss: 0.0289, pre: 867.8, gt: 926.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [324/800] Iter:[100/150], Time: 0.62, lr: 6.4612, Loss: 0.0293, pre: 839.6, gt: 809.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [324/800] Iter:[120/150], Time: 0.61, lr: 6.4587, Loss: 0.0282, pre: 1092.3, gt: 1253.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [324/800] Iter:[140/150], Time: 0.61, lr: 6.4562, Loss: 0.0277, pre: 898.8, gt: 1031.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [325/800] Iter:[0/150], Time: 2.61, lr: 6.4550, Loss: 0.0149, pre: 553.4, gt: 599.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [325/800] Iter:[20/150], Time: 0.68, lr: 6.4525, Loss: 0.0286, pre: 2681.7, gt: 2594.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [325/800] Iter:[40/150], Time: 0.63, lr: 6.4500, Loss: 0.0265, pre: 1588.5, gt: 1116.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [325/800] Iter:[60/150], Time: 0.62, lr: 6.4475, Loss: 0.0261, pre: 947.8, gt: 1134.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [325/800] Iter:[80/150], Time: 0.61, lr: 6.4450, Loss: 0.0260, pre: 1706.7, gt: 1727.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [325/800] Iter:[100/150], Time: 0.60, lr: 6.4425, Loss: 0.0258, pre: 1325.5, gt: 1346.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [325/800] Iter:[120/150], Time: 0.60, lr: 6.4399, Loss: 0.0265, pre: 556.9, gt: 540.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [325/800] Iter:[140/150], Time: 0.60, lr: 6.4374, Loss: 0.0269, pre: 296.4, gt: 329.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [326/800] Iter:[0/150], Time: 2.18, lr: 6.4362, Loss: 0.0128, pre: 312.8, gt: 298.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [326/800] Iter:[20/150], Time: 0.67, lr: 6.4337, Loss: 0.0243, pre: 1723.8, gt: 1772.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [326/800] Iter:[40/150], Time: 0.63, lr: 6.4312, Loss: 0.0272, pre: 1509.5, gt: 1256.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [326/800] Iter:[60/150], Time: 0.61, lr: 6.4287, Loss: 0.0257, pre: 272.7, gt: 257.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [326/800] Iter:[80/150], Time: 0.60, lr: 6.4262, Loss: 0.0267, pre: 795.1, gt: 621.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [326/800] Iter:[100/150], Time: 0.60, lr: 6.4237, Loss: 0.0275, pre: 1000.9, gt: 1093.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [326/800] Iter:[120/150], Time: 0.60, lr: 6.4211, Loss: 0.0282, pre: 1628.4, gt: 2638.0,acc:0.89, accx8:0.94,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [326/800] Iter:[140/150], Time: 0.60, lr: 6.4186, Loss: 0.0278, pre: 476.1, gt: 487.0,acc:0.89, accx8:0.94,  accx16:0.94,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  301.99, Best_MAE:  92.4190 MSE:  462.8790,Best_MSE:  153.1174\n","Epoch: [327/800] Iter:[0/150], Time: 4.33, lr: 6.4174, Loss: 0.0252, pre: 799.5, gt: 592.0,acc:0.89, accx8:0.94,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [327/800] Iter:[20/150], Time: 0.76, lr: 6.4149, Loss: 0.0321, pre: 1052.3, gt: 1087.0,acc:0.89, accx8:0.94,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [327/800] Iter:[40/150], Time: 0.68, lr: 6.4124, Loss: 0.0306, pre: 682.4, gt: 823.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [327/800] Iter:[60/150], Time: 0.64, lr: 6.4099, Loss: 0.0290, pre: 817.6, gt: 897.0,acc:0.89, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [327/800] Iter:[80/150], Time: 0.63, lr: 6.4073, Loss: 0.0284, pre: 2763.3, gt: 3473.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [327/800] Iter:[100/150], Time: 0.62, lr: 6.4048, Loss: 0.0286, pre: 1415.8, gt: 1503.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [327/800] Iter:[120/150], Time: 0.61, lr: 6.4023, Loss: 0.0283, pre: 288.0, gt: 385.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [327/800] Iter:[140/150], Time: 0.61, lr: 6.3998, Loss: 0.0282, pre: 3123.3, gt: 2800.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [328/800] Iter:[0/150], Time: 1.81, lr: 6.3986, Loss: 0.0250, pre: 1611.4, gt: 1501.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [328/800] Iter:[20/150], Time: 0.64, lr: 6.3960, Loss: 0.0272, pre: 1137.9, gt: 1354.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [328/800] Iter:[40/150], Time: 0.61, lr: 6.3935, Loss: 0.0288, pre: 475.4, gt: 440.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [328/800] Iter:[60/150], Time: 0.60, lr: 6.3910, Loss: 0.0283, pre: 4465.5, gt: 4367.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [328/800] Iter:[80/150], Time: 0.60, lr: 6.3885, Loss: 0.0281, pre: 2123.0, gt: 2304.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [328/800] Iter:[100/150], Time: 0.59, lr: 6.3860, Loss: 0.0277, pre: 974.5, gt: 942.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [328/800] Iter:[120/150], Time: 0.59, lr: 6.3835, Loss: 0.0282, pre: 1224.3, gt: 1176.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [328/800] Iter:[140/150], Time: 0.59, lr: 6.3810, Loss: 0.0282, pre: 465.5, gt: 464.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [329/800] Iter:[0/150], Time: 2.29, lr: 6.3797, Loss: 0.0139, pre: 394.3, gt: 449.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [329/800] Iter:[20/150], Time: 0.66, lr: 6.3772, Loss: 0.0241, pre: 1331.1, gt: 1241.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [329/800] Iter:[40/150], Time: 0.62, lr: 6.3747, Loss: 0.0243, pre: 1721.3, gt: 1540.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [329/800] Iter:[60/150], Time: 0.61, lr: 6.3722, Loss: 0.0255, pre: 304.0, gt: 299.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [329/800] Iter:[80/150], Time: 0.60, lr: 6.3697, Loss: 0.0260, pre: 671.2, gt: 751.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [329/800] Iter:[100/150], Time: 0.60, lr: 6.3671, Loss: 0.0263, pre: 2372.9, gt: 2834.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [329/800] Iter:[120/150], Time: 0.60, lr: 6.3646, Loss: 0.0276, pre: 946.5, gt: 1208.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [329/800] Iter:[140/150], Time: 0.59, lr: 6.3621, Loss: 0.0274, pre: 1134.1, gt: 1411.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  126.25, Best_MAE:  92.4190 MSE:  229.9558,Best_MSE:  153.1174\n","Epoch: [330/800] Iter:[0/150], Time: 4.72, lr: 6.3608, Loss: 0.0175, pre: 645.0, gt: 587.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [330/800] Iter:[20/150], Time: 0.78, lr: 6.3583, Loss: 0.0291, pre: 1371.7, gt: 2082.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [330/800] Iter:[40/150], Time: 0.68, lr: 6.3558, Loss: 0.0267, pre: 911.3, gt: 830.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [330/800] Iter:[60/150], Time: 0.65, lr: 6.3533, Loss: 0.0270, pre: 1394.4, gt: 1446.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [330/800] Iter:[80/150], Time: 0.64, lr: 6.3508, Loss: 0.0270, pre: 1118.6, gt: 1098.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [330/800] Iter:[100/150], Time: 0.62, lr: 6.3483, Loss: 0.0270, pre: 1453.7, gt: 1526.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [330/800] Iter:[120/150], Time: 0.62, lr: 6.3457, Loss: 0.0270, pre: 2463.2, gt: 2221.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [330/800] Iter:[140/150], Time: 0.61, lr: 6.3432, Loss: 0.0271, pre: 616.1, gt: 658.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [331/800] Iter:[0/150], Time: 2.13, lr: 6.3420, Loss: 0.0223, pre: 2448.5, gt: 2435.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [331/800] Iter:[20/150], Time: 0.66, lr: 6.3394, Loss: 0.0256, pre: 1498.6, gt: 1630.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [331/800] Iter:[40/150], Time: 0.62, lr: 6.3369, Loss: 0.0260, pre: 1688.5, gt: 1982.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [331/800] Iter:[60/150], Time: 0.61, lr: 6.3344, Loss: 0.0263, pre: 847.8, gt: 779.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [331/800] Iter:[80/150], Time: 0.60, lr: 6.3319, Loss: 0.0265, pre: 643.7, gt: 707.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [331/800] Iter:[100/150], Time: 0.60, lr: 6.3294, Loss: 0.0267, pre: 2731.2, gt: 2760.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [331/800] Iter:[120/150], Time: 0.59, lr: 6.3268, Loss: 0.0267, pre: 1276.3, gt: 1261.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [331/800] Iter:[140/150], Time: 0.59, lr: 6.3243, Loss: 0.0261, pre: 1226.4, gt: 1191.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [332/800] Iter:[0/150], Time: 1.75, lr: 6.3230, Loss: 0.0255, pre: 744.9, gt: 954.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [332/800] Iter:[20/150], Time: 0.64, lr: 6.3205, Loss: 0.0298, pre: 3140.7, gt: 3410.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [332/800] Iter:[40/150], Time: 0.61, lr: 6.3180, Loss: 0.0271, pre: 1069.7, gt: 1064.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [332/800] Iter:[60/150], Time: 0.60, lr: 6.3155, Loss: 0.0285, pre: 5338.1, gt: 5463.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [332/800] Iter:[80/150], Time: 0.60, lr: 6.3130, Loss: 0.0278, pre: 683.5, gt: 647.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [332/800] Iter:[100/150], Time: 0.59, lr: 6.3104, Loss: 0.0274, pre: 2000.0, gt: 2189.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [332/800] Iter:[120/150], Time: 0.59, lr: 6.3079, Loss: 0.0274, pre: 1418.3, gt: 1679.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [332/800] Iter:[140/150], Time: 0.59, lr: 6.3054, Loss: 0.0276, pre: 874.3, gt: 889.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  97.74, Best_MAE:  92.4190 MSE:  192.2884,Best_MSE:  153.1174\n","Epoch: [333/800] Iter:[0/150], Time: 4.35, lr: 6.3041, Loss: 0.0326, pre: 1798.0, gt: 2105.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [333/800] Iter:[20/150], Time: 0.77, lr: 6.3016, Loss: 0.0306, pre: 1815.1, gt: 1549.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [333/800] Iter:[40/150], Time: 0.68, lr: 6.2991, Loss: 0.0307, pre: 1139.1, gt: 1274.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [333/800] Iter:[60/150], Time: 0.65, lr: 6.2965, Loss: 0.0289, pre: 1298.0, gt: 1206.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [333/800] Iter:[80/150], Time: 0.63, lr: 6.2940, Loss: 0.0282, pre: 984.0, gt: 1238.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [333/800] Iter:[100/150], Time: 0.62, lr: 6.2915, Loss: 0.0285, pre: 848.6, gt: 917.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [333/800] Iter:[120/150], Time: 0.61, lr: 6.2890, Loss: 0.0276, pre: 398.3, gt: 433.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [333/800] Iter:[140/150], Time: 0.61, lr: 6.2864, Loss: 0.0276, pre: 1349.2, gt: 1323.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [334/800] Iter:[0/150], Time: 1.75, lr: 6.2852, Loss: 0.0251, pre: 1458.2, gt: 1123.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [334/800] Iter:[20/150], Time: 0.64, lr: 6.2826, Loss: 0.0268, pre: 1162.4, gt: 1120.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [334/800] Iter:[40/150], Time: 0.61, lr: 6.2801, Loss: 0.0287, pre: 1392.7, gt: 1306.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [334/800] Iter:[60/150], Time: 0.60, lr: 6.2776, Loss: 0.0287, pre: 841.2, gt: 757.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [334/800] Iter:[80/150], Time: 0.60, lr: 6.2751, Loss: 0.0285, pre: 356.2, gt: 375.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [334/800] Iter:[100/150], Time: 0.59, lr: 6.2725, Loss: 0.0282, pre: 1357.7, gt: 1240.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [334/800] Iter:[120/150], Time: 0.59, lr: 6.2700, Loss: 0.0276, pre: 678.8, gt: 642.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [334/800] Iter:[140/150], Time: 0.59, lr: 6.2675, Loss: 0.0276, pre: 746.3, gt: 683.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [335/800] Iter:[0/150], Time: 2.07, lr: 6.2662, Loss: 0.0180, pre: 1091.9, gt: 934.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [335/800] Iter:[20/150], Time: 0.65, lr: 6.2637, Loss: 0.0267, pre: 2468.5, gt: 2843.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [335/800] Iter:[40/150], Time: 0.62, lr: 6.2611, Loss: 0.0254, pre: 3841.9, gt: 4069.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [335/800] Iter:[60/150], Time: 0.61, lr: 6.2586, Loss: 0.0255, pre: 1210.4, gt: 1211.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [335/800] Iter:[80/150], Time: 0.60, lr: 6.2561, Loss: 0.0262, pre: 1555.5, gt: 1543.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [335/800] Iter:[100/150], Time: 0.60, lr: 6.2535, Loss: 0.0267, pre: 680.4, gt: 625.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [335/800] Iter:[120/150], Time: 0.60, lr: 6.2510, Loss: 0.0273, pre: 3051.2, gt: 2581.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [335/800] Iter:[140/150], Time: 0.59, lr: 6.2485, Loss: 0.0272, pre: 1011.8, gt: 1135.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  99.56, Best_MAE:  92.4190 MSE:  177.0083,Best_MSE:  153.1174\n","Epoch: [336/800] Iter:[0/150], Time: 4.16, lr: 6.2472, Loss: 0.0194, pre: 378.1, gt: 388.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [336/800] Iter:[20/150], Time: 0.76, lr: 6.2447, Loss: 0.0304, pre: 2236.4, gt: 2315.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [336/800] Iter:[40/150], Time: 0.67, lr: 6.2421, Loss: 0.0285, pre: 2108.5, gt: 2077.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [336/800] Iter:[60/150], Time: 0.64, lr: 6.2396, Loss: 0.0277, pre: 239.3, gt: 223.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [336/800] Iter:[80/150], Time: 0.63, lr: 6.2371, Loss: 0.0284, pre: 1656.7, gt: 1998.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [336/800] Iter:[100/150], Time: 0.62, lr: 6.2345, Loss: 0.0281, pre: 2432.5, gt: 2269.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [336/800] Iter:[120/150], Time: 0.61, lr: 6.2320, Loss: 0.0281, pre: 1531.0, gt: 1447.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [336/800] Iter:[140/150], Time: 0.61, lr: 6.2295, Loss: 0.0275, pre: 543.0, gt: 492.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [337/800] Iter:[0/150], Time: 2.51, lr: 6.2282, Loss: 0.0629, pre: 7956.6, gt: 9114.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [337/800] Iter:[20/150], Time: 0.68, lr: 6.2257, Loss: 0.0269, pre: 936.1, gt: 899.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [337/800] Iter:[40/150], Time: 0.63, lr: 6.2231, Loss: 0.0264, pre: 1857.8, gt: 2019.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [337/800] Iter:[60/150], Time: 0.61, lr: 6.2206, Loss: 0.0276, pre: 356.7, gt: 420.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [337/800] Iter:[80/150], Time: 0.61, lr: 6.2181, Loss: 0.0281, pre: 608.8, gt: 537.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [337/800] Iter:[100/150], Time: 0.60, lr: 6.2155, Loss: 0.0273, pre: 1742.3, gt: 1559.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [337/800] Iter:[120/150], Time: 0.60, lr: 6.2130, Loss: 0.0275, pre: 617.4, gt: 722.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [337/800] Iter:[140/150], Time: 0.60, lr: 6.2104, Loss: 0.0272, pre: 1446.7, gt: 1877.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [338/800] Iter:[0/150], Time: 1.94, lr: 6.2092, Loss: 0.0248, pre: 806.9, gt: 818.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [338/800] Iter:[20/150], Time: 0.65, lr: 6.2066, Loss: 0.0258, pre: 2617.7, gt: 2999.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [338/800] Iter:[40/150], Time: 0.62, lr: 6.2041, Loss: 0.0254, pre: 2848.8, gt: 2890.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [338/800] Iter:[60/150], Time: 0.60, lr: 6.2016, Loss: 0.0269, pre: 641.8, gt: 892.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [338/800] Iter:[80/150], Time: 0.60, lr: 6.1990, Loss: 0.0267, pre: 915.6, gt: 838.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [338/800] Iter:[100/150], Time: 0.60, lr: 6.1965, Loss: 0.0268, pre: 1670.7, gt: 2038.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [338/800] Iter:[120/150], Time: 0.59, lr: 6.1939, Loss: 0.0269, pre: 899.4, gt: 1018.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [338/800] Iter:[140/150], Time: 0.59, lr: 6.1914, Loss: 0.0264, pre: 1986.1, gt: 1874.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  111.49, Best_MAE:  92.4190 MSE:  193.9048,Best_MSE:  153.1174\n","Epoch: [339/800] Iter:[0/150], Time: 3.87, lr: 6.1901, Loss: 0.0167, pre: 713.6, gt: 707.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [339/800] Iter:[20/150], Time: 0.74, lr: 6.1876, Loss: 0.0249, pre: 1337.7, gt: 1245.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [339/800] Iter:[40/150], Time: 0.66, lr: 6.1850, Loss: 0.0256, pre: 4076.2, gt: 4036.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [339/800] Iter:[60/150], Time: 0.64, lr: 6.1825, Loss: 0.0267, pre: 1901.1, gt: 2107.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [339/800] Iter:[80/150], Time: 0.62, lr: 6.1800, Loss: 0.0265, pre: 680.1, gt: 754.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [339/800] Iter:[100/150], Time: 0.62, lr: 6.1774, Loss: 0.0264, pre: 821.3, gt: 809.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [339/800] Iter:[120/150], Time: 0.61, lr: 6.1749, Loss: 0.0264, pre: 1158.5, gt: 1336.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [339/800] Iter:[140/150], Time: 0.61, lr: 6.1723, Loss: 0.0266, pre: 868.7, gt: 791.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [340/800] Iter:[0/150], Time: 1.86, lr: 6.1711, Loss: 0.0287, pre: 1293.0, gt: 1197.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [340/800] Iter:[20/150], Time: 0.65, lr: 6.1685, Loss: 0.0291, pre: 1039.4, gt: 1292.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [340/800] Iter:[40/150], Time: 0.62, lr: 6.1660, Loss: 0.0299, pre: 2801.4, gt: 3670.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [340/800] Iter:[60/150], Time: 0.60, lr: 6.1634, Loss: 0.0282, pre: 2487.9, gt: 2319.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [340/800] Iter:[80/150], Time: 0.60, lr: 6.1609, Loss: 0.0275, pre: 294.0, gt: 396.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [340/800] Iter:[100/150], Time: 0.60, lr: 6.1583, Loss: 0.0273, pre: 728.2, gt: 746.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [340/800] Iter:[120/150], Time: 0.59, lr: 6.1558, Loss: 0.0272, pre: 6552.3, gt: 7816.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [340/800] Iter:[140/150], Time: 0.59, lr: 6.1533, Loss: 0.0271, pre: 1197.7, gt: 1073.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [341/800] Iter:[0/150], Time: 1.71, lr: 6.1520, Loss: 0.0268, pre: 784.1, gt: 992.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [341/800] Iter:[20/150], Time: 0.64, lr: 6.1494, Loss: 0.0257, pre: 1547.8, gt: 1601.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [341/800] Iter:[40/150], Time: 0.61, lr: 6.1469, Loss: 0.0267, pre: 2798.0, gt: 2710.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [341/800] Iter:[60/150], Time: 0.60, lr: 6.1443, Loss: 0.0260, pre: 1447.5, gt: 1384.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [341/800] Iter:[80/150], Time: 0.60, lr: 6.1418, Loss: 0.0260, pre: 1890.1, gt: 1911.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [341/800] Iter:[100/150], Time: 0.59, lr: 6.1392, Loss: 0.0276, pre: 3914.8, gt: 3344.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [341/800] Iter:[120/150], Time: 0.59, lr: 6.1367, Loss: 0.0278, pre: 3790.3, gt: 4144.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [341/800] Iter:[140/150], Time: 0.59, lr: 6.1342, Loss: 0.0271, pre: 727.3, gt: 751.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  165.67, Best_MAE:  92.4190 MSE:  347.7110,Best_MSE:  153.1174\n","Epoch: [342/800] Iter:[0/150], Time: 4.31, lr: 6.1329, Loss: 0.0335, pre: 2344.4, gt: 2134.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [342/800] Iter:[20/150], Time: 0.77, lr: 6.1303, Loss: 0.0268, pre: 3920.6, gt: 3065.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [342/800] Iter:[40/150], Time: 0.68, lr: 6.1278, Loss: 0.0248, pre: 324.3, gt: 336.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [342/800] Iter:[60/150], Time: 0.65, lr: 6.1252, Loss: 0.0256, pre: 1154.7, gt: 1076.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [342/800] Iter:[80/150], Time: 0.63, lr: 6.1227, Loss: 0.0257, pre: 967.5, gt: 1172.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [342/800] Iter:[100/150], Time: 0.62, lr: 6.1201, Loss: 0.0262, pre: 1957.5, gt: 1793.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [342/800] Iter:[120/150], Time: 0.61, lr: 6.1176, Loss: 0.0268, pre: 1725.7, gt: 1595.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [342/800] Iter:[140/150], Time: 0.61, lr: 6.1150, Loss: 0.0265, pre: 2755.2, gt: 2520.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [343/800] Iter:[0/150], Time: 2.12, lr: 6.1138, Loss: 0.0337, pre: 2826.9, gt: 2524.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [343/800] Iter:[20/150], Time: 0.66, lr: 6.1112, Loss: 0.0256, pre: 2436.0, gt: 2719.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [343/800] Iter:[40/150], Time: 0.62, lr: 6.1087, Loss: 0.0270, pre: 1726.8, gt: 1935.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [343/800] Iter:[60/150], Time: 0.61, lr: 6.1061, Loss: 0.0277, pre: 1492.1, gt: 1570.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [343/800] Iter:[80/150], Time: 0.60, lr: 6.1036, Loss: 0.0281, pre: 1784.3, gt: 1489.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [343/800] Iter:[100/150], Time: 0.60, lr: 6.1010, Loss: 0.0274, pre: 1198.6, gt: 1250.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [343/800] Iter:[120/150], Time: 0.59, lr: 6.0985, Loss: 0.0272, pre: 800.9, gt: 791.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [343/800] Iter:[140/150], Time: 0.59, lr: 6.0959, Loss: 0.0277, pre: 6285.3, gt: 5817.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [344/800] Iter:[0/150], Time: 2.14, lr: 6.0946, Loss: 0.0326, pre: 1447.9, gt: 1209.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [344/800] Iter:[20/150], Time: 0.66, lr: 6.0921, Loss: 0.0279, pre: 890.5, gt: 810.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [344/800] Iter:[40/150], Time: 0.62, lr: 6.0895, Loss: 0.0274, pre: 1055.0, gt: 1232.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [344/800] Iter:[60/150], Time: 0.61, lr: 6.0870, Loss: 0.0277, pre: 2000.3, gt: 2157.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [344/800] Iter:[80/150], Time: 0.60, lr: 6.0844, Loss: 0.0279, pre: 1594.0, gt: 1435.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [344/800] Iter:[100/150], Time: 0.60, lr: 6.0819, Loss: 0.0281, pre: 1356.9, gt: 1427.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [344/800] Iter:[120/150], Time: 0.60, lr: 6.0793, Loss: 0.0278, pre: 764.0, gt: 826.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [344/800] Iter:[140/150], Time: 0.59, lr: 6.0768, Loss: 0.0274, pre: 4096.6, gt: 4572.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  133.53, Best_MAE:  92.4190 MSE:  243.2239,Best_MSE:  153.1174\n","Epoch: [345/800] Iter:[0/150], Time: 4.54, lr: 6.0755, Loss: 0.0256, pre: 1768.7, gt: 2075.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [345/800] Iter:[20/150], Time: 0.77, lr: 6.0729, Loss: 0.0276, pre: 970.3, gt: 813.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [345/800] Iter:[40/150], Time: 0.68, lr: 6.0704, Loss: 0.0267, pre: 1034.1, gt: 1135.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [345/800] Iter:[60/150], Time: 0.65, lr: 6.0678, Loss: 0.0261, pre: 1490.7, gt: 1971.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [345/800] Iter:[80/150], Time: 0.63, lr: 6.0653, Loss: 0.0265, pre: 2170.9, gt: 2155.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [345/800] Iter:[100/150], Time: 0.62, lr: 6.0627, Loss: 0.0273, pre: 5654.4, gt: 4794.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [345/800] Iter:[120/150], Time: 0.62, lr: 6.0601, Loss: 0.0270, pre: 694.8, gt: 709.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [345/800] Iter:[140/150], Time: 0.61, lr: 6.0576, Loss: 0.0271, pre: 1320.9, gt: 1095.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [346/800] Iter:[0/150], Time: 1.71, lr: 6.0563, Loss: 0.0118, pre: 851.8, gt: 810.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [346/800] Iter:[20/150], Time: 0.64, lr: 6.0537, Loss: 0.0247, pre: 1765.2, gt: 1468.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [346/800] Iter:[40/150], Time: 0.61, lr: 6.0512, Loss: 0.0280, pre: 2058.5, gt: 2171.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [346/800] Iter:[60/150], Time: 0.60, lr: 6.0486, Loss: 0.0285, pre: 795.8, gt: 868.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [346/800] Iter:[80/150], Time: 0.60, lr: 6.0461, Loss: 0.0281, pre: 1698.7, gt: 1466.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [346/800] Iter:[100/150], Time: 0.60, lr: 6.0435, Loss: 0.0271, pre: 1187.9, gt: 1156.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [346/800] Iter:[120/150], Time: 0.59, lr: 6.0410, Loss: 0.0266, pre: 673.9, gt: 839.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [346/800] Iter:[140/150], Time: 0.59, lr: 6.0384, Loss: 0.0270, pre: 1204.9, gt: 1258.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [347/800] Iter:[0/150], Time: 2.25, lr: 6.0371, Loss: 0.0247, pre: 976.4, gt: 794.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [347/800] Iter:[20/150], Time: 0.66, lr: 6.0346, Loss: 0.0252, pre: 1911.3, gt: 2454.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [347/800] Iter:[40/150], Time: 0.62, lr: 6.0320, Loss: 0.0267, pre: 4532.6, gt: 4553.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [347/800] Iter:[60/150], Time: 0.61, lr: 6.0294, Loss: 0.0259, pre: 1025.9, gt: 897.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [347/800] Iter:[80/150], Time: 0.60, lr: 6.0269, Loss: 0.0265, pre: 1925.9, gt: 2190.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [347/800] Iter:[100/150], Time: 0.60, lr: 6.0243, Loss: 0.0263, pre: 875.9, gt: 991.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [347/800] Iter:[120/150], Time: 0.60, lr: 6.0218, Loss: 0.0266, pre: 1577.8, gt: 1793.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [347/800] Iter:[140/150], Time: 0.59, lr: 6.0192, Loss: 0.0269, pre: 1679.9, gt: 1776.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  118.89, Best_MAE:  92.4190 MSE:  198.5112,Best_MSE:  153.1174\n","Epoch: [348/800] Iter:[0/150], Time: 4.29, lr: 6.0179, Loss: 0.0173, pre: 552.0, gt: 561.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [348/800] Iter:[20/150], Time: 0.76, lr: 6.0154, Loss: 0.0261, pre: 1754.9, gt: 1730.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [348/800] Iter:[40/150], Time: 0.67, lr: 6.0128, Loss: 0.0245, pre: 1127.7, gt: 814.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [348/800] Iter:[60/150], Time: 0.64, lr: 6.0102, Loss: 0.0251, pre: 3657.2, gt: 3628.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [348/800] Iter:[80/150], Time: 0.63, lr: 6.0077, Loss: 0.0266, pre: 679.6, gt: 675.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [348/800] Iter:[100/150], Time: 0.62, lr: 6.0051, Loss: 0.0261, pre: 1313.3, gt: 1272.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [348/800] Iter:[120/150], Time: 0.61, lr: 6.0026, Loss: 0.0263, pre: 2084.4, gt: 2514.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [348/800] Iter:[140/150], Time: 0.61, lr: 6.0000, Loss: 0.0257, pre: 1495.9, gt: 1403.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [349/800] Iter:[0/150], Time: 2.12, lr: 5.9987, Loss: 0.0413, pre: 3514.8, gt: 3539.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [349/800] Iter:[20/150], Time: 0.66, lr: 5.9961, Loss: 0.0279, pre: 4464.4, gt: 4770.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [349/800] Iter:[40/150], Time: 0.62, lr: 5.9936, Loss: 0.0254, pre: 932.5, gt: 1091.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [349/800] Iter:[60/150], Time: 0.61, lr: 5.9910, Loss: 0.0268, pre: 2834.2, gt: 3523.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [349/800] Iter:[80/150], Time: 0.60, lr: 5.9885, Loss: 0.0261, pre: 1335.3, gt: 1220.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [349/800] Iter:[100/150], Time: 0.60, lr: 5.9859, Loss: 0.0259, pre: 951.3, gt: 941.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [349/800] Iter:[120/150], Time: 0.60, lr: 5.9833, Loss: 0.0261, pre: 2458.7, gt: 2324.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [349/800] Iter:[140/150], Time: 0.59, lr: 5.9808, Loss: 0.0258, pre: 673.8, gt: 597.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [350/800] Iter:[0/150], Time: 1.99, lr: 5.9795, Loss: 0.0202, pre: 1066.1, gt: 1108.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [350/800] Iter:[20/150], Time: 0.65, lr: 5.9769, Loss: 0.0267, pre: 1460.8, gt: 1340.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [350/800] Iter:[40/150], Time: 0.62, lr: 5.9743, Loss: 0.0255, pre: 1105.4, gt: 1134.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [350/800] Iter:[60/150], Time: 0.61, lr: 5.9718, Loss: 0.0251, pre: 2021.7, gt: 1978.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [350/800] Iter:[80/150], Time: 0.60, lr: 5.9692, Loss: 0.0257, pre: 1333.6, gt: 1335.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [350/800] Iter:[100/150], Time: 0.60, lr: 5.9666, Loss: 0.0257, pre: 1240.7, gt: 1239.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [350/800] Iter:[120/150], Time: 0.59, lr: 5.9641, Loss: 0.0265, pre: 960.5, gt: 1008.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [350/800] Iter:[140/150], Time: 0.59, lr: 5.9615, Loss: 0.0267, pre: 1278.4, gt: 1102.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  108.55, Best_MAE:  92.4190 MSE:  192.6354,Best_MSE:  153.1174\n","Epoch: [351/800] Iter:[0/150], Time: 4.61, lr: 5.9602, Loss: 0.0269, pre: 2399.4, gt: 2592.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [351/800] Iter:[20/150], Time: 0.78, lr: 5.9577, Loss: 0.0289, pre: 1765.0, gt: 1984.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [351/800] Iter:[40/150], Time: 0.68, lr: 5.9551, Loss: 0.0304, pre: 618.1, gt: 757.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [351/800] Iter:[60/150], Time: 0.65, lr: 5.9525, Loss: 0.0282, pre: 1733.7, gt: 2021.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [351/800] Iter:[80/150], Time: 0.63, lr: 5.9500, Loss: 0.0273, pre: 585.0, gt: 834.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [351/800] Iter:[100/150], Time: 0.62, lr: 5.9474, Loss: 0.0268, pre: 901.2, gt: 768.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [351/800] Iter:[120/150], Time: 0.62, lr: 5.9448, Loss: 0.0267, pre: 608.9, gt: 727.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [351/800] Iter:[140/150], Time: 0.61, lr: 5.9423, Loss: 0.0264, pre: 1252.9, gt: 1169.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [352/800] Iter:[0/150], Time: 2.59, lr: 5.9410, Loss: 0.0204, pre: 1586.5, gt: 1659.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [352/800] Iter:[20/150], Time: 0.68, lr: 5.9384, Loss: 0.0234, pre: 1748.5, gt: 1765.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [352/800] Iter:[40/150], Time: 0.63, lr: 5.9358, Loss: 0.0273, pre: 439.8, gt: 410.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [352/800] Iter:[60/150], Time: 0.61, lr: 5.9333, Loss: 0.0280, pre: 1268.1, gt: 1636.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [352/800] Iter:[80/150], Time: 0.61, lr: 5.9307, Loss: 0.0294, pre: 6412.7, gt: 8338.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [352/800] Iter:[100/150], Time: 0.60, lr: 5.9281, Loss: 0.0285, pre: 610.6, gt: 571.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [352/800] Iter:[120/150], Time: 0.60, lr: 5.9256, Loss: 0.0283, pre: 1312.7, gt: 1445.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [352/800] Iter:[140/150], Time: 0.60, lr: 5.9230, Loss: 0.0276, pre: 729.1, gt: 758.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [353/800] Iter:[0/150], Time: 2.06, lr: 5.9217, Loss: 0.0285, pre: 1188.2, gt: 1418.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [353/800] Iter:[20/150], Time: 0.65, lr: 5.9191, Loss: 0.0264, pre: 160.8, gt: 185.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [353/800] Iter:[40/150], Time: 0.62, lr: 5.9166, Loss: 0.0269, pre: 1145.5, gt: 1073.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [353/800] Iter:[60/150], Time: 0.61, lr: 5.9140, Loss: 0.0264, pre: 838.5, gt: 791.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [353/800] Iter:[80/150], Time: 0.60, lr: 5.9114, Loss: 0.0265, pre: 946.1, gt: 1046.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [353/800] Iter:[100/150], Time: 0.60, lr: 5.9088, Loss: 0.0263, pre: 1421.7, gt: 1194.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [353/800] Iter:[120/150], Time: 0.60, lr: 5.9063, Loss: 0.0260, pre: 1144.1, gt: 1340.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [353/800] Iter:[140/150], Time: 0.59, lr: 5.9037, Loss: 0.0268, pre: 7055.3, gt: 6917.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  102.60, Best_MAE:  92.4190 MSE:  175.9412,Best_MSE:  153.1174\n","Epoch: [354/800] Iter:[0/150], Time: 4.16, lr: 5.9024, Loss: 0.0166, pre: 712.0, gt: 876.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [354/800] Iter:[20/150], Time: 0.76, lr: 5.8998, Loss: 0.0285, pre: 1582.1, gt: 1626.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [354/800] Iter:[40/150], Time: 0.67, lr: 5.8973, Loss: 0.0303, pre: 677.0, gt: 478.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [354/800] Iter:[60/150], Time: 0.64, lr: 5.8947, Loss: 0.0296, pre: 2437.3, gt: 2852.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [354/800] Iter:[80/150], Time: 0.63, lr: 5.8921, Loss: 0.0287, pre: 1102.2, gt: 871.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [354/800] Iter:[100/150], Time: 0.62, lr: 5.8895, Loss: 0.0286, pre: 776.9, gt: 831.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [354/800] Iter:[120/150], Time: 0.61, lr: 5.8870, Loss: 0.0281, pre: 4699.1, gt: 4521.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [354/800] Iter:[140/150], Time: 0.61, lr: 5.8844, Loss: 0.0282, pre: 455.1, gt: 465.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [355/800] Iter:[0/150], Time: 2.12, lr: 5.8831, Loss: 0.0426, pre: 2404.0, gt: 2319.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [355/800] Iter:[20/150], Time: 0.66, lr: 5.8805, Loss: 0.0279, pre: 2370.4, gt: 2820.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [355/800] Iter:[40/150], Time: 0.62, lr: 5.8780, Loss: 0.0269, pre: 1981.1, gt: 1963.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [355/800] Iter:[60/150], Time: 0.61, lr: 5.8754, Loss: 0.0269, pre: 1179.3, gt: 1341.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [355/800] Iter:[80/150], Time: 0.60, lr: 5.8728, Loss: 0.0278, pre: 619.6, gt: 584.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [355/800] Iter:[100/150], Time: 0.60, lr: 5.8702, Loss: 0.0278, pre: 1148.6, gt: 1099.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [355/800] Iter:[120/150], Time: 0.60, lr: 5.8677, Loss: 0.0273, pre: 766.6, gt: 890.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [355/800] Iter:[140/150], Time: 0.59, lr: 5.8651, Loss: 0.0266, pre: 955.5, gt: 1071.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [356/800] Iter:[0/150], Time: 1.82, lr: 5.8638, Loss: 0.0271, pre: 1836.6, gt: 1549.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [356/800] Iter:[20/150], Time: 0.64, lr: 5.8612, Loss: 0.0269, pre: 224.8, gt: 94.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [356/800] Iter:[40/150], Time: 0.61, lr: 5.8586, Loss: 0.0263, pre: 209.7, gt: 206.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [356/800] Iter:[60/150], Time: 0.60, lr: 5.8561, Loss: 0.0264, pre: 1862.6, gt: 1796.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [356/800] Iter:[80/150], Time: 0.60, lr: 5.8535, Loss: 0.0269, pre: 647.7, gt: 706.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [356/800] Iter:[100/150], Time: 0.59, lr: 5.8509, Loss: 0.0270, pre: 1724.4, gt: 2118.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [356/800] Iter:[120/150], Time: 0.59, lr: 5.8483, Loss: 0.0270, pre: 2430.7, gt: 2355.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [356/800] Iter:[140/150], Time: 0.59, lr: 5.8457, Loss: 0.0270, pre: 501.3, gt: 488.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  97.55, Best_MAE:  92.4190 MSE:  162.4720,Best_MSE:  153.1174\n","Epoch: [357/800] Iter:[0/150], Time: 4.48, lr: 5.8445, Loss: 0.0275, pre: 1696.4, gt: 1266.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [357/800] Iter:[20/150], Time: 0.77, lr: 5.8419, Loss: 0.0261, pre: 1899.8, gt: 1889.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [357/800] Iter:[40/150], Time: 0.68, lr: 5.8393, Loss: 0.0271, pre: 3131.5, gt: 3526.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [357/800] Iter:[60/150], Time: 0.65, lr: 5.8367, Loss: 0.0271, pre: 1423.5, gt: 1417.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [357/800] Iter:[80/150], Time: 0.63, lr: 5.8341, Loss: 0.0278, pre: 1320.9, gt: 1416.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [357/800] Iter:[100/150], Time: 0.62, lr: 5.8316, Loss: 0.0271, pre: 745.3, gt: 697.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [357/800] Iter:[120/150], Time: 0.61, lr: 5.8290, Loss: 0.0269, pre: 965.8, gt: 1180.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [357/800] Iter:[140/150], Time: 0.61, lr: 5.8264, Loss: 0.0266, pre: 1753.1, gt: 1689.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [358/800] Iter:[0/150], Time: 2.07, lr: 5.8251, Loss: 0.0386, pre: 2029.8, gt: 1971.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [358/800] Iter:[20/150], Time: 0.65, lr: 5.8225, Loss: 0.0273, pre: 932.3, gt: 1153.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [358/800] Iter:[40/150], Time: 0.62, lr: 5.8200, Loss: 0.0273, pre: 6676.9, gt: 7168.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [358/800] Iter:[60/150], Time: 0.61, lr: 5.8174, Loss: 0.0274, pre: 4521.9, gt: 3701.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [358/800] Iter:[80/150], Time: 0.60, lr: 5.8148, Loss: 0.0271, pre: 2098.4, gt: 2231.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [358/800] Iter:[100/150], Time: 0.60, lr: 5.8122, Loss: 0.0278, pre: 1860.5, gt: 1676.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [358/800] Iter:[120/150], Time: 0.59, lr: 5.8096, Loss: 0.0276, pre: 757.5, gt: 732.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [358/800] Iter:[140/150], Time: 0.59, lr: 5.8070, Loss: 0.0279, pre: 2198.9, gt: 2467.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [359/800] Iter:[0/150], Time: 2.08, lr: 5.8058, Loss: 0.0342, pre: 2199.3, gt: 2555.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [359/800] Iter:[20/150], Time: 0.65, lr: 5.8032, Loss: 0.0256, pre: 494.5, gt: 970.0,acc:0.90, accx8:0.94,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [359/800] Iter:[40/150], Time: 0.62, lr: 5.8006, Loss: 0.0259, pre: 2287.2, gt: 2674.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [359/800] Iter:[60/150], Time: 0.61, lr: 5.7980, Loss: 0.0268, pre: 1143.8, gt: 1077.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [359/800] Iter:[80/150], Time: 0.60, lr: 5.7954, Loss: 0.0260, pre: 639.7, gt: 616.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [359/800] Iter:[100/150], Time: 0.60, lr: 5.7928, Loss: 0.0256, pre: 1691.6, gt: 1639.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [359/800] Iter:[120/150], Time: 0.60, lr: 5.7903, Loss: 0.0262, pre: 2548.8, gt: 2214.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [359/800] Iter:[140/150], Time: 0.59, lr: 5.7877, Loss: 0.0267, pre: 1270.9, gt: 1036.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  137.65, Best_MAE:  92.4190 MSE:  207.7748,Best_MSE:  153.1174\n","Epoch: [360/800] Iter:[0/150], Time: 4.37, lr: 5.7864, Loss: 0.0305, pre: 1515.7, gt: 1619.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [360/800] Iter:[20/150], Time: 0.77, lr: 5.7838, Loss: 0.0300, pre: 1692.2, gt: 1235.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [360/800] Iter:[40/150], Time: 0.68, lr: 5.7812, Loss: 0.0309, pre: 1557.7, gt: 1543.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [360/800] Iter:[60/150], Time: 0.65, lr: 5.7786, Loss: 0.0295, pre: 1430.8, gt: 1452.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [360/800] Iter:[80/150], Time: 0.63, lr: 5.7761, Loss: 0.0289, pre: 2191.2, gt: 2896.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [360/800] Iter:[100/150], Time: 0.62, lr: 5.7735, Loss: 0.0288, pre: 1537.8, gt: 1491.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [360/800] Iter:[120/150], Time: 0.61, lr: 5.7709, Loss: 0.0282, pre: 833.9, gt: 996.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [360/800] Iter:[140/150], Time: 0.61, lr: 5.7683, Loss: 0.0286, pre: 2269.3, gt: 2392.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [361/800] Iter:[0/150], Time: 2.18, lr: 5.7670, Loss: 0.0239, pre: 1964.3, gt: 2077.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [361/800] Iter:[20/150], Time: 0.66, lr: 5.7644, Loss: 0.0219, pre: 896.2, gt: 1100.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [361/800] Iter:[40/150], Time: 0.62, lr: 5.7618, Loss: 0.0244, pre: 1466.1, gt: 1335.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [361/800] Iter:[60/150], Time: 0.61, lr: 5.7593, Loss: 0.0256, pre: 1281.9, gt: 1315.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [361/800] Iter:[80/150], Time: 0.60, lr: 5.7567, Loss: 0.0264, pre: 1414.3, gt: 1400.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [361/800] Iter:[100/150], Time: 0.60, lr: 5.7541, Loss: 0.0268, pre: 1076.1, gt: 1107.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [361/800] Iter:[120/150], Time: 0.60, lr: 5.7515, Loss: 0.0271, pre: 1093.6, gt: 1214.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [361/800] Iter:[140/150], Time: 0.59, lr: 5.7489, Loss: 0.0272, pre: 2122.2, gt: 2380.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [362/800] Iter:[0/150], Time: 1.76, lr: 5.7476, Loss: 0.0263, pre: 2199.2, gt: 2051.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [362/800] Iter:[20/150], Time: 0.64, lr: 5.7450, Loss: 0.0274, pre: 2049.3, gt: 1856.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [362/800] Iter:[40/150], Time: 0.62, lr: 5.7424, Loss: 0.0276, pre: 316.7, gt: 404.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [362/800] Iter:[60/150], Time: 0.61, lr: 5.7399, Loss: 0.0269, pre: 653.3, gt: 747.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [362/800] Iter:[80/150], Time: 0.60, lr: 5.7373, Loss: 0.0271, pre: 497.6, gt: 484.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [362/800] Iter:[100/150], Time: 0.60, lr: 5.7347, Loss: 0.0269, pre: 1631.2, gt: 2071.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [362/800] Iter:[120/150], Time: 0.59, lr: 5.7321, Loss: 0.0270, pre: 2093.9, gt: 2173.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [362/800] Iter:[140/150], Time: 0.59, lr: 5.7295, Loss: 0.0271, pre: 3865.1, gt: 3701.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  119.88, Best_MAE:  92.4190 MSE:  217.6968,Best_MSE:  153.1174\n","Epoch: [363/800] Iter:[0/150], Time: 4.40, lr: 5.7282, Loss: 0.0127, pre: 639.2, gt: 518.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [363/800] Iter:[20/150], Time: 0.77, lr: 5.7256, Loss: 0.0248, pre: 1002.2, gt: 1104.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [363/800] Iter:[40/150], Time: 0.68, lr: 5.7230, Loss: 0.0254, pre: 1016.8, gt: 963.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [363/800] Iter:[60/150], Time: 0.65, lr: 5.7205, Loss: 0.0258, pre: 1333.4, gt: 1444.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [363/800] Iter:[80/150], Time: 0.63, lr: 5.7179, Loss: 0.0255, pre: 650.7, gt: 910.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [363/800] Iter:[100/150], Time: 0.62, lr: 5.7153, Loss: 0.0264, pre: 2848.2, gt: 2788.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [363/800] Iter:[120/150], Time: 0.62, lr: 5.7127, Loss: 0.0268, pre: 936.7, gt: 843.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [363/800] Iter:[140/150], Time: 0.61, lr: 5.7101, Loss: 0.0269, pre: 1078.2, gt: 1008.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [364/800] Iter:[0/150], Time: 2.00, lr: 5.7088, Loss: 0.0168, pre: 857.9, gt: 989.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [364/800] Iter:[20/150], Time: 0.65, lr: 5.7062, Loss: 0.0235, pre: 4638.0, gt: 5049.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [364/800] Iter:[40/150], Time: 0.62, lr: 5.7036, Loss: 0.0252, pre: 1588.2, gt: 1950.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [364/800] Iter:[60/150], Time: 0.61, lr: 5.7010, Loss: 0.0256, pre: 1744.5, gt: 1869.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [364/800] Iter:[80/150], Time: 0.60, lr: 5.6984, Loss: 0.0254, pre: 2232.8, gt: 2325.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [364/800] Iter:[100/150], Time: 0.60, lr: 5.6959, Loss: 0.0255, pre: 3434.0, gt: 4294.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [364/800] Iter:[120/150], Time: 0.60, lr: 5.6933, Loss: 0.0251, pre: 1601.9, gt: 1854.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [364/800] Iter:[140/150], Time: 0.59, lr: 5.6907, Loss: 0.0262, pre: 2766.8, gt: 2245.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [365/800] Iter:[0/150], Time: 2.24, lr: 5.6894, Loss: 0.0209, pre: 1132.9, gt: 1515.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [365/800] Iter:[20/150], Time: 0.66, lr: 5.6868, Loss: 0.0278, pre: 3184.4, gt: 2691.0,acc:0.89, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [365/800] Iter:[40/150], Time: 0.62, lr: 5.6842, Loss: 0.0272, pre: 834.8, gt: 950.0,acc:0.89, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [365/800] Iter:[60/150], Time: 0.61, lr: 5.6816, Loss: 0.0280, pre: 3352.5, gt: 3733.0,acc:0.89, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [365/800] Iter:[80/150], Time: 0.60, lr: 5.6790, Loss: 0.0274, pre: 127.0, gt: 94.0,acc:0.89, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [365/800] Iter:[100/150], Time: 0.60, lr: 5.6764, Loss: 0.0275, pre: 1116.6, gt: 1239.0,acc:0.89, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [365/800] Iter:[120/150], Time: 0.60, lr: 5.6738, Loss: 0.0273, pre: 1331.3, gt: 1413.0,acc:0.89, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [365/800] Iter:[140/150], Time: 0.59, lr: 5.6712, Loss: 0.0276, pre: 2222.2, gt: 2357.0,acc:0.89, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  91.73, Best_MAE:  91.7303 MSE:  147.0617,Best_MSE:  147.0617\n","Epoch: [366/800] Iter:[0/150], Time: 2.72, lr: 5.6699, Loss: 0.0315, pre: 2981.7, gt: 2875.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [366/800] Iter:[20/150], Time: 0.69, lr: 5.6673, Loss: 0.0257, pre: 5638.0, gt: 5341.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [366/800] Iter:[40/150], Time: 0.64, lr: 5.6648, Loss: 0.0263, pre: 4188.4, gt: 3631.0,acc:0.89, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [366/800] Iter:[60/150], Time: 0.62, lr: 5.6622, Loss: 0.0261, pre: 822.7, gt: 833.0,acc:0.89, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [366/800] Iter:[80/150], Time: 0.61, lr: 5.6596, Loss: 0.0261, pre: 590.4, gt: 324.0,acc:0.89, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [366/800] Iter:[100/150], Time: 0.61, lr: 5.6570, Loss: 0.0259, pre: 1152.5, gt: 1168.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [366/800] Iter:[120/150], Time: 0.60, lr: 5.6544, Loss: 0.0261, pre: 2024.1, gt: 1880.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [366/800] Iter:[140/150], Time: 0.60, lr: 5.6518, Loss: 0.0263, pre: 4133.2, gt: 3976.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [367/800] Iter:[0/150], Time: 2.15, lr: 5.6505, Loss: 0.0327, pre: 2577.6, gt: 2643.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [367/800] Iter:[20/150], Time: 0.66, lr: 5.6479, Loss: 0.0255, pre: 1807.0, gt: 1841.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [367/800] Iter:[40/150], Time: 0.62, lr: 5.6453, Loss: 0.0252, pre: 2987.1, gt: 3016.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [367/800] Iter:[60/150], Time: 0.61, lr: 5.6427, Loss: 0.0248, pre: 846.7, gt: 947.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [367/800] Iter:[80/150], Time: 0.60, lr: 5.6401, Loss: 0.0242, pre: 1406.9, gt: 1380.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [367/800] Iter:[100/150], Time: 0.60, lr: 5.6375, Loss: 0.0249, pre: 412.1, gt: 469.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [367/800] Iter:[120/150], Time: 0.60, lr: 5.6349, Loss: 0.0257, pre: 279.1, gt: 302.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [367/800] Iter:[140/150], Time: 0.59, lr: 5.6323, Loss: 0.0255, pre: 1703.0, gt: 1969.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [368/800] Iter:[0/150], Time: 2.33, lr: 5.6310, Loss: 0.0189, pre: 745.9, gt: 788.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [368/800] Iter:[20/150], Time: 0.67, lr: 5.6284, Loss: 0.0254, pre: 1286.7, gt: 1238.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [368/800] Iter:[40/150], Time: 0.63, lr: 5.6258, Loss: 0.0243, pre: 1680.6, gt: 1643.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [368/800] Iter:[60/150], Time: 0.61, lr: 5.6233, Loss: 0.0250, pre: 925.6, gt: 1018.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [368/800] Iter:[80/150], Time: 0.60, lr: 5.6207, Loss: 0.0261, pre: 1380.0, gt: 1514.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [368/800] Iter:[100/150], Time: 0.60, lr: 5.6181, Loss: 0.0257, pre: 1817.8, gt: 1938.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [368/800] Iter:[120/150], Time: 0.60, lr: 5.6155, Loss: 0.0261, pre: 2341.0, gt: 2203.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [368/800] Iter:[140/150], Time: 0.59, lr: 5.6129, Loss: 0.0263, pre: 750.0, gt: 919.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  97.16, Best_MAE:  91.7303 MSE:  169.6714,Best_MSE:  147.0617\n","Epoch: [369/800] Iter:[0/150], Time: 4.65, lr: 5.6116, Loss: 0.0262, pre: 1900.2, gt: 2221.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [369/800] Iter:[20/150], Time: 0.78, lr: 5.6090, Loss: 0.0274, pre: 1325.1, gt: 1530.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [369/800] Iter:[40/150], Time: 0.68, lr: 5.6064, Loss: 0.0282, pre: 778.8, gt: 788.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [369/800] Iter:[60/150], Time: 0.65, lr: 5.6038, Loss: 0.0285, pre: 2217.9, gt: 2613.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [369/800] Iter:[80/150], Time: 0.63, lr: 5.6012, Loss: 0.0280, pre: 2057.1, gt: 2007.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [369/800] Iter:[100/150], Time: 0.62, lr: 5.5986, Loss: 0.0272, pre: 886.9, gt: 949.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [369/800] Iter:[120/150], Time: 0.62, lr: 5.5960, Loss: 0.0263, pre: 218.4, gt: 201.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [369/800] Iter:[140/150], Time: 0.61, lr: 5.5934, Loss: 0.0265, pre: 1059.3, gt: 837.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [370/800] Iter:[0/150], Time: 2.51, lr: 5.5921, Loss: 0.0387, pre: 2252.3, gt: 2653.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [370/800] Iter:[20/150], Time: 0.67, lr: 5.5895, Loss: 0.0296, pre: 625.9, gt: 630.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [370/800] Iter:[40/150], Time: 0.63, lr: 5.5869, Loss: 0.0276, pre: 1422.3, gt: 1139.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [370/800] Iter:[60/150], Time: 0.61, lr: 5.5843, Loss: 0.0284, pre: 822.1, gt: 839.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [370/800] Iter:[80/150], Time: 0.61, lr: 5.5817, Loss: 0.0282, pre: 1621.5, gt: 1646.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [370/800] Iter:[100/150], Time: 0.60, lr: 5.5791, Loss: 0.0280, pre: 1885.9, gt: 1928.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [370/800] Iter:[120/150], Time: 0.60, lr: 5.5765, Loss: 0.0273, pre: 1033.8, gt: 1176.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [370/800] Iter:[140/150], Time: 0.60, lr: 5.5739, Loss: 0.0268, pre: 885.8, gt: 818.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [371/800] Iter:[0/150], Time: 1.92, lr: 5.5726, Loss: 0.0258, pre: 1162.3, gt: 1180.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [371/800] Iter:[20/150], Time: 0.65, lr: 5.5700, Loss: 0.0259, pre: 468.5, gt: 479.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [371/800] Iter:[40/150], Time: 0.62, lr: 5.5674, Loss: 0.0260, pre: 729.1, gt: 849.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [371/800] Iter:[60/150], Time: 0.60, lr: 5.5648, Loss: 0.0266, pre: 861.9, gt: 773.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [371/800] Iter:[80/150], Time: 0.60, lr: 5.5622, Loss: 0.0266, pre: 1075.7, gt: 1209.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [371/800] Iter:[100/150], Time: 0.60, lr: 5.5596, Loss: 0.0269, pre: 519.1, gt: 562.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [371/800] Iter:[120/150], Time: 0.59, lr: 5.5570, Loss: 0.0275, pre: 3630.1, gt: 3219.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [371/800] Iter:[140/150], Time: 0.59, lr: 5.5544, Loss: 0.0274, pre: 1345.1, gt: 1341.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  140.47, Best_MAE:  91.7303 MSE:  208.6506,Best_MSE:  147.0617\n","Epoch: [372/800] Iter:[0/150], Time: 4.59, lr: 5.5531, Loss: 0.0289, pre: 1962.7, gt: 1885.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [372/800] Iter:[20/150], Time: 0.77, lr: 5.5505, Loss: 0.0235, pre: 709.0, gt: 883.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [372/800] Iter:[40/150], Time: 0.68, lr: 5.5479, Loss: 0.0237, pre: 906.7, gt: 734.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [372/800] Iter:[60/150], Time: 0.65, lr: 5.5453, Loss: 0.0248, pre: 619.4, gt: 772.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [372/800] Iter:[80/150], Time: 0.63, lr: 5.5427, Loss: 0.0253, pre: 1397.7, gt: 1333.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [372/800] Iter:[100/150], Time: 0.62, lr: 5.5401, Loss: 0.0257, pre: 823.0, gt: 747.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [372/800] Iter:[120/150], Time: 0.62, lr: 5.5375, Loss: 0.0261, pre: 1223.3, gt: 1031.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [372/800] Iter:[140/150], Time: 0.61, lr: 5.5349, Loss: 0.0257, pre: 715.7, gt: 631.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [373/800] Iter:[0/150], Time: 1.85, lr: 5.5336, Loss: 0.0362, pre: 1463.2, gt: 1472.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [373/800] Iter:[20/150], Time: 0.65, lr: 5.5310, Loss: 0.0257, pre: 726.2, gt: 729.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [373/800] Iter:[40/150], Time: 0.62, lr: 5.5284, Loss: 0.0265, pre: 2558.6, gt: 2736.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [373/800] Iter:[60/150], Time: 0.60, lr: 5.5258, Loss: 0.0263, pre: 1368.1, gt: 1187.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [373/800] Iter:[80/150], Time: 0.60, lr: 5.5232, Loss: 0.0264, pre: 3713.1, gt: 3608.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [373/800] Iter:[100/150], Time: 0.60, lr: 5.5206, Loss: 0.0263, pre: 586.5, gt: 772.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [373/800] Iter:[120/150], Time: 0.59, lr: 5.5180, Loss: 0.0270, pre: 1250.0, gt: 1178.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [373/800] Iter:[140/150], Time: 0.59, lr: 5.5154, Loss: 0.0268, pre: 1742.0, gt: 1939.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [374/800] Iter:[0/150], Time: 2.33, lr: 5.5141, Loss: 0.0305, pre: 1504.4, gt: 1576.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [374/800] Iter:[20/150], Time: 0.67, lr: 5.5115, Loss: 0.0331, pre: 1883.4, gt: 2302.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [374/800] Iter:[40/150], Time: 0.63, lr: 5.5089, Loss: 0.0298, pre: 1176.1, gt: 1261.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [374/800] Iter:[60/150], Time: 0.61, lr: 5.5063, Loss: 0.0298, pre: 1462.9, gt: 1586.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [374/800] Iter:[80/150], Time: 0.60, lr: 5.5037, Loss: 0.0297, pre: 1787.5, gt: 2041.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [374/800] Iter:[100/150], Time: 0.60, lr: 5.5011, Loss: 0.0291, pre: 1229.1, gt: 1480.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [374/800] Iter:[120/150], Time: 0.60, lr: 5.4985, Loss: 0.0283, pre: 2210.8, gt: 2357.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [374/800] Iter:[140/150], Time: 0.60, lr: 5.4959, Loss: 0.0278, pre: 605.3, gt: 529.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  85.97, Best_MAE:  85.9745 MSE:  143.9424,Best_MSE:  143.9424\n","Epoch: [375/800] Iter:[0/150], Time: 3.71, lr: 5.4946, Loss: 0.0182, pre: 603.2, gt: 517.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [375/800] Iter:[20/150], Time: 0.74, lr: 5.4920, Loss: 0.0256, pre: 1407.3, gt: 1334.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [375/800] Iter:[40/150], Time: 0.66, lr: 5.4894, Loss: 0.0286, pre: 1157.2, gt: 1168.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [375/800] Iter:[60/150], Time: 0.64, lr: 5.4868, Loss: 0.0286, pre: 942.5, gt: 1231.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [375/800] Iter:[80/150], Time: 0.62, lr: 5.4842, Loss: 0.0279, pre: 1304.5, gt: 1245.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [375/800] Iter:[100/150], Time: 0.61, lr: 5.4816, Loss: 0.0278, pre: 1301.2, gt: 1443.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [375/800] Iter:[120/150], Time: 0.61, lr: 5.4790, Loss: 0.0273, pre: 923.3, gt: 959.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [375/800] Iter:[140/150], Time: 0.61, lr: 5.4764, Loss: 0.0271, pre: 808.9, gt: 887.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [376/800] Iter:[0/150], Time: 2.06, lr: 5.4751, Loss: 0.0220, pre: 940.8, gt: 978.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [376/800] Iter:[20/150], Time: 0.65, lr: 5.4725, Loss: 0.0294, pre: 1045.6, gt: 1034.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [376/800] Iter:[40/150], Time: 0.62, lr: 5.4699, Loss: 0.0276, pre: 630.7, gt: 815.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [376/800] Iter:[60/150], Time: 0.61, lr: 5.4673, Loss: 0.0269, pre: 3930.4, gt: 3670.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [376/800] Iter:[80/150], Time: 0.60, lr: 5.4647, Loss: 0.0278, pre: 1612.2, gt: 1986.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [376/800] Iter:[100/150], Time: 0.60, lr: 5.4621, Loss: 0.0278, pre: 1839.5, gt: 1652.0,acc:0.91, accx8:0.93,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [376/800] Iter:[120/150], Time: 0.59, lr: 5.4594, Loss: 0.0271, pre: 1163.1, gt: 1173.0,acc:0.91, accx8:0.93,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [376/800] Iter:[140/150], Time: 0.59, lr: 5.4568, Loss: 0.0272, pre: 6737.7, gt: 6013.0,acc:0.91, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [377/800] Iter:[0/150], Time: 1.90, lr: 5.4555, Loss: 0.0213, pre: 1047.3, gt: 829.0,acc:0.91, accx8:0.93,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [377/800] Iter:[20/150], Time: 0.65, lr: 5.4529, Loss: 0.0249, pre: 559.7, gt: 537.0,acc:0.91, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [377/800] Iter:[40/150], Time: 0.62, lr: 5.4503, Loss: 0.0250, pre: 288.2, gt: 324.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [377/800] Iter:[60/150], Time: 0.61, lr: 5.4477, Loss: 0.0257, pre: 1054.4, gt: 1134.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [377/800] Iter:[80/150], Time: 0.60, lr: 5.4451, Loss: 0.0260, pre: 566.7, gt: 491.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [377/800] Iter:[100/150], Time: 0.60, lr: 5.4425, Loss: 0.0264, pre: 1282.5, gt: 1319.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [377/800] Iter:[120/150], Time: 0.59, lr: 5.4399, Loss: 0.0264, pre: 2606.0, gt: 2343.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.94,acc1:0.00\n","Epoch: [377/800] Iter:[140/150], Time: 0.59, lr: 5.4373, Loss: 0.0260, pre: 898.5, gt: 811.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  126.44, Best_MAE:  85.9745 MSE:  248.7166,Best_MSE:  143.9424\n","Epoch: [378/800] Iter:[0/150], Time: 4.63, lr: 5.4360, Loss: 0.0178, pre: 1200.5, gt: 1048.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [378/800] Iter:[20/150], Time: 0.78, lr: 5.4334, Loss: 0.0239, pre: 2630.3, gt: 2664.0,acc:0.90, accx8:0.93,  accx16:0.94,accx32:0.95,acc1:0.00\n","Epoch: [378/800] Iter:[40/150], Time: 0.68, lr: 5.4308, Loss: 0.0256, pre: 921.5, gt: 1014.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [378/800] Iter:[60/150], Time: 0.65, lr: 5.4282, Loss: 0.0245, pre: 1082.0, gt: 1282.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [378/800] Iter:[80/150], Time: 0.63, lr: 5.4256, Loss: 0.0259, pre: 1106.7, gt: 1143.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [378/800] Iter:[100/150], Time: 0.62, lr: 5.4230, Loss: 0.0262, pre: 1204.7, gt: 1168.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [378/800] Iter:[120/150], Time: 0.62, lr: 5.4204, Loss: 0.0264, pre: 2584.5, gt: 2717.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [378/800] Iter:[140/150], Time: 0.61, lr: 5.4178, Loss: 0.0261, pre: 1300.6, gt: 1294.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [379/800] Iter:[0/150], Time: 1.90, lr: 5.4165, Loss: 0.0160, pre: 565.2, gt: 653.0,acc:0.91, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [379/800] Iter:[20/150], Time: 0.64, lr: 5.4138, Loss: 0.0233, pre: 1536.7, gt: 2072.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [379/800] Iter:[40/150], Time: 0.61, lr: 5.4112, Loss: 0.0263, pre: 772.7, gt: 638.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [379/800] Iter:[60/150], Time: 0.60, lr: 5.4086, Loss: 0.0262, pre: 1116.5, gt: 1214.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [379/800] Iter:[80/150], Time: 0.60, lr: 5.4060, Loss: 0.0258, pre: 902.5, gt: 826.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [379/800] Iter:[100/150], Time: 0.59, lr: 5.4034, Loss: 0.0264, pre: 1972.7, gt: 2278.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [379/800] Iter:[120/150], Time: 0.59, lr: 5.4008, Loss: 0.0261, pre: 1093.4, gt: 1104.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [379/800] Iter:[140/150], Time: 0.59, lr: 5.3982, Loss: 0.0260, pre: 1951.6, gt: 2113.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [380/800] Iter:[0/150], Time: 1.67, lr: 5.3969, Loss: 0.0211, pre: 883.2, gt: 970.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [380/800] Iter:[20/150], Time: 0.64, lr: 5.3943, Loss: 0.0275, pre: 910.4, gt: 997.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [380/800] Iter:[40/150], Time: 0.61, lr: 5.3917, Loss: 0.0277, pre: 3185.0, gt: 3658.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [380/800] Iter:[60/150], Time: 0.60, lr: 5.3891, Loss: 0.0275, pre: 1012.2, gt: 955.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [380/800] Iter:[80/150], Time: 0.59, lr: 5.3865, Loss: 0.0277, pre: 1069.7, gt: 1024.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.94,acc1:0.00\n","Epoch: [380/800] Iter:[100/150], Time: 0.59, lr: 5.3839, Loss: 0.0272, pre: 500.5, gt: 507.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [380/800] Iter:[120/150], Time: 0.59, lr: 5.3813, Loss: 0.0272, pre: 801.1, gt: 859.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [380/800] Iter:[140/150], Time: 0.59, lr: 5.3786, Loss: 0.0269, pre: 2683.0, gt: 2808.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  98.32, Best_MAE:  85.9745 MSE:  174.6237,Best_MSE:  143.9424\n","Epoch: [381/800] Iter:[0/150], Time: 4.64, lr: 5.3773, Loss: 0.0327, pre: 2628.0, gt: 2625.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [381/800] Iter:[20/150], Time: 0.78, lr: 5.3747, Loss: 0.0245, pre: 1376.1, gt: 1340.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [381/800] Iter:[40/150], Time: 0.68, lr: 5.3721, Loss: 0.0245, pre: 1058.6, gt: 1540.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [381/800] Iter:[60/150], Time: 0.65, lr: 5.3695, Loss: 0.0250, pre: 1626.5, gt: 1643.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [381/800] Iter:[80/150], Time: 0.64, lr: 5.3669, Loss: 0.0265, pre: 1072.8, gt: 1178.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [381/800] Iter:[100/150], Time: 0.62, lr: 5.3643, Loss: 0.0264, pre: 451.3, gt: 504.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [381/800] Iter:[120/150], Time: 0.62, lr: 5.3617, Loss: 0.0261, pre: 644.7, gt: 707.0,acc:0.90, accx8:0.93,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [381/800] Iter:[140/150], Time: 0.61, lr: 5.3591, Loss: 0.0269, pre: 1096.5, gt: 955.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [382/800] Iter:[0/150], Time: 1.74, lr: 5.3578, Loss: 0.0287, pre: 2803.5, gt: 2726.0,acc:0.90, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [382/800] Iter:[20/150], Time: 0.64, lr: 5.3552, Loss: 0.0282, pre: 1963.0, gt: 2057.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [382/800] Iter:[40/150], Time: 0.61, lr: 5.3526, Loss: 0.0265, pre: 731.7, gt: 799.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [382/800] Iter:[60/150], Time: 0.60, lr: 5.3500, Loss: 0.0260, pre: 1243.3, gt: 1536.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [382/800] Iter:[80/150], Time: 0.60, lr: 5.3473, Loss: 0.0262, pre: 4391.3, gt: 4176.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [382/800] Iter:[100/150], Time: 0.59, lr: 5.3447, Loss: 0.0258, pre: 1093.6, gt: 1257.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [382/800] Iter:[120/150], Time: 0.59, lr: 5.3421, Loss: 0.0262, pre: 2904.5, gt: 3150.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [382/800] Iter:[140/150], Time: 0.59, lr: 5.3395, Loss: 0.0272, pre: 1452.3, gt: 1719.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [383/800] Iter:[0/150], Time: 2.11, lr: 5.3382, Loss: 0.0227, pre: 1087.8, gt: 982.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [383/800] Iter:[20/150], Time: 0.66, lr: 5.3356, Loss: 0.0248, pre: 823.8, gt: 797.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [383/800] Iter:[40/150], Time: 0.62, lr: 5.3330, Loss: 0.0234, pre: 785.1, gt: 762.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [383/800] Iter:[60/150], Time: 0.61, lr: 5.3304, Loss: 0.0252, pre: 2123.7, gt: 2485.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [383/800] Iter:[80/150], Time: 0.60, lr: 5.3278, Loss: 0.0253, pre: 960.9, gt: 1006.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [383/800] Iter:[100/150], Time: 0.60, lr: 5.3252, Loss: 0.0255, pre: 2367.7, gt: 2183.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [383/800] Iter:[120/150], Time: 0.59, lr: 5.3226, Loss: 0.0268, pre: 3481.5, gt: 3893.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [383/800] Iter:[140/150], Time: 0.59, lr: 5.3199, Loss: 0.0266, pre: 1617.4, gt: 1215.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  102.65, Best_MAE:  85.9745 MSE:  152.0080,Best_MSE:  143.9424\n","Epoch: [384/800] Iter:[0/150], Time: 4.24, lr: 5.3186, Loss: 0.0300, pre: 2462.6, gt: 2728.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [384/800] Iter:[20/150], Time: 0.76, lr: 5.3160, Loss: 0.0260, pre: 460.4, gt: 440.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [384/800] Iter:[40/150], Time: 0.67, lr: 5.3134, Loss: 0.0260, pre: 1156.5, gt: 1102.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [384/800] Iter:[60/150], Time: 0.64, lr: 5.3108, Loss: 0.0260, pre: 3557.3, gt: 4165.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [384/800] Iter:[80/150], Time: 0.63, lr: 5.3082, Loss: 0.0260, pre: 278.2, gt: 230.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [384/800] Iter:[100/150], Time: 0.62, lr: 5.3056, Loss: 0.0257, pre: 876.9, gt: 1202.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [384/800] Iter:[120/150], Time: 0.61, lr: 5.3030, Loss: 0.0259, pre: 915.4, gt: 1265.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [384/800] Iter:[140/150], Time: 0.61, lr: 5.3004, Loss: 0.0266, pre: 1984.8, gt: 1967.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [385/800] Iter:[0/150], Time: 1.98, lr: 5.2991, Loss: 0.0382, pre: 2807.0, gt: 2603.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [385/800] Iter:[20/150], Time: 0.65, lr: 5.2964, Loss: 0.0272, pre: 1652.0, gt: 1568.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [385/800] Iter:[40/150], Time: 0.62, lr: 5.2938, Loss: 0.0281, pre: 1071.9, gt: 1084.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [385/800] Iter:[60/150], Time: 0.61, lr: 5.2912, Loss: 0.0274, pre: 947.9, gt: 1102.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [385/800] Iter:[80/150], Time: 0.60, lr: 5.2886, Loss: 0.0278, pre: 2555.0, gt: 2506.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [385/800] Iter:[100/150], Time: 0.60, lr: 5.2860, Loss: 0.0273, pre: 1545.5, gt: 1710.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [385/800] Iter:[120/150], Time: 0.59, lr: 5.2834, Loss: 0.0267, pre: 3212.5, gt: 3191.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [385/800] Iter:[140/150], Time: 0.59, lr: 5.2808, Loss: 0.0269, pre: 370.1, gt: 456.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [386/800] Iter:[0/150], Time: 2.02, lr: 5.2795, Loss: 0.0436, pre: 2575.6, gt: 2786.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [386/800] Iter:[20/150], Time: 0.65, lr: 5.2769, Loss: 0.0325, pre: 1224.9, gt: 1297.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [386/800] Iter:[40/150], Time: 0.62, lr: 5.2743, Loss: 0.0284, pre: 1787.1, gt: 1887.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [386/800] Iter:[60/150], Time: 0.61, lr: 5.2716, Loss: 0.0271, pre: 1713.4, gt: 1789.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [386/800] Iter:[80/150], Time: 0.60, lr: 5.2690, Loss: 0.0263, pre: 1385.3, gt: 1368.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [386/800] Iter:[100/150], Time: 0.60, lr: 5.2664, Loss: 0.0262, pre: 3038.0, gt: 3447.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [386/800] Iter:[120/150], Time: 0.59, lr: 5.2638, Loss: 0.0263, pre: 697.5, gt: 688.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [386/800] Iter:[140/150], Time: 0.59, lr: 5.2612, Loss: 0.0265, pre: 7342.1, gt: 8799.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.012, MAE:  290.09, Best_MAE:  85.9745 MSE:  481.1216,Best_MSE:  143.9424\n","Epoch: [387/800] Iter:[0/150], Time: 4.50, lr: 5.2599, Loss: 0.0589, pre: 4336.9, gt: 2924.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [387/800] Iter:[20/150], Time: 0.77, lr: 5.2573, Loss: 0.0338, pre: 6312.0, gt: 5817.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [387/800] Iter:[40/150], Time: 0.68, lr: 5.2547, Loss: 0.0312, pre: 1788.7, gt: 1699.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [387/800] Iter:[60/150], Time: 0.65, lr: 5.2521, Loss: 0.0298, pre: 2739.6, gt: 2512.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [387/800] Iter:[80/150], Time: 0.63, lr: 5.2494, Loss: 0.0289, pre: 2358.0, gt: 2609.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [387/800] Iter:[100/150], Time: 0.62, lr: 5.2468, Loss: 0.0282, pre: 3596.4, gt: 3011.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [387/800] Iter:[120/150], Time: 0.62, lr: 5.2442, Loss: 0.0281, pre: 910.1, gt: 1039.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [387/800] Iter:[140/150], Time: 0.61, lr: 5.2416, Loss: 0.0284, pre: 1902.0, gt: 2067.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [388/800] Iter:[0/150], Time: 1.87, lr: 5.2403, Loss: 0.0173, pre: 680.1, gt: 698.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [388/800] Iter:[20/150], Time: 0.65, lr: 5.2377, Loss: 0.0267, pre: 842.2, gt: 910.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [388/800] Iter:[40/150], Time: 0.61, lr: 5.2351, Loss: 0.0269, pre: 1104.9, gt: 1308.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [388/800] Iter:[60/150], Time: 0.60, lr: 5.2325, Loss: 0.0256, pre: 1477.3, gt: 1324.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [388/800] Iter:[80/150], Time: 0.60, lr: 5.2298, Loss: 0.0258, pre: 411.8, gt: 318.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [388/800] Iter:[100/150], Time: 0.60, lr: 5.2272, Loss: 0.0263, pre: 832.9, gt: 948.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [388/800] Iter:[120/150], Time: 0.59, lr: 5.2246, Loss: 0.0268, pre: 3726.0, gt: 3596.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [388/800] Iter:[140/150], Time: 0.59, lr: 5.2220, Loss: 0.0270, pre: 950.0, gt: 999.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [389/800] Iter:[0/150], Time: 2.07, lr: 5.2207, Loss: 0.0262, pre: 2110.4, gt: 2174.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [389/800] Iter:[20/150], Time: 0.65, lr: 5.2181, Loss: 0.0272, pre: 2883.1, gt: 2757.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [389/800] Iter:[40/150], Time: 0.62, lr: 5.2155, Loss: 0.0267, pre: 1401.5, gt: 1373.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [389/800] Iter:[60/150], Time: 0.61, lr: 5.2129, Loss: 0.0263, pre: 1216.1, gt: 1409.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [389/800] Iter:[80/150], Time: 0.60, lr: 5.2102, Loss: 0.0271, pre: 1114.0, gt: 1038.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [389/800] Iter:[100/150], Time: 0.60, lr: 5.2076, Loss: 0.0266, pre: 1368.3, gt: 1410.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [389/800] Iter:[120/150], Time: 0.60, lr: 5.2050, Loss: 0.0266, pre: 6866.1, gt: 7373.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [389/800] Iter:[140/150], Time: 0.59, lr: 5.2024, Loss: 0.0268, pre: 1080.0, gt: 1014.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  92.26, Best_MAE:  85.9745 MSE:  157.8951,Best_MSE:  143.9424\n","Epoch: [390/800] Iter:[0/150], Time: 4.44, lr: 5.2011, Loss: 0.0310, pre: 1985.2, gt: 2132.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [390/800] Iter:[20/150], Time: 0.77, lr: 5.1985, Loss: 0.0261, pre: 1021.1, gt: 1005.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [390/800] Iter:[40/150], Time: 0.68, lr: 5.1959, Loss: 0.0275, pre: 699.9, gt: 612.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [390/800] Iter:[60/150], Time: 0.65, lr: 5.1933, Loss: 0.0278, pre: 2379.3, gt: 2574.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [390/800] Iter:[80/150], Time: 0.63, lr: 5.1906, Loss: 0.0284, pre: 3196.3, gt: 2666.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [390/800] Iter:[100/150], Time: 0.62, lr: 5.1880, Loss: 0.0278, pre: 2411.3, gt: 2052.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [390/800] Iter:[120/150], Time: 0.62, lr: 5.1854, Loss: 0.0277, pre: 2157.8, gt: 2251.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [390/800] Iter:[140/150], Time: 0.61, lr: 5.1828, Loss: 0.0276, pre: 1989.2, gt: 1758.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [391/800] Iter:[0/150], Time: 2.37, lr: 5.1815, Loss: 0.0260, pre: 1167.4, gt: 1253.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [391/800] Iter:[20/150], Time: 0.67, lr: 5.1789, Loss: 0.0250, pre: 3078.2, gt: 3342.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [391/800] Iter:[40/150], Time: 0.63, lr: 5.1763, Loss: 0.0269, pre: 955.3, gt: 980.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [391/800] Iter:[60/150], Time: 0.61, lr: 5.1737, Loss: 0.0269, pre: 484.6, gt: 500.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [391/800] Iter:[80/150], Time: 0.61, lr: 5.1710, Loss: 0.0271, pre: 2898.6, gt: 2713.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [391/800] Iter:[100/150], Time: 0.60, lr: 5.1684, Loss: 0.0279, pre: 554.7, gt: 565.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [391/800] Iter:[120/150], Time: 0.60, lr: 5.1658, Loss: 0.0279, pre: 899.9, gt: 981.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [391/800] Iter:[140/150], Time: 0.60, lr: 5.1632, Loss: 0.0274, pre: 784.0, gt: 910.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [392/800] Iter:[0/150], Time: 2.08, lr: 5.1619, Loss: 0.0244, pre: 1522.5, gt: 1891.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [392/800] Iter:[20/150], Time: 0.66, lr: 5.1593, Loss: 0.0268, pre: 896.7, gt: 966.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [392/800] Iter:[40/150], Time: 0.62, lr: 5.1567, Loss: 0.0251, pre: 1619.0, gt: 1714.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [392/800] Iter:[60/150], Time: 0.61, lr: 5.1541, Loss: 0.0248, pre: 1499.7, gt: 1447.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [392/800] Iter:[80/150], Time: 0.60, lr: 5.1514, Loss: 0.0249, pre: 1780.8, gt: 1825.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [392/800] Iter:[100/150], Time: 0.60, lr: 5.1488, Loss: 0.0261, pre: 4237.1, gt: 4322.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [392/800] Iter:[120/150], Time: 0.60, lr: 5.1462, Loss: 0.0266, pre: 1043.2, gt: 1105.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [392/800] Iter:[140/150], Time: 0.59, lr: 5.1436, Loss: 0.0263, pre: 559.7, gt: 533.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  95.60, Best_MAE:  85.9745 MSE:  157.1218,Best_MSE:  143.9424\n","Epoch: [393/800] Iter:[0/150], Time: 4.84, lr: 5.1423, Loss: 0.0117, pre: 544.9, gt: 468.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [393/800] Iter:[20/150], Time: 0.79, lr: 5.1397, Loss: 0.0259, pre: 3688.3, gt: 4238.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [393/800] Iter:[40/150], Time: 0.69, lr: 5.1371, Loss: 0.0265, pre: 1127.4, gt: 1169.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [393/800] Iter:[60/150], Time: 0.65, lr: 5.1344, Loss: 0.0271, pre: 3177.1, gt: 3401.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [393/800] Iter:[80/150], Time: 0.64, lr: 5.1318, Loss: 0.0269, pre: 1481.1, gt: 1494.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [393/800] Iter:[100/150], Time: 0.63, lr: 5.1292, Loss: 0.0273, pre: 2055.6, gt: 2174.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [393/800] Iter:[120/150], Time: 0.62, lr: 5.1266, Loss: 0.0264, pre: 1361.4, gt: 1359.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [393/800] Iter:[140/150], Time: 0.61, lr: 5.1240, Loss: 0.0263, pre: 1073.5, gt: 1451.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [394/800] Iter:[0/150], Time: 1.99, lr: 5.1227, Loss: 0.0261, pre: 1688.2, gt: 1951.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [394/800] Iter:[20/150], Time: 0.65, lr: 5.1201, Loss: 0.0254, pre: 1711.7, gt: 2033.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [394/800] Iter:[40/150], Time: 0.62, lr: 5.1175, Loss: 0.0261, pre: 632.5, gt: 690.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [394/800] Iter:[60/150], Time: 0.61, lr: 5.1148, Loss: 0.0264, pre: 1365.6, gt: 1339.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [394/800] Iter:[80/150], Time: 0.60, lr: 5.1122, Loss: 0.0258, pre: 2778.7, gt: 2703.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [394/800] Iter:[100/150], Time: 0.60, lr: 5.1096, Loss: 0.0255, pre: 2259.2, gt: 2408.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [394/800] Iter:[120/150], Time: 0.59, lr: 5.1070, Loss: 0.0258, pre: 1488.4, gt: 1578.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [394/800] Iter:[140/150], Time: 0.59, lr: 5.1044, Loss: 0.0261, pre: 4171.7, gt: 3628.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [395/800] Iter:[0/150], Time: 1.98, lr: 5.1031, Loss: 0.0259, pre: 738.6, gt: 865.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [395/800] Iter:[20/150], Time: 0.65, lr: 5.1005, Loss: 0.0270, pre: 2176.9, gt: 2056.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [395/800] Iter:[40/150], Time: 0.62, lr: 5.0978, Loss: 0.0282, pre: 1687.2, gt: 2276.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [395/800] Iter:[60/150], Time: 0.61, lr: 5.0952, Loss: 0.0276, pre: 1036.3, gt: 901.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [395/800] Iter:[80/150], Time: 0.60, lr: 5.0926, Loss: 0.0269, pre: 816.5, gt: 911.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [395/800] Iter:[100/150], Time: 0.60, lr: 5.0900, Loss: 0.0267, pre: 560.4, gt: 615.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [395/800] Iter:[120/150], Time: 0.59, lr: 5.0874, Loss: 0.0268, pre: 1289.9, gt: 1313.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [395/800] Iter:[140/150], Time: 0.59, lr: 5.0848, Loss: 0.0268, pre: 870.3, gt: 940.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  103.62, Best_MAE:  85.9745 MSE:  187.0988,Best_MSE:  143.9424\n","Epoch: [396/800] Iter:[0/150], Time: 4.27, lr: 5.0835, Loss: 0.0320, pre: 2321.3, gt: 2388.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [396/800] Iter:[20/150], Time: 0.76, lr: 5.0808, Loss: 0.0256, pre: 869.6, gt: 760.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [396/800] Iter:[40/150], Time: 0.67, lr: 5.0782, Loss: 0.0265, pre: 3103.8, gt: 3089.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [396/800] Iter:[60/150], Time: 0.64, lr: 5.0756, Loss: 0.0264, pre: 1499.4, gt: 1562.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [396/800] Iter:[80/150], Time: 0.63, lr: 5.0730, Loss: 0.0253, pre: 2416.6, gt: 2547.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [396/800] Iter:[100/150], Time: 0.62, lr: 5.0704, Loss: 0.0254, pre: 1057.0, gt: 1102.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [396/800] Iter:[120/150], Time: 0.61, lr: 5.0678, Loss: 0.0255, pre: 3567.6, gt: 3674.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [396/800] Iter:[140/150], Time: 0.61, lr: 5.0652, Loss: 0.0260, pre: 4136.4, gt: 3807.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [397/800] Iter:[0/150], Time: 1.81, lr: 5.0638, Loss: 0.0232, pre: 1166.9, gt: 1355.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [397/800] Iter:[20/150], Time: 0.64, lr: 5.0612, Loss: 0.0246, pre: 1637.0, gt: 1684.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [397/800] Iter:[40/150], Time: 0.61, lr: 5.0586, Loss: 0.0247, pre: 4053.5, gt: 4532.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [397/800] Iter:[60/150], Time: 0.60, lr: 5.0560, Loss: 0.0261, pre: 755.1, gt: 667.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [397/800] Iter:[80/150], Time: 0.60, lr: 5.0534, Loss: 0.0268, pre: 1042.6, gt: 1061.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [397/800] Iter:[100/150], Time: 0.59, lr: 5.0508, Loss: 0.0274, pre: 1338.1, gt: 1337.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [397/800] Iter:[120/150], Time: 0.59, lr: 5.0482, Loss: 0.0267, pre: 1023.5, gt: 1010.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [397/800] Iter:[140/150], Time: 0.59, lr: 5.0455, Loss: 0.0266, pre: 1986.3, gt: 2201.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [398/800] Iter:[0/150], Time: 1.83, lr: 5.0442, Loss: 0.0079, pre: 281.9, gt: 350.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [398/800] Iter:[20/150], Time: 0.64, lr: 5.0416, Loss: 0.0243, pre: 1359.3, gt: 1260.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [398/800] Iter:[40/150], Time: 0.61, lr: 5.0390, Loss: 0.0268, pre: 508.5, gt: 553.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [398/800] Iter:[60/150], Time: 0.60, lr: 5.0364, Loss: 0.0278, pre: 882.8, gt: 935.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [398/800] Iter:[80/150], Time: 0.60, lr: 5.0338, Loss: 0.0271, pre: 1969.3, gt: 1996.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [398/800] Iter:[100/150], Time: 0.59, lr: 5.0312, Loss: 0.0266, pre: 3199.0, gt: 3152.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [398/800] Iter:[120/150], Time: 0.59, lr: 5.0285, Loss: 0.0258, pre: 4009.7, gt: 4231.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [398/800] Iter:[140/150], Time: 0.59, lr: 5.0259, Loss: 0.0259, pre: 971.6, gt: 942.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  99.12, Best_MAE:  85.9745 MSE:  156.1300,Best_MSE:  143.9424\n","Epoch: [399/800] Iter:[0/150], Time: 3.84, lr: 5.0246, Loss: 0.0187, pre: 1189.1, gt: 1165.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [399/800] Iter:[20/150], Time: 0.75, lr: 5.0220, Loss: 0.0271, pre: 1143.7, gt: 1343.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [399/800] Iter:[40/150], Time: 0.66, lr: 5.0194, Loss: 0.0275, pre: 1704.8, gt: 1773.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [399/800] Iter:[60/150], Time: 0.64, lr: 5.0168, Loss: 0.0272, pre: 513.4, gt: 521.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [399/800] Iter:[80/150], Time: 0.62, lr: 5.0142, Loss: 0.0268, pre: 1402.2, gt: 1606.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [399/800] Iter:[100/150], Time: 0.62, lr: 5.0115, Loss: 0.0264, pre: 753.5, gt: 872.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [399/800] Iter:[120/150], Time: 0.61, lr: 5.0089, Loss: 0.0261, pre: 723.3, gt: 668.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [399/800] Iter:[140/150], Time: 0.61, lr: 5.0063, Loss: 0.0261, pre: 765.4, gt: 706.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [400/800] Iter:[0/150], Time: 2.11, lr: 5.0050, Loss: 0.0309, pre: 1481.5, gt: 1364.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [400/800] Iter:[20/150], Time: 0.66, lr: 5.0024, Loss: 0.0253, pre: 1777.6, gt: 1239.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [400/800] Iter:[40/150], Time: 0.62, lr: 4.9998, Loss: 0.0262, pre: 1092.6, gt: 1095.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [400/800] Iter:[60/150], Time: 0.61, lr: 4.9972, Loss: 0.0265, pre: 3119.9, gt: 3232.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [400/800] Iter:[80/150], Time: 0.60, lr: 4.9945, Loss: 0.0275, pre: 961.1, gt: 951.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [400/800] Iter:[100/150], Time: 0.60, lr: 4.9919, Loss: 0.0276, pre: 3645.5, gt: 3814.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [400/800] Iter:[120/150], Time: 0.60, lr: 4.9893, Loss: 0.0275, pre: 898.0, gt: 995.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [400/800] Iter:[140/150], Time: 0.59, lr: 4.9867, Loss: 0.0273, pre: 1210.8, gt: 1239.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [401/800] Iter:[0/150], Time: 1.92, lr: 4.9854, Loss: 0.0209, pre: 1044.5, gt: 952.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [401/800] Iter:[20/150], Time: 0.65, lr: 4.9828, Loss: 0.0289, pre: 511.6, gt: 587.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [401/800] Iter:[40/150], Time: 0.62, lr: 4.9802, Loss: 0.0266, pre: 1159.4, gt: 1195.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [401/800] Iter:[60/150], Time: 0.61, lr: 4.9775, Loss: 0.0258, pre: 1135.2, gt: 1096.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [401/800] Iter:[80/150], Time: 0.60, lr: 4.9749, Loss: 0.0262, pre: 1738.6, gt: 1889.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [401/800] Iter:[100/150], Time: 0.60, lr: 4.9723, Loss: 0.0258, pre: 1306.8, gt: 1488.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [401/800] Iter:[120/150], Time: 0.60, lr: 4.9697, Loss: 0.0259, pre: 1453.2, gt: 1428.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [401/800] Iter:[140/150], Time: 0.59, lr: 4.9671, Loss: 0.0262, pre: 1319.9, gt: 1615.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  89.36, Best_MAE:  85.9745 MSE:  151.2406,Best_MSE:  143.9424\n","Epoch: [402/800] Iter:[0/150], Time: 4.52, lr: 4.9658, Loss: 0.0125, pre: 380.0, gt: 356.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [402/800] Iter:[20/150], Time: 0.77, lr: 4.9632, Loss: 0.0250, pre: 1071.9, gt: 1255.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [402/800] Iter:[40/150], Time: 0.68, lr: 4.9605, Loss: 0.0242, pre: 1586.0, gt: 2099.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [402/800] Iter:[60/150], Time: 0.65, lr: 4.9579, Loss: 0.0262, pre: 1241.3, gt: 1411.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [402/800] Iter:[80/150], Time: 0.63, lr: 4.9553, Loss: 0.0268, pre: 3661.4, gt: 3741.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [402/800] Iter:[100/150], Time: 0.62, lr: 4.9527, Loss: 0.0269, pre: 547.4, gt: 569.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [402/800] Iter:[120/150], Time: 0.62, lr: 4.9501, Loss: 0.0268, pre: 2654.5, gt: 3013.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [402/800] Iter:[140/150], Time: 0.61, lr: 4.9475, Loss: 0.0266, pre: 1086.0, gt: 1063.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [403/800] Iter:[0/150], Time: 1.64, lr: 4.9462, Loss: 0.0449, pre: 1927.4, gt: 2232.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [403/800] Iter:[20/150], Time: 0.63, lr: 4.9435, Loss: 0.0256, pre: 1403.0, gt: 1725.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [403/800] Iter:[40/150], Time: 0.61, lr: 4.9409, Loss: 0.0243, pre: 1443.8, gt: 1432.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [403/800] Iter:[60/150], Time: 0.60, lr: 4.9383, Loss: 0.0259, pre: 1850.2, gt: 1986.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [403/800] Iter:[80/150], Time: 0.60, lr: 4.9357, Loss: 0.0267, pre: 6697.9, gt: 5758.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [403/800] Iter:[100/150], Time: 0.59, lr: 4.9331, Loss: 0.0262, pre: 2480.0, gt: 2859.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [403/800] Iter:[120/150], Time: 0.59, lr: 4.9305, Loss: 0.0262, pre: 1130.9, gt: 1152.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [403/800] Iter:[140/150], Time: 0.59, lr: 4.9278, Loss: 0.0264, pre: 1642.4, gt: 1619.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  102.44, Best_MAE:  85.9745 MSE:  185.7898,Best_MSE:  143.9424\n","Epoch: [404/800] Iter:[0/150], Time: 4.29, lr: 4.9265, Loss: 0.0194, pre: 383.1, gt: 387.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [404/800] Iter:[20/150], Time: 0.76, lr: 4.9239, Loss: 0.0249, pre: 1742.2, gt: 1834.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [404/800] Iter:[40/150], Time: 0.68, lr: 4.9213, Loss: 0.0251, pre: 1543.4, gt: 1591.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [404/800] Iter:[60/150], Time: 0.64, lr: 4.9187, Loss: 0.0258, pre: 2693.0, gt: 2738.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [404/800] Iter:[80/150], Time: 0.63, lr: 4.9161, Loss: 0.0256, pre: 845.8, gt: 857.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [404/800] Iter:[100/150], Time: 0.62, lr: 4.9135, Loss: 0.0257, pre: 975.4, gt: 812.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [404/800] Iter:[120/150], Time: 0.61, lr: 4.9109, Loss: 0.0262, pre: 3099.2, gt: 3311.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [404/800] Iter:[140/150], Time: 0.61, lr: 4.9082, Loss: 0.0267, pre: 883.8, gt: 866.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [405/800] Iter:[0/150], Time: 2.14, lr: 4.9069, Loss: 0.0234, pre: 648.9, gt: 595.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [405/800] Iter:[20/150], Time: 0.66, lr: 4.9043, Loss: 0.0268, pre: 4611.6, gt: 4674.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [405/800] Iter:[40/150], Time: 0.62, lr: 4.9017, Loss: 0.0269, pre: 3182.9, gt: 3578.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [405/800] Iter:[60/150], Time: 0.61, lr: 4.8991, Loss: 0.0262, pre: 2142.3, gt: 2587.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [405/800] Iter:[80/150], Time: 0.60, lr: 4.8965, Loss: 0.0258, pre: 743.6, gt: 989.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [405/800] Iter:[100/150], Time: 0.60, lr: 4.8939, Loss: 0.0270, pre: 5693.1, gt: 5109.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [405/800] Iter:[120/150], Time: 0.60, lr: 4.8912, Loss: 0.0272, pre: 1118.9, gt: 1405.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [405/800] Iter:[140/150], Time: 0.59, lr: 4.8886, Loss: 0.0277, pre: 1712.0, gt: 1903.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  95.79, Best_MAE:  85.9745 MSE:  155.5473,Best_MSE:  143.9424\n","Epoch: [406/800] Iter:[0/150], Time: 4.31, lr: 4.8873, Loss: 0.0240, pre: 1105.6, gt: 1069.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [406/800] Iter:[20/150], Time: 0.77, lr: 4.8847, Loss: 0.0260, pre: 2012.7, gt: 2007.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [406/800] Iter:[40/150], Time: 0.68, lr: 4.8821, Loss: 0.0242, pre: 1422.5, gt: 1181.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [406/800] Iter:[60/150], Time: 0.64, lr: 4.8795, Loss: 0.0236, pre: 1149.0, gt: 1257.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [406/800] Iter:[80/150], Time: 0.63, lr: 4.8769, Loss: 0.0243, pre: 1507.7, gt: 1630.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [406/800] Iter:[100/150], Time: 0.62, lr: 4.8742, Loss: 0.0248, pre: 1418.2, gt: 1592.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [406/800] Iter:[120/150], Time: 0.61, lr: 4.8716, Loss: 0.0250, pre: 1802.5, gt: 1832.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [406/800] Iter:[140/150], Time: 0.61, lr: 4.8690, Loss: 0.0253, pre: 2435.2, gt: 2991.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [407/800] Iter:[0/150], Time: 1.71, lr: 4.8677, Loss: 0.0218, pre: 789.6, gt: 801.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [407/800] Iter:[20/150], Time: 0.64, lr: 4.8651, Loss: 0.0243, pre: 439.1, gt: 578.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [407/800] Iter:[40/150], Time: 0.61, lr: 4.8625, Loss: 0.0244, pre: 317.5, gt: 394.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [407/800] Iter:[60/150], Time: 0.60, lr: 4.8599, Loss: 0.0269, pre: 3687.1, gt: 4041.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [407/800] Iter:[80/150], Time: 0.60, lr: 4.8573, Loss: 0.0284, pre: 814.6, gt: 776.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [407/800] Iter:[100/150], Time: 0.60, lr: 4.8546, Loss: 0.0282, pre: 976.3, gt: 1101.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [407/800] Iter:[120/150], Time: 0.59, lr: 4.8520, Loss: 0.0282, pre: 3021.5, gt: 3275.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [407/800] Iter:[140/150], Time: 0.59, lr: 4.8494, Loss: 0.0281, pre: 1740.1, gt: 1705.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  101.22, Best_MAE:  85.9745 MSE:  170.3437,Best_MSE:  143.9424\n","Epoch: [408/800] Iter:[0/150], Time: 4.27, lr: 4.8481, Loss: 0.0186, pre: 1525.2, gt: 1546.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [408/800] Iter:[20/150], Time: 0.76, lr: 4.8455, Loss: 0.0251, pre: 650.7, gt: 710.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [408/800] Iter:[40/150], Time: 0.67, lr: 4.8429, Loss: 0.0268, pre: 763.1, gt: 659.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [408/800] Iter:[60/150], Time: 0.64, lr: 4.8403, Loss: 0.0262, pre: 2531.7, gt: 2615.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [408/800] Iter:[80/150], Time: 0.63, lr: 4.8376, Loss: 0.0261, pre: 2794.7, gt: 2932.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [408/800] Iter:[100/150], Time: 0.62, lr: 4.8350, Loss: 0.0273, pre: 879.3, gt: 801.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [408/800] Iter:[120/150], Time: 0.61, lr: 4.8324, Loss: 0.0265, pre: 1352.4, gt: 1627.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [408/800] Iter:[140/150], Time: 0.61, lr: 4.8298, Loss: 0.0267, pre: 2759.0, gt: 3661.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [409/800] Iter:[0/150], Time: 1.97, lr: 4.8285, Loss: 0.0268, pre: 2104.0, gt: 1859.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [409/800] Iter:[20/150], Time: 0.65, lr: 4.8259, Loss: 0.0258, pre: 685.9, gt: 967.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [409/800] Iter:[40/150], Time: 0.62, lr: 4.8233, Loss: 0.0261, pre: 2514.0, gt: 3091.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [409/800] Iter:[60/150], Time: 0.61, lr: 4.8207, Loss: 0.0261, pre: 610.5, gt: 495.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [409/800] Iter:[80/150], Time: 0.60, lr: 4.8180, Loss: 0.0261, pre: 1862.2, gt: 1786.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [409/800] Iter:[100/150], Time: 0.60, lr: 4.8154, Loss: 0.0260, pre: 707.8, gt: 630.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [409/800] Iter:[120/150], Time: 0.59, lr: 4.8128, Loss: 0.0266, pre: 1724.6, gt: 1630.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [409/800] Iter:[140/150], Time: 0.59, lr: 4.8102, Loss: 0.0263, pre: 1532.0, gt: 1332.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  91.16, Best_MAE:  85.9745 MSE:  158.1258,Best_MSE:  143.9424\n","Epoch: [410/800] Iter:[0/150], Time: 4.46, lr: 4.8089, Loss: 0.0187, pre: 785.3, gt: 902.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [410/800] Iter:[20/150], Time: 0.77, lr: 4.8063, Loss: 0.0274, pre: 3394.7, gt: 2973.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [410/800] Iter:[40/150], Time: 0.68, lr: 4.8037, Loss: 0.0254, pre: 2244.0, gt: 2392.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [410/800] Iter:[60/150], Time: 0.65, lr: 4.8011, Loss: 0.0246, pre: 1565.9, gt: 1470.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [410/800] Iter:[80/150], Time: 0.63, lr: 4.7984, Loss: 0.0244, pre: 1166.3, gt: 1246.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [410/800] Iter:[100/150], Time: 0.62, lr: 4.7958, Loss: 0.0256, pre: 2571.0, gt: 2469.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [410/800] Iter:[120/150], Time: 0.61, lr: 4.7932, Loss: 0.0255, pre: 798.6, gt: 802.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [410/800] Iter:[140/150], Time: 0.61, lr: 4.7906, Loss: 0.0258, pre: 791.2, gt: 859.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [411/800] Iter:[0/150], Time: 1.88, lr: 4.7893, Loss: 0.0250, pre: 1127.3, gt: 1148.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [411/800] Iter:[20/150], Time: 0.65, lr: 4.7867, Loss: 0.0276, pre: 377.5, gt: 474.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [411/800] Iter:[40/150], Time: 0.61, lr: 4.7841, Loss: 0.0288, pre: 1357.6, gt: 1841.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [411/800] Iter:[60/150], Time: 0.60, lr: 4.7815, Loss: 0.0281, pre: 480.7, gt: 461.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [411/800] Iter:[80/150], Time: 0.60, lr: 4.7788, Loss: 0.0278, pre: 1128.4, gt: 916.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [411/800] Iter:[100/150], Time: 0.60, lr: 4.7762, Loss: 0.0274, pre: 830.2, gt: 894.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [411/800] Iter:[120/150], Time: 0.59, lr: 4.7736, Loss: 0.0270, pre: 1524.0, gt: 1619.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [411/800] Iter:[140/150], Time: 0.59, lr: 4.7710, Loss: 0.0265, pre: 2562.5, gt: 2605.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  97.45, Best_MAE:  85.9745 MSE:  160.4906,Best_MSE:  143.9424\n","Epoch: [412/800] Iter:[0/150], Time: 4.57, lr: 4.7697, Loss: 0.0090, pre: 303.6, gt: 321.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [412/800] Iter:[20/150], Time: 0.78, lr: 4.7671, Loss: 0.0282, pre: 242.0, gt: 291.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [412/800] Iter:[40/150], Time: 0.68, lr: 4.7645, Loss: 0.0258, pre: 544.9, gt: 429.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [412/800] Iter:[60/150], Time: 0.65, lr: 4.7619, Loss: 0.0272, pre: 712.0, gt: 709.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [412/800] Iter:[80/150], Time: 0.63, lr: 4.7593, Loss: 0.0271, pre: 2191.0, gt: 2560.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [412/800] Iter:[100/150], Time: 0.62, lr: 4.7566, Loss: 0.0279, pre: 875.1, gt: 834.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [412/800] Iter:[120/150], Time: 0.62, lr: 4.7540, Loss: 0.0272, pre: 2509.0, gt: 2308.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [412/800] Iter:[140/150], Time: 0.61, lr: 4.7514, Loss: 0.0264, pre: 812.8, gt: 773.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [413/800] Iter:[0/150], Time: 2.26, lr: 4.7501, Loss: 0.0116, pre: 639.6, gt: 661.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [413/800] Iter:[20/150], Time: 0.66, lr: 4.7475, Loss: 0.0285, pre: 1146.5, gt: 1045.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [413/800] Iter:[40/150], Time: 0.62, lr: 4.7449, Loss: 0.0274, pre: 883.9, gt: 685.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [413/800] Iter:[60/150], Time: 0.61, lr: 4.7423, Loss: 0.0273, pre: 1607.0, gt: 1631.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [413/800] Iter:[80/150], Time: 0.60, lr: 4.7397, Loss: 0.0268, pre: 496.8, gt: 539.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [413/800] Iter:[100/150], Time: 0.60, lr: 4.7371, Loss: 0.0266, pre: 4664.9, gt: 4738.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [413/800] Iter:[120/150], Time: 0.60, lr: 4.7344, Loss: 0.0261, pre: 838.6, gt: 716.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [413/800] Iter:[140/150], Time: 0.59, lr: 4.7318, Loss: 0.0266, pre: 830.9, gt: 658.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  95.93, Best_MAE:  85.9745 MSE:  149.0780,Best_MSE:  143.9424\n","Epoch: [414/800] Iter:[0/150], Time: 4.58, lr: 4.7305, Loss: 0.0346, pre: 3141.1, gt: 3411.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [414/800] Iter:[20/150], Time: 0.78, lr: 4.7279, Loss: 0.0232, pre: 167.9, gt: 197.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [414/800] Iter:[40/150], Time: 0.68, lr: 4.7253, Loss: 0.0247, pre: 806.2, gt: 766.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [414/800] Iter:[60/150], Time: 0.65, lr: 4.7227, Loss: 0.0247, pre: 860.2, gt: 820.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [414/800] Iter:[80/150], Time: 0.63, lr: 4.7201, Loss: 0.0254, pre: 3445.7, gt: 2973.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [414/800] Iter:[100/150], Time: 0.62, lr: 4.7175, Loss: 0.0261, pre: 2004.9, gt: 1877.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [414/800] Iter:[120/150], Time: 0.62, lr: 4.7149, Loss: 0.0259, pre: 2429.1, gt: 2656.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [414/800] Iter:[140/150], Time: 0.61, lr: 4.7122, Loss: 0.0258, pre: 1132.7, gt: 1204.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [415/800] Iter:[0/150], Time: 2.14, lr: 4.7109, Loss: 0.0266, pre: 2202.1, gt: 2131.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [415/800] Iter:[20/150], Time: 0.66, lr: 4.7083, Loss: 0.0260, pre: 1002.6, gt: 1284.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [415/800] Iter:[40/150], Time: 0.62, lr: 4.7057, Loss: 0.0254, pre: 625.0, gt: 688.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [415/800] Iter:[60/150], Time: 0.61, lr: 4.7031, Loss: 0.0251, pre: 1514.0, gt: 1600.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [415/800] Iter:[80/150], Time: 0.60, lr: 4.7005, Loss: 0.0248, pre: 628.8, gt: 517.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [415/800] Iter:[100/150], Time: 0.60, lr: 4.6979, Loss: 0.0254, pre: 297.7, gt: 347.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [415/800] Iter:[120/150], Time: 0.60, lr: 4.6953, Loss: 0.0255, pre: 1152.2, gt: 1309.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [415/800] Iter:[140/150], Time: 0.59, lr: 4.6927, Loss: 0.0254, pre: 1882.6, gt: 1896.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  97.89, Best_MAE:  85.9745 MSE:  150.6394,Best_MSE:  143.9424\n","Epoch: [416/800] Iter:[0/150], Time: 4.23, lr: 4.6914, Loss: 0.0231, pre: 996.5, gt: 979.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [416/800] Iter:[20/150], Time: 0.76, lr: 4.6888, Loss: 0.0274, pre: 1586.2, gt: 1517.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [416/800] Iter:[40/150], Time: 0.67, lr: 4.6861, Loss: 0.0262, pre: 130.0, gt: 81.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [416/800] Iter:[60/150], Time: 0.64, lr: 4.6835, Loss: 0.0265, pre: 1144.7, gt: 1306.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [416/800] Iter:[80/150], Time: 0.63, lr: 4.6809, Loss: 0.0261, pre: 618.9, gt: 559.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [416/800] Iter:[100/150], Time: 0.62, lr: 4.6783, Loss: 0.0261, pre: 1626.6, gt: 1813.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [416/800] Iter:[120/150], Time: 0.61, lr: 4.6757, Loss: 0.0265, pre: 1586.7, gt: 1468.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [416/800] Iter:[140/150], Time: 0.61, lr: 4.6731, Loss: 0.0266, pre: 1095.2, gt: 939.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [417/800] Iter:[0/150], Time: 2.02, lr: 4.6718, Loss: 0.0155, pre: 595.7, gt: 594.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [417/800] Iter:[20/150], Time: 0.65, lr: 4.6692, Loss: 0.0283, pre: 1402.2, gt: 1848.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [417/800] Iter:[40/150], Time: 0.62, lr: 4.6666, Loss: 0.0274, pre: 4258.2, gt: 4306.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [417/800] Iter:[60/150], Time: 0.61, lr: 4.6640, Loss: 0.0266, pre: 422.1, gt: 494.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [417/800] Iter:[80/150], Time: 0.60, lr: 4.6613, Loss: 0.0269, pre: 1656.1, gt: 1717.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [417/800] Iter:[100/150], Time: 0.60, lr: 4.6587, Loss: 0.0270, pre: 2231.9, gt: 2443.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [417/800] Iter:[120/150], Time: 0.60, lr: 4.6561, Loss: 0.0267, pre: 389.9, gt: 394.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [417/800] Iter:[140/150], Time: 0.59, lr: 4.6535, Loss: 0.0274, pre: 755.3, gt: 826.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  92.23, Best_MAE:  85.9745 MSE:  160.2073,Best_MSE:  143.9424\n","Epoch: [418/800] Iter:[0/150], Time: 4.55, lr: 4.6522, Loss: 0.0185, pre: 806.2, gt: 730.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [418/800] Iter:[20/150], Time: 0.78, lr: 4.6496, Loss: 0.0229, pre: 850.9, gt: 889.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [418/800] Iter:[40/150], Time: 0.68, lr: 4.6470, Loss: 0.0234, pre: 1600.4, gt: 1806.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [418/800] Iter:[60/150], Time: 0.65, lr: 4.6444, Loss: 0.0236, pre: 629.5, gt: 591.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [418/800] Iter:[80/150], Time: 0.63, lr: 4.6418, Loss: 0.0244, pre: 3438.3, gt: 4232.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [418/800] Iter:[100/150], Time: 0.62, lr: 4.6392, Loss: 0.0248, pre: 2236.4, gt: 2058.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [418/800] Iter:[120/150], Time: 0.62, lr: 4.6366, Loss: 0.0248, pre: 1557.2, gt: 1397.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [418/800] Iter:[140/150], Time: 0.61, lr: 4.6340, Loss: 0.0252, pre: 1684.5, gt: 1649.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [419/800] Iter:[0/150], Time: 2.12, lr: 4.6327, Loss: 0.0320, pre: 1818.9, gt: 1537.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [419/800] Iter:[20/150], Time: 0.66, lr: 4.6300, Loss: 0.0285, pre: 1770.7, gt: 2105.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [419/800] Iter:[40/150], Time: 0.62, lr: 4.6274, Loss: 0.0284, pre: 1500.0, gt: 1387.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [419/800] Iter:[60/150], Time: 0.61, lr: 4.6248, Loss: 0.0275, pre: 1080.4, gt: 1035.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [419/800] Iter:[80/150], Time: 0.60, lr: 4.6222, Loss: 0.0278, pre: 1403.0, gt: 1207.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [419/800] Iter:[100/150], Time: 0.60, lr: 4.6196, Loss: 0.0273, pre: 1000.4, gt: 1106.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [419/800] Iter:[120/150], Time: 0.59, lr: 4.6170, Loss: 0.0272, pre: 1943.1, gt: 1837.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [419/800] Iter:[140/150], Time: 0.59, lr: 4.6144, Loss: 0.0270, pre: 6626.8, gt: 6094.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  94.10, Best_MAE:  85.9745 MSE:  156.3570,Best_MSE:  143.9424\n","Epoch: [420/800] Iter:[0/150], Time: 4.26, lr: 4.6131, Loss: 0.0279, pre: 1153.5, gt: 1386.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [420/800] Iter:[20/150], Time: 0.76, lr: 4.6105, Loss: 0.0268, pre: 1198.3, gt: 1161.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [420/800] Iter:[40/150], Time: 0.68, lr: 4.6079, Loss: 0.0269, pre: 2471.3, gt: 2296.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [420/800] Iter:[60/150], Time: 0.64, lr: 4.6053, Loss: 0.0273, pre: 887.1, gt: 1093.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [420/800] Iter:[80/150], Time: 0.63, lr: 4.6027, Loss: 0.0264, pre: 1361.7, gt: 1435.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [420/800] Iter:[100/150], Time: 0.62, lr: 4.6001, Loss: 0.0262, pre: 2932.9, gt: 3061.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [420/800] Iter:[120/150], Time: 0.61, lr: 4.5975, Loss: 0.0263, pre: 1631.0, gt: 1710.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [420/800] Iter:[140/150], Time: 0.61, lr: 4.5948, Loss: 0.0257, pre: 951.9, gt: 835.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [421/800] Iter:[0/150], Time: 2.11, lr: 4.5935, Loss: 0.0172, pre: 606.6, gt: 606.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [421/800] Iter:[20/150], Time: 0.66, lr: 4.5909, Loss: 0.0306, pre: 1420.2, gt: 1531.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [421/800] Iter:[40/150], Time: 0.62, lr: 4.5883, Loss: 0.0288, pre: 707.4, gt: 590.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [421/800] Iter:[60/150], Time: 0.61, lr: 4.5857, Loss: 0.0271, pre: 2309.3, gt: 2248.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [421/800] Iter:[80/150], Time: 0.60, lr: 4.5831, Loss: 0.0266, pre: 3875.8, gt: 3884.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [421/800] Iter:[100/150], Time: 0.60, lr: 4.5805, Loss: 0.0262, pre: 786.7, gt: 704.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [421/800] Iter:[120/150], Time: 0.59, lr: 4.5779, Loss: 0.0260, pre: 2547.8, gt: 2629.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [421/800] Iter:[140/150], Time: 0.59, lr: 4.5753, Loss: 0.0261, pre: 828.2, gt: 939.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  125.09, Best_MAE:  85.9745 MSE:  237.6096,Best_MSE:  143.9424\n","Epoch: [422/800] Iter:[0/150], Time: 4.57, lr: 4.5740, Loss: 0.0085, pre: 423.6, gt: 384.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [422/800] Iter:[20/150], Time: 0.78, lr: 4.5714, Loss: 0.0262, pre: 1636.8, gt: 1989.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [422/800] Iter:[40/150], Time: 0.68, lr: 4.5688, Loss: 0.0253, pre: 1122.2, gt: 1063.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [422/800] Iter:[60/150], Time: 0.65, lr: 4.5662, Loss: 0.0247, pre: 1355.9, gt: 1303.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [422/800] Iter:[80/150], Time: 0.63, lr: 4.5636, Loss: 0.0262, pre: 5114.9, gt: 5415.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [422/800] Iter:[100/150], Time: 0.62, lr: 4.5610, Loss: 0.0259, pre: 527.6, gt: 515.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [422/800] Iter:[120/150], Time: 0.62, lr: 4.5584, Loss: 0.0256, pre: 1569.4, gt: 1820.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [422/800] Iter:[140/150], Time: 0.61, lr: 4.5558, Loss: 0.0254, pre: 2983.6, gt: 3023.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [423/800] Iter:[0/150], Time: 2.14, lr: 4.5545, Loss: 0.0296, pre: 2671.3, gt: 2736.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [423/800] Iter:[20/150], Time: 0.66, lr: 4.5519, Loss: 0.0253, pre: 1896.6, gt: 1736.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [423/800] Iter:[40/150], Time: 0.62, lr: 4.5493, Loss: 0.0249, pre: 1018.4, gt: 1049.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [423/800] Iter:[60/150], Time: 0.61, lr: 4.5466, Loss: 0.0246, pre: 1514.1, gt: 1345.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [423/800] Iter:[80/150], Time: 0.60, lr: 4.5440, Loss: 0.0249, pre: 410.7, gt: 371.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [423/800] Iter:[100/150], Time: 0.60, lr: 4.5414, Loss: 0.0253, pre: 1563.3, gt: 1490.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [423/800] Iter:[120/150], Time: 0.59, lr: 4.5388, Loss: 0.0260, pre: 2911.6, gt: 3170.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [423/800] Iter:[140/150], Time: 0.59, lr: 4.5362, Loss: 0.0261, pre: 5144.8, gt: 5148.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  122.20, Best_MAE:  85.9745 MSE:  206.1595,Best_MSE:  143.9424\n","Epoch: [424/800] Iter:[0/150], Time: 4.02, lr: 4.5349, Loss: 0.0261, pre: 1143.4, gt: 1078.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [424/800] Iter:[20/150], Time: 0.75, lr: 4.5323, Loss: 0.0338, pre: 381.5, gt: 373.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [424/800] Iter:[40/150], Time: 0.67, lr: 4.5297, Loss: 0.0292, pre: 2437.1, gt: 2426.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [424/800] Iter:[60/150], Time: 0.64, lr: 4.5271, Loss: 0.0288, pre: 3056.4, gt: 4082.0,acc:0.92, accx8:0.94,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [424/800] Iter:[80/150], Time: 0.63, lr: 4.5245, Loss: 0.0275, pre: 631.2, gt: 705.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [424/800] Iter:[100/150], Time: 0.62, lr: 4.5219, Loss: 0.0271, pre: 3174.6, gt: 3891.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [424/800] Iter:[120/150], Time: 0.61, lr: 4.5193, Loss: 0.0267, pre: 711.4, gt: 718.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [424/800] Iter:[140/150], Time: 0.61, lr: 4.5167, Loss: 0.0263, pre: 1826.7, gt: 1357.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [425/800] Iter:[0/150], Time: 1.78, lr: 4.5154, Loss: 0.0167, pre: 547.5, gt: 665.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [425/800] Iter:[20/150], Time: 0.64, lr: 4.5128, Loss: 0.0249, pre: 1632.1, gt: 1749.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [425/800] Iter:[40/150], Time: 0.61, lr: 4.5102, Loss: 0.0265, pre: 467.8, gt: 431.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [425/800] Iter:[60/150], Time: 0.60, lr: 4.5076, Loss: 0.0270, pre: 1329.9, gt: 1454.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [425/800] Iter:[80/150], Time: 0.60, lr: 4.5050, Loss: 0.0274, pre: 1666.9, gt: 1758.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [425/800] Iter:[100/150], Time: 0.60, lr: 4.5024, Loss: 0.0265, pre: 1269.8, gt: 1319.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [425/800] Iter:[120/150], Time: 0.59, lr: 4.4998, Loss: 0.0267, pre: 2471.8, gt: 2330.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [425/800] Iter:[140/150], Time: 0.59, lr: 4.4972, Loss: 0.0269, pre: 932.8, gt: 1057.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  92.01, Best_MAE:  85.9745 MSE:  153.7739,Best_MSE:  143.9424\n","Epoch: [426/800] Iter:[0/150], Time: 4.70, lr: 4.4959, Loss: 0.0271, pre: 1849.9, gt: 1876.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [426/800] Iter:[20/150], Time: 0.78, lr: 4.4933, Loss: 0.0280, pre: 790.5, gt: 884.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [426/800] Iter:[40/150], Time: 0.69, lr: 4.4907, Loss: 0.0266, pre: 1676.5, gt: 1619.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [426/800] Iter:[60/150], Time: 0.65, lr: 4.4881, Loss: 0.0263, pre: 576.2, gt: 498.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [426/800] Iter:[80/150], Time: 0.64, lr: 4.4855, Loss: 0.0259, pre: 1047.8, gt: 1248.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [426/800] Iter:[100/150], Time: 0.63, lr: 4.4829, Loss: 0.0263, pre: 1645.7, gt: 1463.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [426/800] Iter:[120/150], Time: 0.62, lr: 4.4803, Loss: 0.0271, pre: 603.7, gt: 362.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [426/800] Iter:[140/150], Time: 0.61, lr: 4.4777, Loss: 0.0274, pre: 1899.6, gt: 2205.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [427/800] Iter:[0/150], Time: 2.20, lr: 4.4764, Loss: 0.0239, pre: 1408.7, gt: 1503.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [427/800] Iter:[20/150], Time: 0.66, lr: 4.4738, Loss: 0.0257, pre: 1746.6, gt: 1927.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [427/800] Iter:[40/150], Time: 0.62, lr: 4.4712, Loss: 0.0265, pre: 3718.2, gt: 3669.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [427/800] Iter:[60/150], Time: 0.61, lr: 4.4686, Loss: 0.0250, pre: 843.9, gt: 770.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [427/800] Iter:[80/150], Time: 0.60, lr: 4.4660, Loss: 0.0253, pre: 2504.3, gt: 2776.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [427/800] Iter:[100/150], Time: 0.60, lr: 4.4634, Loss: 0.0255, pre: 1088.8, gt: 1427.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [427/800] Iter:[120/150], Time: 0.60, lr: 4.4608, Loss: 0.0265, pre: 1281.9, gt: 1353.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [427/800] Iter:[140/150], Time: 0.59, lr: 4.4582, Loss: 0.0262, pre: 816.5, gt: 876.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  109.42, Best_MAE:  85.9745 MSE:  201.1868,Best_MSE:  143.9424\n","Epoch: [428/800] Iter:[0/150], Time: 4.69, lr: 4.4569, Loss: 0.0153, pre: 400.3, gt: 413.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [428/800] Iter:[20/150], Time: 0.78, lr: 4.4543, Loss: 0.0238, pre: 934.8, gt: 973.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [428/800] Iter:[40/150], Time: 0.68, lr: 4.4517, Loss: 0.0284, pre: 1195.2, gt: 1263.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [428/800] Iter:[60/150], Time: 0.65, lr: 4.4491, Loss: 0.0277, pre: 4215.4, gt: 3994.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [428/800] Iter:[80/150], Time: 0.64, lr: 4.4465, Loss: 0.0272, pre: 967.4, gt: 1024.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [428/800] Iter:[100/150], Time: 0.63, lr: 4.4439, Loss: 0.0262, pre: 851.0, gt: 843.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [428/800] Iter:[120/150], Time: 0.62, lr: 4.4413, Loss: 0.0272, pre: 4467.0, gt: 5293.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [428/800] Iter:[140/150], Time: 0.61, lr: 4.4387, Loss: 0.0271, pre: 483.8, gt: 476.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [429/800] Iter:[0/150], Time: 1.93, lr: 4.4374, Loss: 0.0295, pre: 1515.5, gt: 1752.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [429/800] Iter:[20/150], Time: 0.65, lr: 4.4348, Loss: 0.0289, pre: 4889.9, gt: 5236.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [429/800] Iter:[40/150], Time: 0.62, lr: 4.4322, Loss: 0.0316, pre: 1501.1, gt: 1725.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [429/800] Iter:[60/150], Time: 0.61, lr: 4.4296, Loss: 0.0289, pre: 783.4, gt: 820.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [429/800] Iter:[80/150], Time: 0.60, lr: 4.4270, Loss: 0.0278, pre: 1436.3, gt: 1682.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [429/800] Iter:[100/150], Time: 0.60, lr: 4.4244, Loss: 0.0273, pre: 1669.5, gt: 1549.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [429/800] Iter:[120/150], Time: 0.59, lr: 4.4218, Loss: 0.0266, pre: 1457.4, gt: 1634.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [429/800] Iter:[140/150], Time: 0.59, lr: 4.4192, Loss: 0.0266, pre: 1415.0, gt: 1400.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  94.47, Best_MAE:  85.9745 MSE:  151.1254,Best_MSE:  143.9424\n","Epoch: [430/800] Iter:[0/150], Time: 4.37, lr: 4.4179, Loss: 0.0317, pre: 2274.5, gt: 2729.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [430/800] Iter:[20/150], Time: 0.77, lr: 4.4153, Loss: 0.0264, pre: 688.1, gt: 654.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [430/800] Iter:[40/150], Time: 0.68, lr: 4.4127, Loss: 0.0255, pre: 1708.7, gt: 1757.0,acc:0.91, accx8:0.94,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [430/800] Iter:[60/150], Time: 0.65, lr: 4.4101, Loss: 0.0259, pre: 1403.1, gt: 1309.0,acc:0.91, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [430/800] Iter:[80/150], Time: 0.63, lr: 4.4075, Loss: 0.0269, pre: 2596.3, gt: 2598.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [430/800] Iter:[100/150], Time: 0.62, lr: 4.4049, Loss: 0.0267, pre: 1266.6, gt: 1026.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [430/800] Iter:[120/150], Time: 0.62, lr: 4.4023, Loss: 0.0260, pre: 1425.4, gt: 1131.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [430/800] Iter:[140/150], Time: 0.61, lr: 4.3997, Loss: 0.0260, pre: 1570.8, gt: 1834.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [431/800] Iter:[0/150], Time: 1.78, lr: 4.3984, Loss: 0.0241, pre: 976.5, gt: 969.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [431/800] Iter:[20/150], Time: 0.64, lr: 4.3958, Loss: 0.0278, pre: 1150.2, gt: 1330.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [431/800] Iter:[40/150], Time: 0.61, lr: 4.3932, Loss: 0.0278, pre: 1021.5, gt: 947.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [431/800] Iter:[60/150], Time: 0.60, lr: 4.3906, Loss: 0.0292, pre: 908.6, gt: 901.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [431/800] Iter:[80/150], Time: 0.60, lr: 4.3880, Loss: 0.0285, pre: 1167.0, gt: 1407.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [431/800] Iter:[100/150], Time: 0.59, lr: 4.3854, Loss: 0.0275, pre: 638.4, gt: 634.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [431/800] Iter:[120/150], Time: 0.59, lr: 4.3829, Loss: 0.0273, pre: 613.1, gt: 666.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [431/800] Iter:[140/150], Time: 0.59, lr: 4.3803, Loss: 0.0266, pre: 643.1, gt: 679.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  93.01, Best_MAE:  85.9745 MSE:  159.2265,Best_MSE:  143.9424\n","Epoch: [432/800] Iter:[0/150], Time: 4.24, lr: 4.3790, Loss: 0.0248, pre: 1955.1, gt: 2150.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [432/800] Iter:[20/150], Time: 0.76, lr: 4.3764, Loss: 0.0249, pre: 4835.7, gt: 4786.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [432/800] Iter:[40/150], Time: 0.68, lr: 4.3738, Loss: 0.0252, pre: 2074.5, gt: 1950.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [432/800] Iter:[60/150], Time: 0.65, lr: 4.3712, Loss: 0.0251, pre: 1076.4, gt: 990.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [432/800] Iter:[80/150], Time: 0.63, lr: 4.3686, Loss: 0.0262, pre: 1183.2, gt: 1391.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [432/800] Iter:[100/150], Time: 0.62, lr: 4.3660, Loss: 0.0258, pre: 1876.1, gt: 1969.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [432/800] Iter:[120/150], Time: 0.61, lr: 4.3634, Loss: 0.0260, pre: 519.9, gt: 441.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [432/800] Iter:[140/150], Time: 0.61, lr: 4.3608, Loss: 0.0260, pre: 1425.9, gt: 1406.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [433/800] Iter:[0/150], Time: 2.21, lr: 4.3595, Loss: 0.0230, pre: 1836.0, gt: 2028.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [433/800] Iter:[20/150], Time: 0.66, lr: 4.3569, Loss: 0.0262, pre: 3136.7, gt: 2860.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [433/800] Iter:[40/150], Time: 0.62, lr: 4.3543, Loss: 0.0262, pre: 1607.1, gt: 2010.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [433/800] Iter:[60/150], Time: 0.61, lr: 4.3517, Loss: 0.0259, pre: 1772.5, gt: 1732.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [433/800] Iter:[80/150], Time: 0.60, lr: 4.3491, Loss: 0.0256, pre: 4128.5, gt: 4424.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [433/800] Iter:[100/150], Time: 0.60, lr: 4.3465, Loss: 0.0258, pre: 1186.1, gt: 1230.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [433/800] Iter:[120/150], Time: 0.60, lr: 4.3439, Loss: 0.0258, pre: 1332.8, gt: 1517.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [433/800] Iter:[140/150], Time: 0.59, lr: 4.3414, Loss: 0.0260, pre: 726.7, gt: 750.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  98.71, Best_MAE:  85.9745 MSE:  171.5822,Best_MSE:  143.9424\n","Epoch: [434/800] Iter:[0/150], Time: 3.96, lr: 4.3401, Loss: 0.0572, pre: 5547.9, gt: 5904.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [434/800] Iter:[20/150], Time: 0.75, lr: 4.3375, Loss: 0.0258, pre: 1159.9, gt: 1128.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [434/800] Iter:[40/150], Time: 0.67, lr: 4.3349, Loss: 0.0268, pre: 3047.7, gt: 3319.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [434/800] Iter:[60/150], Time: 0.64, lr: 4.3323, Loss: 0.0272, pre: 1094.6, gt: 1097.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [434/800] Iter:[80/150], Time: 0.63, lr: 4.3297, Loss: 0.0259, pre: 2483.0, gt: 2403.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [434/800] Iter:[100/150], Time: 0.62, lr: 4.3271, Loss: 0.0258, pre: 847.0, gt: 1026.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [434/800] Iter:[120/150], Time: 0.61, lr: 4.3245, Loss: 0.0263, pre: 1368.3, gt: 1292.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [434/800] Iter:[140/150], Time: 0.61, lr: 4.3219, Loss: 0.0259, pre: 471.7, gt: 451.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [435/800] Iter:[0/150], Time: 1.69, lr: 4.3206, Loss: 0.0294, pre: 945.4, gt: 1023.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [435/800] Iter:[20/150], Time: 0.64, lr: 4.3180, Loss: 0.0278, pre: 770.1, gt: 707.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [435/800] Iter:[40/150], Time: 0.61, lr: 4.3154, Loss: 0.0261, pre: 1141.5, gt: 1097.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [435/800] Iter:[60/150], Time: 0.60, lr: 4.3129, Loss: 0.0269, pre: 3487.8, gt: 3468.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [435/800] Iter:[80/150], Time: 0.60, lr: 4.3103, Loss: 0.0265, pre: 2623.8, gt: 2688.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [435/800] Iter:[100/150], Time: 0.59, lr: 4.3077, Loss: 0.0260, pre: 605.0, gt: 609.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [435/800] Iter:[120/150], Time: 0.59, lr: 4.3051, Loss: 0.0256, pre: 3168.3, gt: 3161.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [435/800] Iter:[140/150], Time: 0.59, lr: 4.3025, Loss: 0.0255, pre: 1532.9, gt: 1656.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  85.83, Best_MAE:  85.8329 MSE:  139.3664,Best_MSE:  139.3664\n","Epoch: [436/800] Iter:[0/150], Time: 4.77, lr: 4.3012, Loss: 0.0206, pre: 1217.8, gt: 1135.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [436/800] Iter:[20/150], Time: 0.79, lr: 4.2986, Loss: 0.0281, pre: 456.8, gt: 519.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [436/800] Iter:[40/150], Time: 0.69, lr: 4.2960, Loss: 0.0271, pre: 644.3, gt: 546.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [436/800] Iter:[60/150], Time: 0.66, lr: 4.2934, Loss: 0.0266, pre: 1609.1, gt: 1541.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [436/800] Iter:[80/150], Time: 0.64, lr: 4.2908, Loss: 0.0257, pre: 768.4, gt: 771.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [436/800] Iter:[100/150], Time: 0.63, lr: 4.2883, Loss: 0.0249, pre: 445.8, gt: 522.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [436/800] Iter:[120/150], Time: 0.62, lr: 4.2857, Loss: 0.0257, pre: 1520.1, gt: 1309.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [436/800] Iter:[140/150], Time: 0.61, lr: 4.2831, Loss: 0.0260, pre: 1556.7, gt: 1396.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [437/800] Iter:[0/150], Time: 1.72, lr: 4.2818, Loss: 0.0244, pre: 824.4, gt: 785.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [437/800] Iter:[20/150], Time: 0.64, lr: 4.2792, Loss: 0.0261, pre: 329.0, gt: 336.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [437/800] Iter:[40/150], Time: 0.61, lr: 4.2766, Loss: 0.0265, pre: 4778.5, gt: 4760.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [437/800] Iter:[60/150], Time: 0.60, lr: 4.2740, Loss: 0.0256, pre: 554.4, gt: 572.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [437/800] Iter:[80/150], Time: 0.60, lr: 4.2714, Loss: 0.0254, pre: 868.5, gt: 954.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [437/800] Iter:[100/150], Time: 0.59, lr: 4.2688, Loss: 0.0260, pre: 1477.6, gt: 1575.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [437/800] Iter:[120/150], Time: 0.59, lr: 4.2663, Loss: 0.0258, pre: 1826.2, gt: 1727.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [437/800] Iter:[140/150], Time: 0.59, lr: 4.2637, Loss: 0.0265, pre: 568.9, gt: 473.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  87.35, Best_MAE:  85.8329 MSE:  143.5193,Best_MSE:  139.3664\n","Epoch: [438/800] Iter:[0/150], Time: 4.29, lr: 4.2624, Loss: 0.0283, pre: 1356.8, gt: 1251.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [438/800] Iter:[20/150], Time: 0.77, lr: 4.2598, Loss: 0.0266, pre: 714.2, gt: 642.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [438/800] Iter:[40/150], Time: 0.68, lr: 4.2572, Loss: 0.0261, pre: 4589.4, gt: 4286.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [438/800] Iter:[60/150], Time: 0.65, lr: 4.2546, Loss: 0.0258, pre: 605.4, gt: 642.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [438/800] Iter:[80/150], Time: 0.63, lr: 4.2520, Loss: 0.0259, pre: 1139.4, gt: 1179.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [438/800] Iter:[100/150], Time: 0.62, lr: 4.2495, Loss: 0.0261, pre: 647.0, gt: 628.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [438/800] Iter:[120/150], Time: 0.62, lr: 4.2469, Loss: 0.0259, pre: 634.5, gt: 508.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [438/800] Iter:[140/150], Time: 0.61, lr: 4.2443, Loss: 0.0258, pre: 915.9, gt: 868.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [439/800] Iter:[0/150], Time: 1.91, lr: 4.2430, Loss: 0.0242, pre: 1703.1, gt: 1760.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [439/800] Iter:[20/150], Time: 0.65, lr: 4.2404, Loss: 0.0277, pre: 506.0, gt: 516.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [439/800] Iter:[40/150], Time: 0.62, lr: 4.2378, Loss: 0.0273, pre: 219.7, gt: 181.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [439/800] Iter:[60/150], Time: 0.60, lr: 4.2352, Loss: 0.0282, pre: 1698.5, gt: 1806.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [439/800] Iter:[80/150], Time: 0.60, lr: 4.2327, Loss: 0.0276, pre: 1494.7, gt: 1533.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [439/800] Iter:[100/150], Time: 0.60, lr: 4.2301, Loss: 0.0266, pre: 1599.4, gt: 1746.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [439/800] Iter:[120/150], Time: 0.59, lr: 4.2275, Loss: 0.0266, pre: 377.4, gt: 305.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [439/800] Iter:[140/150], Time: 0.59, lr: 4.2249, Loss: 0.0265, pre: 1298.6, gt: 1399.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  97.97, Best_MAE:  85.8329 MSE:  169.7179,Best_MSE:  139.3664\n","Epoch: [440/800] Iter:[0/150], Time: 4.37, lr: 4.2236, Loss: 0.0184, pre: 693.3, gt: 567.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [440/800] Iter:[20/150], Time: 0.77, lr: 4.2210, Loss: 0.0293, pre: 1770.3, gt: 1695.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [440/800] Iter:[40/150], Time: 0.68, lr: 4.2184, Loss: 0.0263, pre: 1579.7, gt: 1652.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [440/800] Iter:[60/150], Time: 0.65, lr: 4.2159, Loss: 0.0266, pre: 1178.2, gt: 1348.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [440/800] Iter:[80/150], Time: 0.63, lr: 4.2133, Loss: 0.0264, pre: 1850.7, gt: 1782.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [440/800] Iter:[100/150], Time: 0.62, lr: 4.2107, Loss: 0.0262, pre: 1556.2, gt: 1606.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [440/800] Iter:[120/150], Time: 0.62, lr: 4.2081, Loss: 0.0258, pre: 1737.0, gt: 1714.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [440/800] Iter:[140/150], Time: 0.61, lr: 4.2055, Loss: 0.0257, pre: 3221.7, gt: 3411.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [441/800] Iter:[0/150], Time: 2.64, lr: 4.2042, Loss: 0.0066, pre: 124.6, gt: 80.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [441/800] Iter:[20/150], Time: 0.68, lr: 4.2017, Loss: 0.0226, pre: 852.2, gt: 725.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [441/800] Iter:[40/150], Time: 0.63, lr: 4.1991, Loss: 0.0234, pre: 1064.1, gt: 1137.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [441/800] Iter:[60/150], Time: 0.62, lr: 4.1965, Loss: 0.0238, pre: 957.6, gt: 921.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [441/800] Iter:[80/150], Time: 0.61, lr: 4.1939, Loss: 0.0245, pre: 6203.4, gt: 6175.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [441/800] Iter:[100/150], Time: 0.60, lr: 4.1913, Loss: 0.0252, pre: 6198.6, gt: 6356.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [441/800] Iter:[120/150], Time: 0.60, lr: 4.1888, Loss: 0.0252, pre: 843.7, gt: 833.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [441/800] Iter:[140/150], Time: 0.60, lr: 4.1862, Loss: 0.0258, pre: 2809.1, gt: 2714.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  101.91, Best_MAE:  85.8329 MSE:  187.6926,Best_MSE:  139.3664\n","Epoch: [442/800] Iter:[0/150], Time: 4.74, lr: 4.1849, Loss: 0.0075, pre: 340.2, gt: 397.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [442/800] Iter:[20/150], Time: 0.79, lr: 4.1823, Loss: 0.0257, pre: 5848.8, gt: 5419.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [442/800] Iter:[40/150], Time: 0.69, lr: 4.1797, Loss: 0.0256, pre: 1314.6, gt: 1309.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [442/800] Iter:[60/150], Time: 0.65, lr: 4.1771, Loss: 0.0262, pre: 2079.2, gt: 1880.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [442/800] Iter:[80/150], Time: 0.64, lr: 4.1746, Loss: 0.0267, pre: 4862.5, gt: 5105.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [442/800] Iter:[100/150], Time: 0.63, lr: 4.1720, Loss: 0.0266, pre: 720.8, gt: 715.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [442/800] Iter:[120/150], Time: 0.62, lr: 4.1694, Loss: 0.0264, pre: 667.3, gt: 666.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [442/800] Iter:[140/150], Time: 0.61, lr: 4.1668, Loss: 0.0265, pre: 908.4, gt: 997.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [443/800] Iter:[0/150], Time: 1.79, lr: 4.1655, Loss: 0.0111, pre: 777.0, gt: 686.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [443/800] Iter:[20/150], Time: 0.64, lr: 4.1630, Loss: 0.0265, pre: 886.9, gt: 1043.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [443/800] Iter:[40/150], Time: 0.61, lr: 4.1604, Loss: 0.0278, pre: 1358.8, gt: 1769.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [443/800] Iter:[60/150], Time: 0.60, lr: 4.1578, Loss: 0.0273, pre: 2527.1, gt: 2762.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [443/800] Iter:[80/150], Time: 0.60, lr: 4.1552, Loss: 0.0275, pre: 1015.5, gt: 1101.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [443/800] Iter:[100/150], Time: 0.59, lr: 4.1527, Loss: 0.0273, pre: 1148.1, gt: 947.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [443/800] Iter:[120/150], Time: 0.59, lr: 4.1501, Loss: 0.0263, pre: 378.3, gt: 426.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [443/800] Iter:[140/150], Time: 0.59, lr: 4.1475, Loss: 0.0262, pre: 1618.2, gt: 1471.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  101.80, Best_MAE:  85.8329 MSE:  189.5456,Best_MSE:  139.3664\n","Epoch: [444/800] Iter:[0/150], Time: 4.62, lr: 4.1462, Loss: 0.0117, pre: 416.2, gt: 394.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [444/800] Iter:[20/150], Time: 0.78, lr: 4.1436, Loss: 0.0228, pre: 2446.4, gt: 2518.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [444/800] Iter:[40/150], Time: 0.68, lr: 4.1411, Loss: 0.0252, pre: 1256.7, gt: 1225.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [444/800] Iter:[60/150], Time: 0.65, lr: 4.1385, Loss: 0.0261, pre: 563.2, gt: 529.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [444/800] Iter:[80/150], Time: 0.63, lr: 4.1359, Loss: 0.0262, pre: 455.1, gt: 411.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [444/800] Iter:[100/150], Time: 0.62, lr: 4.1333, Loss: 0.0264, pre: 3768.9, gt: 3428.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [444/800] Iter:[120/150], Time: 0.62, lr: 4.1308, Loss: 0.0267, pre: 583.9, gt: 622.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [444/800] Iter:[140/150], Time: 0.61, lr: 4.1282, Loss: 0.0266, pre: 556.3, gt: 546.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [445/800] Iter:[0/150], Time: 1.86, lr: 4.1269, Loss: 0.0284, pre: 1551.6, gt: 1848.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [445/800] Iter:[20/150], Time: 0.64, lr: 4.1243, Loss: 0.0277, pre: 1124.4, gt: 1048.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [445/800] Iter:[40/150], Time: 0.61, lr: 4.1217, Loss: 0.0272, pre: 2361.1, gt: 2195.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [445/800] Iter:[60/150], Time: 0.60, lr: 4.1192, Loss: 0.0266, pre: 481.1, gt: 495.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.96,acc1:0.00\n","Epoch: [445/800] Iter:[80/150], Time: 0.60, lr: 4.1166, Loss: 0.0275, pre: 3013.2, gt: 2654.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.96,acc1:0.00\n","Epoch: [445/800] Iter:[100/150], Time: 0.59, lr: 4.1140, Loss: 0.0269, pre: 2518.0, gt: 2772.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.96,acc1:0.00\n","Epoch: [445/800] Iter:[120/150], Time: 0.59, lr: 4.1115, Loss: 0.0263, pre: 1171.9, gt: 1065.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [445/800] Iter:[140/150], Time: 0.59, lr: 4.1089, Loss: 0.0264, pre: 2492.8, gt: 2457.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  90.06, Best_MAE:  85.8329 MSE:  144.5198,Best_MSE:  139.3664\n","Epoch: [446/800] Iter:[0/150], Time: 4.88, lr: 4.1076, Loss: 0.0267, pre: 1184.0, gt: 1233.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [446/800] Iter:[20/150], Time: 0.79, lr: 4.1050, Loss: 0.0239, pre: 6344.5, gt: 6023.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.96,acc1:0.00\n","Epoch: [446/800] Iter:[40/150], Time: 0.69, lr: 4.1024, Loss: 0.0246, pre: 1110.8, gt: 1288.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.96,acc1:0.00\n","Epoch: [446/800] Iter:[60/150], Time: 0.65, lr: 4.0999, Loss: 0.0241, pre: 1209.8, gt: 1239.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.96,acc1:0.00\n","Epoch: [446/800] Iter:[80/150], Time: 0.64, lr: 4.0973, Loss: 0.0249, pre: 5287.1, gt: 6070.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.96,acc1:0.00\n","Epoch: [446/800] Iter:[100/150], Time: 0.62, lr: 4.0947, Loss: 0.0247, pre: 1245.0, gt: 1244.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.96,acc1:0.00\n","Epoch: [446/800] Iter:[120/150], Time: 0.62, lr: 4.0922, Loss: 0.0259, pre: 7499.4, gt: 6719.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.96,acc1:0.00\n","Epoch: [446/800] Iter:[140/150], Time: 0.61, lr: 4.0896, Loss: 0.0265, pre: 1651.9, gt: 1844.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.96,acc1:0.00\n","Epoch: [447/800] Iter:[0/150], Time: 1.74, lr: 4.0883, Loss: 0.0198, pre: 420.1, gt: 488.0,acc:0.92, accx8:0.95,  accx16:0.95,accx32:0.96,acc1:0.00\n","Epoch: [447/800] Iter:[20/150], Time: 0.64, lr: 4.0857, Loss: 0.0287, pre: 1552.7, gt: 1691.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.96,acc1:0.00\n","Epoch: [447/800] Iter:[40/150], Time: 0.61, lr: 4.0832, Loss: 0.0272, pre: 1533.9, gt: 1384.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.96,acc1:0.00\n","Epoch: [447/800] Iter:[60/150], Time: 0.60, lr: 4.0806, Loss: 0.0265, pre: 3070.4, gt: 3431.0,acc:0.92, accx8:0.94,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [447/800] Iter:[80/150], Time: 0.60, lr: 4.0780, Loss: 0.0260, pre: 2219.2, gt: 2194.0,acc:0.92, accx8:0.94,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [447/800] Iter:[100/150], Time: 0.59, lr: 4.0755, Loss: 0.0262, pre: 987.8, gt: 1040.0,acc:0.92, accx8:0.94,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [447/800] Iter:[120/150], Time: 0.59, lr: 4.0729, Loss: 0.0259, pre: 677.5, gt: 689.0,acc:0.92, accx8:0.94,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [447/800] Iter:[140/150], Time: 0.59, lr: 4.0703, Loss: 0.0258, pre: 809.4, gt: 898.0,acc:0.92, accx8:0.94,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  84.86, Best_MAE:  84.8633 MSE:  150.8886,Best_MSE:  139.3664\n","Epoch: [448/800] Iter:[0/150], Time: 4.43, lr: 4.0690, Loss: 0.0345, pre: 2587.0, gt: 2491.0,acc:0.92, accx8:0.94,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [448/800] Iter:[20/150], Time: 0.77, lr: 4.0665, Loss: 0.0279, pre: 1249.1, gt: 1259.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.96,acc1:0.00\n","Epoch: [448/800] Iter:[40/150], Time: 0.68, lr: 4.0639, Loss: 0.0267, pre: 292.4, gt: 300.0,acc:0.92, accx8:0.94,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [448/800] Iter:[60/150], Time: 0.65, lr: 4.0613, Loss: 0.0267, pre: 1488.1, gt: 1603.0,acc:0.92, accx8:0.94,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [448/800] Iter:[80/150], Time: 0.63, lr: 4.0588, Loss: 0.0262, pre: 1059.2, gt: 1060.0,acc:0.92, accx8:0.94,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [448/800] Iter:[100/150], Time: 0.62, lr: 4.0562, Loss: 0.0263, pre: 538.5, gt: 645.0,acc:0.92, accx8:0.94,  accx16:0.95,accx32:0.96,acc1:0.00\n","Epoch: [448/800] Iter:[120/150], Time: 0.62, lr: 4.0536, Loss: 0.0262, pre: 826.7, gt: 907.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [448/800] Iter:[140/150], Time: 0.61, lr: 4.0511, Loss: 0.0256, pre: 705.0, gt: 772.0,acc:0.92, accx8:0.94,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [449/800] Iter:[0/150], Time: 2.46, lr: 4.0498, Loss: 0.0407, pre: 2599.5, gt: 3178.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [449/800] Iter:[20/150], Time: 0.67, lr: 4.0472, Loss: 0.0240, pre: 1180.6, gt: 1187.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [449/800] Iter:[40/150], Time: 0.63, lr: 4.0446, Loss: 0.0266, pre: 742.9, gt: 716.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [449/800] Iter:[60/150], Time: 0.61, lr: 4.0421, Loss: 0.0271, pre: 903.0, gt: 882.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [449/800] Iter:[80/150], Time: 0.61, lr: 4.0395, Loss: 0.0266, pre: 788.3, gt: 839.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [449/800] Iter:[100/150], Time: 0.60, lr: 4.0369, Loss: 0.0271, pre: 2096.1, gt: 2286.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [449/800] Iter:[120/150], Time: 0.60, lr: 4.0344, Loss: 0.0271, pre: 1826.7, gt: 1853.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [449/800] Iter:[140/150], Time: 0.60, lr: 4.0318, Loss: 0.0269, pre: 457.7, gt: 485.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  95.33, Best_MAE:  84.8633 MSE:  151.0741,Best_MSE:  139.3664\n","Epoch: [450/800] Iter:[0/150], Time: 4.56, lr: 4.0305, Loss: 0.0174, pre: 616.1, gt: 661.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [450/800] Iter:[20/150], Time: 0.78, lr: 4.0280, Loss: 0.0271, pre: 1146.5, gt: 1408.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [450/800] Iter:[40/150], Time: 0.68, lr: 4.0254, Loss: 0.0269, pre: 602.0, gt: 710.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [450/800] Iter:[60/150], Time: 0.65, lr: 4.0228, Loss: 0.0262, pre: 432.2, gt: 491.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [450/800] Iter:[80/150], Time: 0.63, lr: 4.0203, Loss: 0.0257, pre: 1943.6, gt: 2009.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [450/800] Iter:[100/150], Time: 0.62, lr: 4.0177, Loss: 0.0263, pre: 1633.4, gt: 1561.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [450/800] Iter:[120/150], Time: 0.62, lr: 4.0151, Loss: 0.0258, pre: 541.5, gt: 564.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [450/800] Iter:[140/150], Time: 0.61, lr: 4.0126, Loss: 0.0255, pre: 1365.5, gt: 1401.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [451/800] Iter:[0/150], Time: 1.88, lr: 4.0113, Loss: 0.0300, pre: 2518.0, gt: 2193.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [451/800] Iter:[20/150], Time: 0.65, lr: 4.0087, Loss: 0.0235, pre: 447.2, gt: 442.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [451/800] Iter:[40/150], Time: 0.62, lr: 4.0062, Loss: 0.0252, pre: 1550.8, gt: 1694.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [451/800] Iter:[60/150], Time: 0.60, lr: 4.0036, Loss: 0.0266, pre: 3385.4, gt: 3746.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [451/800] Iter:[80/150], Time: 0.60, lr: 4.0010, Loss: 0.0273, pre: 1793.9, gt: 1954.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [451/800] Iter:[100/150], Time: 0.60, lr: 3.9985, Loss: 0.0268, pre: 1424.5, gt: 1573.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [451/800] Iter:[120/150], Time: 0.59, lr: 3.9959, Loss: 0.0260, pre: 519.1, gt: 647.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [451/800] Iter:[140/150], Time: 0.59, lr: 3.9934, Loss: 0.0260, pre: 603.2, gt: 607.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  92.54, Best_MAE:  84.8633 MSE:  162.4423,Best_MSE:  139.3664\n","Epoch: [452/800] Iter:[0/150], Time: 3.98, lr: 3.9921, Loss: 0.0528, pre: 4231.6, gt: 4073.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [452/800] Iter:[20/150], Time: 0.75, lr: 3.9895, Loss: 0.0341, pre: 1859.1, gt: 1757.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [452/800] Iter:[40/150], Time: 0.67, lr: 3.9870, Loss: 0.0293, pre: 2447.6, gt: 2377.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [452/800] Iter:[60/150], Time: 0.64, lr: 3.9844, Loss: 0.0287, pre: 650.2, gt: 790.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [452/800] Iter:[80/150], Time: 0.63, lr: 3.9818, Loss: 0.0277, pre: 1260.6, gt: 1252.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [452/800] Iter:[100/150], Time: 0.62, lr: 3.9793, Loss: 0.0271, pre: 762.7, gt: 1101.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [452/800] Iter:[120/150], Time: 0.61, lr: 3.9767, Loss: 0.0269, pre: 1018.6, gt: 805.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [452/800] Iter:[140/150], Time: 0.61, lr: 3.9742, Loss: 0.0264, pre: 454.0, gt: 517.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [453/800] Iter:[0/150], Time: 2.05, lr: 3.9729, Loss: 0.0160, pre: 583.5, gt: 659.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [453/800] Iter:[20/150], Time: 0.66, lr: 3.9703, Loss: 0.0235, pre: 483.6, gt: 381.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [453/800] Iter:[40/150], Time: 0.62, lr: 3.9678, Loss: 0.0245, pre: 1199.5, gt: 1382.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [453/800] Iter:[60/150], Time: 0.61, lr: 3.9652, Loss: 0.0253, pre: 2379.8, gt: 2325.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [453/800] Iter:[80/150], Time: 0.60, lr: 3.9626, Loss: 0.0255, pre: 1503.6, gt: 1361.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [453/800] Iter:[100/150], Time: 0.60, lr: 3.9601, Loss: 0.0259, pre: 1217.9, gt: 1292.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [453/800] Iter:[120/150], Time: 0.60, lr: 3.9575, Loss: 0.0260, pre: 2129.2, gt: 2049.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [453/800] Iter:[140/150], Time: 0.59, lr: 3.9550, Loss: 0.0260, pre: 1151.2, gt: 1505.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  98.34, Best_MAE:  84.8633 MSE:  183.0720,Best_MSE:  139.3664\n","Epoch: [454/800] Iter:[0/150], Time: 4.81, lr: 3.9537, Loss: 0.0283, pre: 906.6, gt: 937.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [454/800] Iter:[20/150], Time: 0.79, lr: 3.9511, Loss: 0.0238, pre: 1977.1, gt: 2547.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [454/800] Iter:[40/150], Time: 0.69, lr: 3.9486, Loss: 0.0244, pre: 2275.1, gt: 2225.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [454/800] Iter:[60/150], Time: 0.65, lr: 3.9460, Loss: 0.0253, pre: 1715.5, gt: 1647.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [454/800] Iter:[80/150], Time: 0.64, lr: 3.9435, Loss: 0.0249, pre: 2469.4, gt: 2483.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [454/800] Iter:[100/150], Time: 0.63, lr: 3.9409, Loss: 0.0256, pre: 1405.2, gt: 1374.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [454/800] Iter:[120/150], Time: 0.62, lr: 3.9384, Loss: 0.0256, pre: 1347.3, gt: 1481.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [454/800] Iter:[140/150], Time: 0.61, lr: 3.9358, Loss: 0.0251, pre: 1057.5, gt: 1091.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [455/800] Iter:[0/150], Time: 1.83, lr: 3.9345, Loss: 0.0195, pre: 803.9, gt: 843.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [455/800] Iter:[20/150], Time: 0.64, lr: 3.9320, Loss: 0.0263, pre: 2295.1, gt: 2394.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [455/800] Iter:[40/150], Time: 0.61, lr: 3.9294, Loss: 0.0250, pre: 1726.7, gt: 1819.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [455/800] Iter:[60/150], Time: 0.60, lr: 3.9269, Loss: 0.0245, pre: 994.8, gt: 933.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [455/800] Iter:[80/150], Time: 0.60, lr: 3.9243, Loss: 0.0249, pre: 2331.7, gt: 2341.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [455/800] Iter:[100/150], Time: 0.60, lr: 3.9218, Loss: 0.0249, pre: 1835.8, gt: 1920.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [455/800] Iter:[120/150], Time: 0.59, lr: 3.9192, Loss: 0.0246, pre: 478.9, gt: 480.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [455/800] Iter:[140/150], Time: 0.59, lr: 3.9167, Loss: 0.0243, pre: 924.7, gt: 1091.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  102.44, Best_MAE:  84.8633 MSE:  185.3981,Best_MSE:  139.3664\n","Epoch: [456/800] Iter:[0/150], Time: 4.63, lr: 3.9154, Loss: 0.0164, pre: 609.7, gt: 680.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [456/800] Iter:[20/150], Time: 0.78, lr: 3.9128, Loss: 0.0255, pre: 2061.6, gt: 2276.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [456/800] Iter:[40/150], Time: 0.68, lr: 3.9103, Loss: 0.0241, pre: 585.8, gt: 601.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [456/800] Iter:[60/150], Time: 0.65, lr: 3.9077, Loss: 0.0244, pre: 1482.4, gt: 1653.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [456/800] Iter:[80/150], Time: 0.63, lr: 3.9052, Loss: 0.0249, pre: 3501.1, gt: 3165.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [456/800] Iter:[100/150], Time: 0.62, lr: 3.9026, Loss: 0.0254, pre: 1155.1, gt: 1100.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [456/800] Iter:[120/150], Time: 0.62, lr: 3.9001, Loss: 0.0253, pre: 1028.0, gt: 1087.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [456/800] Iter:[140/150], Time: 0.61, lr: 3.8975, Loss: 0.0255, pre: 1572.1, gt: 1315.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [457/800] Iter:[0/150], Time: 2.44, lr: 3.8962, Loss: 0.0359, pre: 3082.4, gt: 2833.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [457/800] Iter:[20/150], Time: 0.67, lr: 3.8937, Loss: 0.0254, pre: 791.6, gt: 749.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [457/800] Iter:[40/150], Time: 0.63, lr: 3.8911, Loss: 0.0279, pre: 2272.5, gt: 2309.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [457/800] Iter:[60/150], Time: 0.61, lr: 3.8886, Loss: 0.0279, pre: 3944.0, gt: 3604.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [457/800] Iter:[80/150], Time: 0.61, lr: 3.8860, Loss: 0.0272, pre: 643.9, gt: 636.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [457/800] Iter:[100/150], Time: 0.60, lr: 3.8835, Loss: 0.0263, pre: 213.3, gt: 262.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [457/800] Iter:[120/150], Time: 0.60, lr: 3.8809, Loss: 0.0267, pre: 1456.4, gt: 1505.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [457/800] Iter:[140/150], Time: 0.60, lr: 3.8784, Loss: 0.0264, pre: 2069.2, gt: 1935.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  88.88, Best_MAE:  84.8633 MSE:  149.4515,Best_MSE:  139.3664\n","Epoch: [458/800] Iter:[0/150], Time: 4.84, lr: 3.8771, Loss: 0.0267, pre: 1458.9, gt: 1433.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [458/800] Iter:[20/150], Time: 0.79, lr: 3.8746, Loss: 0.0271, pre: 685.1, gt: 656.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [458/800] Iter:[40/150], Time: 0.69, lr: 3.8720, Loss: 0.0260, pre: 850.8, gt: 852.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [458/800] Iter:[60/150], Time: 0.65, lr: 3.8695, Loss: 0.0261, pre: 1755.6, gt: 1577.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [458/800] Iter:[80/150], Time: 0.63, lr: 3.8669, Loss: 0.0273, pre: 1807.9, gt: 1502.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [458/800] Iter:[100/150], Time: 0.62, lr: 3.8644, Loss: 0.0264, pre: 1893.7, gt: 1955.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [458/800] Iter:[120/150], Time: 0.62, lr: 3.8618, Loss: 0.0264, pre: 2825.2, gt: 2727.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [458/800] Iter:[140/150], Time: 0.61, lr: 3.8593, Loss: 0.0260, pre: 2693.4, gt: 2639.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [459/800] Iter:[0/150], Time: 1.89, lr: 3.8580, Loss: 0.0316, pre: 3118.7, gt: 3177.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [459/800] Iter:[20/150], Time: 0.65, lr: 3.8555, Loss: 0.0278, pre: 794.4, gt: 813.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [459/800] Iter:[40/150], Time: 0.62, lr: 3.8529, Loss: 0.0260, pre: 2814.6, gt: 3658.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [459/800] Iter:[60/150], Time: 0.61, lr: 3.8504, Loss: 0.0267, pre: 1459.4, gt: 1477.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [459/800] Iter:[80/150], Time: 0.60, lr: 3.8478, Loss: 0.0266, pre: 1692.5, gt: 1609.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [459/800] Iter:[100/150], Time: 0.60, lr: 3.8453, Loss: 0.0259, pre: 855.0, gt: 956.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [459/800] Iter:[120/150], Time: 0.59, lr: 3.8428, Loss: 0.0266, pre: 1563.1, gt: 1702.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [459/800] Iter:[140/150], Time: 0.59, lr: 3.8402, Loss: 0.0268, pre: 1682.2, gt: 1782.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  92.61, Best_MAE:  84.8633 MSE:  157.9129,Best_MSE:  139.3664\n","Epoch: [460/800] Iter:[0/150], Time: 4.43, lr: 3.8389, Loss: 0.0098, pre: 364.8, gt: 354.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [460/800] Iter:[20/150], Time: 0.77, lr: 3.8364, Loss: 0.0245, pre: 1455.8, gt: 1437.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [460/800] Iter:[40/150], Time: 0.68, lr: 3.8339, Loss: 0.0250, pre: 1848.2, gt: 1910.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [460/800] Iter:[60/150], Time: 0.65, lr: 3.8313, Loss: 0.0257, pre: 718.3, gt: 768.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [460/800] Iter:[80/150], Time: 0.63, lr: 3.8288, Loss: 0.0251, pre: 2563.8, gt: 2749.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [460/800] Iter:[100/150], Time: 0.62, lr: 3.8262, Loss: 0.0254, pre: 2856.6, gt: 2723.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [460/800] Iter:[120/150], Time: 0.62, lr: 3.8237, Loss: 0.0251, pre: 451.2, gt: 492.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [460/800] Iter:[140/150], Time: 0.61, lr: 3.8211, Loss: 0.0253, pre: 820.2, gt: 801.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [461/800] Iter:[0/150], Time: 2.79, lr: 3.8199, Loss: 0.0530, pre: 3030.5, gt: 4006.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [461/800] Iter:[20/150], Time: 0.69, lr: 3.8173, Loss: 0.0275, pre: 2755.7, gt: 2876.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [461/800] Iter:[40/150], Time: 0.64, lr: 3.8148, Loss: 0.0285, pre: 2589.3, gt: 2787.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [461/800] Iter:[60/150], Time: 0.62, lr: 3.8123, Loss: 0.0280, pre: 418.6, gt: 531.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [461/800] Iter:[80/150], Time: 0.61, lr: 3.8097, Loss: 0.0279, pre: 3512.2, gt: 3394.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [461/800] Iter:[100/150], Time: 0.60, lr: 3.8072, Loss: 0.0278, pre: 5008.4, gt: 5087.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [461/800] Iter:[120/150], Time: 0.60, lr: 3.8046, Loss: 0.0270, pre: 1218.9, gt: 1308.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [461/800] Iter:[140/150], Time: 0.60, lr: 3.8021, Loss: 0.0265, pre: 1018.4, gt: 877.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  104.23, Best_MAE:  84.8633 MSE:  169.9875,Best_MSE:  139.3664\n","Epoch: [462/800] Iter:[0/150], Time: 4.55, lr: 3.8008, Loss: 0.0280, pre: 2185.0, gt: 2316.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [462/800] Iter:[20/150], Time: 0.78, lr: 3.7983, Loss: 0.0263, pre: 1462.9, gt: 1366.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [462/800] Iter:[40/150], Time: 0.68, lr: 3.7958, Loss: 0.0266, pre: 1364.4, gt: 1931.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [462/800] Iter:[60/150], Time: 0.65, lr: 3.7932, Loss: 0.0271, pre: 709.2, gt: 781.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [462/800] Iter:[80/150], Time: 0.63, lr: 3.7907, Loss: 0.0264, pre: 1843.5, gt: 2149.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [462/800] Iter:[100/150], Time: 0.62, lr: 3.7881, Loss: 0.0259, pre: 691.3, gt: 700.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [462/800] Iter:[120/150], Time: 0.62, lr: 3.7856, Loss: 0.0257, pre: 1041.0, gt: 1079.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [462/800] Iter:[140/150], Time: 0.61, lr: 3.7831, Loss: 0.0256, pre: 1526.4, gt: 1376.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [463/800] Iter:[0/150], Time: 2.19, lr: 3.7818, Loss: 0.0397, pre: 3997.9, gt: 3667.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [463/800] Iter:[20/150], Time: 0.66, lr: 3.7793, Loss: 0.0255, pre: 361.8, gt: 352.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [463/800] Iter:[40/150], Time: 0.62, lr: 3.7767, Loss: 0.0263, pre: 2477.1, gt: 2935.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [463/800] Iter:[60/150], Time: 0.61, lr: 3.7742, Loss: 0.0255, pre: 496.2, gt: 522.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [463/800] Iter:[80/150], Time: 0.60, lr: 3.7717, Loss: 0.0252, pre: 539.3, gt: 445.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [463/800] Iter:[100/150], Time: 0.60, lr: 3.7691, Loss: 0.0252, pre: 1650.7, gt: 1984.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.96,acc1:0.00\n","Epoch: [463/800] Iter:[120/150], Time: 0.60, lr: 3.7666, Loss: 0.0250, pre: 2456.5, gt: 2618.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [463/800] Iter:[140/150], Time: 0.60, lr: 3.7641, Loss: 0.0250, pre: 2691.2, gt: 2546.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  90.63, Best_MAE:  84.8633 MSE:  155.2538,Best_MSE:  139.3664\n","Epoch: [464/800] Iter:[0/150], Time: 4.35, lr: 3.7628, Loss: 0.0502, pre: 3038.7, gt: 3005.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [464/800] Iter:[20/150], Time: 0.77, lr: 3.7603, Loss: 0.0270, pre: 4691.3, gt: 5091.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [464/800] Iter:[40/150], Time: 0.68, lr: 3.7577, Loss: 0.0239, pre: 744.8, gt: 678.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [464/800] Iter:[60/150], Time: 0.65, lr: 3.7552, Loss: 0.0250, pre: 2819.7, gt: 3109.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [464/800] Iter:[80/150], Time: 0.63, lr: 3.7527, Loss: 0.0252, pre: 673.8, gt: 649.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [464/800] Iter:[100/150], Time: 0.62, lr: 3.7501, Loss: 0.0257, pre: 1064.7, gt: 945.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [464/800] Iter:[120/150], Time: 0.61, lr: 3.7476, Loss: 0.0260, pre: 1209.5, gt: 1324.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [464/800] Iter:[140/150], Time: 0.61, lr: 3.7451, Loss: 0.0256, pre: 477.3, gt: 629.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [465/800] Iter:[0/150], Time: 1.84, lr: 3.7438, Loss: 0.0217, pre: 781.3, gt: 722.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [465/800] Iter:[20/150], Time: 0.64, lr: 3.7413, Loss: 0.0249, pre: 3700.6, gt: 4045.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [465/800] Iter:[40/150], Time: 0.61, lr: 3.7387, Loss: 0.0272, pre: 6629.5, gt: 6774.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [465/800] Iter:[60/150], Time: 0.60, lr: 3.7362, Loss: 0.0266, pre: 2096.4, gt: 2253.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [465/800] Iter:[80/150], Time: 0.60, lr: 3.7337, Loss: 0.0257, pre: 1058.5, gt: 1302.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [465/800] Iter:[100/150], Time: 0.60, lr: 3.7312, Loss: 0.0256, pre: 633.9, gt: 610.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [465/800] Iter:[120/150], Time: 0.59, lr: 3.7286, Loss: 0.0258, pre: 3623.3, gt: 3466.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [465/800] Iter:[140/150], Time: 0.59, lr: 3.7261, Loss: 0.0257, pre: 1946.9, gt: 1862.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  84.12, Best_MAE:  84.1187 MSE:  139.9406,Best_MSE:  139.3664\n","Epoch: [466/800] Iter:[0/150], Time: 3.91, lr: 3.7248, Loss: 0.0205, pre: 924.4, gt: 820.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [466/800] Iter:[20/150], Time: 0.75, lr: 3.7223, Loss: 0.0242, pre: 1251.6, gt: 1317.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [466/800] Iter:[40/150], Time: 0.67, lr: 3.7198, Loss: 0.0239, pre: 2506.1, gt: 2489.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [466/800] Iter:[60/150], Time: 0.64, lr: 3.7173, Loss: 0.0244, pre: 1428.9, gt: 1608.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [466/800] Iter:[80/150], Time: 0.62, lr: 3.7147, Loss: 0.0250, pre: 1639.5, gt: 1794.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [466/800] Iter:[100/150], Time: 0.62, lr: 3.7122, Loss: 0.0245, pre: 1258.2, gt: 1376.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [466/800] Iter:[120/150], Time: 0.61, lr: 3.7097, Loss: 0.0246, pre: 1764.4, gt: 1691.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [466/800] Iter:[140/150], Time: 0.61, lr: 3.7071, Loss: 0.0253, pre: 568.5, gt: 553.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [467/800] Iter:[0/150], Time: 2.29, lr: 3.7059, Loss: 0.0345, pre: 1716.2, gt: 1666.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [467/800] Iter:[20/150], Time: 0.66, lr: 3.7034, Loss: 0.0251, pre: 488.6, gt: 432.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [467/800] Iter:[40/150], Time: 0.62, lr: 3.7008, Loss: 0.0269, pre: 2388.5, gt: 2396.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [467/800] Iter:[60/150], Time: 0.61, lr: 3.6983, Loss: 0.0264, pre: 1146.3, gt: 1116.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [467/800] Iter:[80/150], Time: 0.60, lr: 3.6958, Loss: 0.0260, pre: 1241.6, gt: 1428.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [467/800] Iter:[100/150], Time: 0.60, lr: 3.6933, Loss: 0.0259, pre: 4233.6, gt: 4214.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [467/800] Iter:[120/150], Time: 0.60, lr: 3.6907, Loss: 0.0261, pre: 1272.0, gt: 1190.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [467/800] Iter:[140/150], Time: 0.59, lr: 3.6882, Loss: 0.0262, pre: 1045.6, gt: 1335.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  97.68, Best_MAE:  84.1187 MSE:  163.0858,Best_MSE:  139.3664\n","Epoch: [468/800] Iter:[0/150], Time: 5.07, lr: 3.6870, Loss: 0.0091, pre: 208.1, gt: 253.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [468/800] Iter:[20/150], Time: 0.80, lr: 3.6844, Loss: 0.0291, pre: 6142.7, gt: 6115.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [468/800] Iter:[40/150], Time: 0.69, lr: 3.6819, Loss: 0.0268, pre: 262.1, gt: 250.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [468/800] Iter:[60/150], Time: 0.66, lr: 3.6794, Loss: 0.0248, pre: 299.3, gt: 406.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [468/800] Iter:[80/150], Time: 0.64, lr: 3.6769, Loss: 0.0245, pre: 2120.5, gt: 2349.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [468/800] Iter:[100/150], Time: 0.63, lr: 3.6743, Loss: 0.0246, pre: 686.1, gt: 695.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [468/800] Iter:[120/150], Time: 0.62, lr: 3.6718, Loss: 0.0247, pre: 3321.5, gt: 3714.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [468/800] Iter:[140/150], Time: 0.61, lr: 3.6693, Loss: 0.0250, pre: 2073.0, gt: 2021.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [469/800] Iter:[0/150], Time: 2.16, lr: 3.6680, Loss: 0.0205, pre: 1895.2, gt: 2009.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [469/800] Iter:[20/150], Time: 0.66, lr: 3.6655, Loss: 0.0259, pre: 1416.7, gt: 1295.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [469/800] Iter:[40/150], Time: 0.62, lr: 3.6630, Loss: 0.0258, pre: 2312.6, gt: 2400.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [469/800] Iter:[60/150], Time: 0.61, lr: 3.6605, Loss: 0.0263, pre: 2962.6, gt: 2814.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [469/800] Iter:[80/150], Time: 0.60, lr: 3.6580, Loss: 0.0257, pre: 3047.1, gt: 2880.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [469/800] Iter:[100/150], Time: 0.60, lr: 3.6554, Loss: 0.0255, pre: 413.9, gt: 447.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [469/800] Iter:[120/150], Time: 0.59, lr: 3.6529, Loss: 0.0257, pre: 682.3, gt: 728.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [469/800] Iter:[140/150], Time: 0.59, lr: 3.6504, Loss: 0.0257, pre: 1167.8, gt: 1126.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  99.71, Best_MAE:  84.1187 MSE:  174.4488,Best_MSE:  139.3664\n","Epoch: [470/800] Iter:[0/150], Time: 4.28, lr: 3.6492, Loss: 0.0289, pre: 1805.8, gt: 1920.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [470/800] Iter:[20/150], Time: 0.76, lr: 3.6466, Loss: 0.0243, pre: 705.1, gt: 723.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [470/800] Iter:[40/150], Time: 0.67, lr: 3.6441, Loss: 0.0254, pre: 1202.4, gt: 1169.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [470/800] Iter:[60/150], Time: 0.64, lr: 3.6416, Loss: 0.0250, pre: 1353.8, gt: 1351.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [470/800] Iter:[80/150], Time: 0.63, lr: 3.6391, Loss: 0.0249, pre: 1459.6, gt: 1358.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [470/800] Iter:[100/150], Time: 0.62, lr: 3.6366, Loss: 0.0252, pre: 1933.7, gt: 2321.0,acc:0.93, accx8:0.95,  accx16:0.95,accx32:0.95,acc1:0.00\n","Epoch: [470/800] Iter:[120/150], Time: 0.61, lr: 3.6341, Loss: 0.0252, pre: 247.3, gt: 308.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [470/800] Iter:[140/150], Time: 0.61, lr: 3.6315, Loss: 0.0252, pre: 1598.9, gt: 1589.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [471/800] Iter:[0/150], Time: 1.69, lr: 3.6303, Loss: 0.0127, pre: 342.7, gt: 324.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [471/800] Iter:[20/150], Time: 0.64, lr: 3.6278, Loss: 0.0300, pre: 8696.7, gt: 7992.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [471/800] Iter:[40/150], Time: 0.61, lr: 3.6253, Loss: 0.0270, pre: 1009.8, gt: 849.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [471/800] Iter:[60/150], Time: 0.60, lr: 3.6227, Loss: 0.0260, pre: 1821.7, gt: 1715.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [471/800] Iter:[80/150], Time: 0.60, lr: 3.6202, Loss: 0.0255, pre: 688.0, gt: 607.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [471/800] Iter:[100/150], Time: 0.59, lr: 3.6177, Loss: 0.0252, pre: 2807.0, gt: 2740.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [471/800] Iter:[120/150], Time: 0.59, lr: 3.6152, Loss: 0.0258, pre: 1749.6, gt: 1648.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [471/800] Iter:[140/150], Time: 0.59, lr: 3.6127, Loss: 0.0261, pre: 2491.0, gt: 2388.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  81.09, Best_MAE:  81.0930 MSE:  134.1343,Best_MSE:  134.1343\n","Epoch: [472/800] Iter:[0/150], Time: 4.92, lr: 3.6114, Loss: 0.0257, pre: 1255.4, gt: 1334.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [472/800] Iter:[20/150], Time: 0.80, lr: 3.6089, Loss: 0.0236, pre: 1461.6, gt: 1530.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [472/800] Iter:[40/150], Time: 0.69, lr: 3.6064, Loss: 0.0238, pre: 800.8, gt: 803.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [472/800] Iter:[60/150], Time: 0.66, lr: 3.6039, Loss: 0.0253, pre: 1494.6, gt: 1859.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [472/800] Iter:[80/150], Time: 0.64, lr: 3.6014, Loss: 0.0255, pre: 1787.7, gt: 1942.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [472/800] Iter:[100/150], Time: 0.63, lr: 3.5989, Loss: 0.0263, pre: 1713.1, gt: 1284.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [472/800] Iter:[120/150], Time: 0.62, lr: 3.5964, Loss: 0.0262, pre: 588.1, gt: 604.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [472/800] Iter:[140/150], Time: 0.61, lr: 3.5939, Loss: 0.0258, pre: 2230.2, gt: 2258.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [473/800] Iter:[0/150], Time: 2.29, lr: 3.5926, Loss: 0.0236, pre: 1172.3, gt: 1414.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [473/800] Iter:[20/150], Time: 0.66, lr: 3.5901, Loss: 0.0236, pre: 3223.1, gt: 3088.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [473/800] Iter:[40/150], Time: 0.63, lr: 3.5876, Loss: 0.0253, pre: 1476.5, gt: 1754.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [473/800] Iter:[60/150], Time: 0.61, lr: 3.5851, Loss: 0.0259, pre: 5578.8, gt: 5944.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [473/800] Iter:[80/150], Time: 0.60, lr: 3.5826, Loss: 0.0260, pre: 1215.9, gt: 1244.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [473/800] Iter:[100/150], Time: 0.60, lr: 3.5801, Loss: 0.0256, pre: 1797.7, gt: 1689.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [473/800] Iter:[120/150], Time: 0.60, lr: 3.5776, Loss: 0.0258, pre: 1102.0, gt: 1117.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [473/800] Iter:[140/150], Time: 0.60, lr: 3.5751, Loss: 0.0258, pre: 4859.7, gt: 5210.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  92.16, Best_MAE:  81.0930 MSE:  154.0149,Best_MSE:  134.1343\n","Epoch: [474/800] Iter:[0/150], Time: 3.82, lr: 3.5738, Loss: 0.0266, pre: 923.6, gt: 1030.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [474/800] Iter:[20/150], Time: 0.74, lr: 3.5713, Loss: 0.0257, pre: 1197.5, gt: 1284.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [474/800] Iter:[40/150], Time: 0.66, lr: 3.5688, Loss: 0.0258, pre: 1764.5, gt: 2087.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [474/800] Iter:[60/150], Time: 0.64, lr: 3.5663, Loss: 0.0244, pre: 671.5, gt: 654.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [474/800] Iter:[80/150], Time: 0.62, lr: 3.5638, Loss: 0.0248, pre: 3579.3, gt: 3951.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [474/800] Iter:[100/150], Time: 0.62, lr: 3.5613, Loss: 0.0256, pre: 3167.7, gt: 3530.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [474/800] Iter:[120/150], Time: 0.61, lr: 3.5588, Loss: 0.0257, pre: 984.0, gt: 1255.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [474/800] Iter:[140/150], Time: 0.61, lr: 3.5563, Loss: 0.0253, pre: 949.4, gt: 944.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [475/800] Iter:[0/150], Time: 2.07, lr: 3.5550, Loss: 0.0316, pre: 1149.3, gt: 1186.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [475/800] Iter:[20/150], Time: 0.66, lr: 3.5525, Loss: 0.0250, pre: 390.3, gt: 678.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [475/800] Iter:[40/150], Time: 0.62, lr: 3.5500, Loss: 0.0265, pre: 1078.8, gt: 929.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [475/800] Iter:[60/150], Time: 0.61, lr: 3.5475, Loss: 0.0259, pre: 1227.8, gt: 1375.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [475/800] Iter:[80/150], Time: 0.60, lr: 3.5450, Loss: 0.0261, pre: 4071.7, gt: 4264.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [475/800] Iter:[100/150], Time: 0.60, lr: 3.5425, Loss: 0.0262, pre: 3149.3, gt: 2938.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [475/800] Iter:[120/150], Time: 0.60, lr: 3.5400, Loss: 0.0262, pre: 3300.7, gt: 3382.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [475/800] Iter:[140/150], Time: 0.59, lr: 3.5375, Loss: 0.0262, pre: 2051.5, gt: 1916.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  90.83, Best_MAE:  81.0930 MSE:  146.1924,Best_MSE:  134.1343\n","Epoch: [476/800] Iter:[0/150], Time: 4.42, lr: 3.5363, Loss: 0.0218, pre: 624.2, gt: 790.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [476/800] Iter:[20/150], Time: 0.77, lr: 3.5338, Loss: 0.0250, pre: 2741.0, gt: 2492.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [476/800] Iter:[40/150], Time: 0.68, lr: 3.5313, Loss: 0.0263, pre: 2052.2, gt: 2129.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [476/800] Iter:[60/150], Time: 0.65, lr: 3.5288, Loss: 0.0269, pre: 1124.2, gt: 1292.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [476/800] Iter:[80/150], Time: 0.63, lr: 3.5263, Loss: 0.0266, pre: 1134.2, gt: 1089.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [476/800] Iter:[100/150], Time: 0.62, lr: 3.5238, Loss: 0.0268, pre: 653.6, gt: 402.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [476/800] Iter:[120/150], Time: 0.61, lr: 3.5213, Loss: 0.0269, pre: 2915.1, gt: 2846.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [476/800] Iter:[140/150], Time: 0.61, lr: 3.5188, Loss: 0.0263, pre: 1237.4, gt: 1368.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [477/800] Iter:[0/150], Time: 2.43, lr: 3.5175, Loss: 0.0088, pre: 296.2, gt: 292.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [477/800] Iter:[20/150], Time: 0.67, lr: 3.5150, Loss: 0.0221, pre: 1060.9, gt: 1083.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [477/800] Iter:[40/150], Time: 0.63, lr: 3.5125, Loss: 0.0242, pre: 3801.5, gt: 3660.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [477/800] Iter:[60/150], Time: 0.61, lr: 3.5100, Loss: 0.0263, pre: 2298.8, gt: 2693.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [477/800] Iter:[80/150], Time: 0.61, lr: 3.5075, Loss: 0.0268, pre: 1735.6, gt: 1746.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [477/800] Iter:[100/150], Time: 0.60, lr: 3.5051, Loss: 0.0264, pre: 2641.6, gt: 2729.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [477/800] Iter:[120/150], Time: 0.60, lr: 3.5026, Loss: 0.0257, pre: 669.3, gt: 688.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [477/800] Iter:[140/150], Time: 0.60, lr: 3.5001, Loss: 0.0259, pre: 1143.6, gt: 1201.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  89.19, Best_MAE:  81.0930 MSE:  148.4204,Best_MSE:  134.1343\n","Epoch: [478/800] Iter:[0/150], Time: 5.37, lr: 3.4988, Loss: 0.0584, pre: 8163.9, gt: 8316.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [478/800] Iter:[20/150], Time: 0.81, lr: 3.4963, Loss: 0.0266, pre: 823.9, gt: 757.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [478/800] Iter:[40/150], Time: 0.70, lr: 3.4938, Loss: 0.0260, pre: 1244.4, gt: 1170.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [478/800] Iter:[60/150], Time: 0.66, lr: 3.4913, Loss: 0.0275, pre: 2675.7, gt: 2657.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [478/800] Iter:[80/150], Time: 0.64, lr: 3.4888, Loss: 0.0263, pre: 1930.5, gt: 1906.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [478/800] Iter:[100/150], Time: 0.63, lr: 3.4864, Loss: 0.0256, pre: 1084.3, gt: 1243.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [478/800] Iter:[120/150], Time: 0.62, lr: 3.4839, Loss: 0.0251, pre: 516.6, gt: 478.0,acc:0.92, accx8:0.94,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [478/800] Iter:[140/150], Time: 0.62, lr: 3.4814, Loss: 0.0254, pre: 913.8, gt: 975.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [479/800] Iter:[0/150], Time: 1.96, lr: 3.4801, Loss: 0.0258, pre: 2751.9, gt: 2710.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [479/800] Iter:[20/150], Time: 0.65, lr: 3.4776, Loss: 0.0253, pre: 1223.6, gt: 1312.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [479/800] Iter:[40/150], Time: 0.62, lr: 3.4751, Loss: 0.0248, pre: 607.5, gt: 646.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [479/800] Iter:[60/150], Time: 0.60, lr: 3.4727, Loss: 0.0253, pre: 1546.3, gt: 1685.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [479/800] Iter:[80/150], Time: 0.60, lr: 3.4702, Loss: 0.0265, pre: 1417.6, gt: 1343.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [479/800] Iter:[100/150], Time: 0.60, lr: 3.4677, Loss: 0.0264, pre: 3135.3, gt: 2746.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [479/800] Iter:[120/150], Time: 0.59, lr: 3.4652, Loss: 0.0265, pre: 3160.8, gt: 2983.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [479/800] Iter:[140/150], Time: 0.59, lr: 3.4627, Loss: 0.0266, pre: 1298.3, gt: 1360.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  92.22, Best_MAE:  81.0930 MSE:  149.7548,Best_MSE:  134.1343\n","Epoch: [480/800] Iter:[0/150], Time: 4.41, lr: 3.4615, Loss: 0.0128, pre: 803.7, gt: 744.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [480/800] Iter:[20/150], Time: 0.77, lr: 3.4590, Loss: 0.0242, pre: 1429.0, gt: 1467.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [480/800] Iter:[40/150], Time: 0.68, lr: 3.4565, Loss: 0.0259, pre: 877.7, gt: 842.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [480/800] Iter:[60/150], Time: 0.65, lr: 3.4540, Loss: 0.0262, pre: 485.2, gt: 491.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [480/800] Iter:[80/150], Time: 0.63, lr: 3.4515, Loss: 0.0265, pre: 2218.8, gt: 2294.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [480/800] Iter:[100/150], Time: 0.62, lr: 3.4490, Loss: 0.0262, pre: 1555.7, gt: 1407.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [480/800] Iter:[120/150], Time: 0.61, lr: 3.4465, Loss: 0.0260, pre: 983.9, gt: 978.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [480/800] Iter:[140/150], Time: 0.61, lr: 3.4441, Loss: 0.0257, pre: 234.4, gt: 252.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [481/800] Iter:[0/150], Time: 1.86, lr: 3.4428, Loss: 0.0248, pre: 634.1, gt: 657.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [481/800] Iter:[20/150], Time: 0.65, lr: 3.4403, Loss: 0.0257, pre: 1188.9, gt: 1247.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [481/800] Iter:[40/150], Time: 0.61, lr: 3.4378, Loss: 0.0248, pre: 875.3, gt: 904.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [481/800] Iter:[60/150], Time: 0.60, lr: 3.4354, Loss: 0.0247, pre: 3481.1, gt: 3219.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [481/800] Iter:[80/150], Time: 0.60, lr: 3.4329, Loss: 0.0244, pre: 785.7, gt: 819.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [481/800] Iter:[100/150], Time: 0.60, lr: 3.4304, Loss: 0.0241, pre: 1429.5, gt: 1432.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [481/800] Iter:[120/150], Time: 0.59, lr: 3.4279, Loss: 0.0250, pre: 793.0, gt: 834.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [481/800] Iter:[140/150], Time: 0.59, lr: 3.4254, Loss: 0.0252, pre: 1099.7, gt: 1203.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  97.40, Best_MAE:  81.0930 MSE:  174.8160,Best_MSE:  134.1343\n","Epoch: [482/800] Iter:[0/150], Time: 4.70, lr: 3.4242, Loss: 0.0436, pre: 7955.1, gt: 7992.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [482/800] Iter:[20/150], Time: 0.78, lr: 3.4217, Loss: 0.0255, pre: 1338.7, gt: 1594.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [482/800] Iter:[40/150], Time: 0.68, lr: 3.4192, Loss: 0.0250, pre: 909.3, gt: 1080.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [482/800] Iter:[60/150], Time: 0.65, lr: 3.4168, Loss: 0.0255, pre: 701.5, gt: 713.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [482/800] Iter:[80/150], Time: 0.63, lr: 3.4143, Loss: 0.0254, pre: 1090.9, gt: 1209.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [482/800] Iter:[100/150], Time: 0.62, lr: 3.4118, Loss: 0.0258, pre: 1379.3, gt: 1466.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [482/800] Iter:[120/150], Time: 0.62, lr: 3.4093, Loss: 0.0263, pre: 1262.7, gt: 1105.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [482/800] Iter:[140/150], Time: 0.61, lr: 3.4068, Loss: 0.0260, pre: 1279.4, gt: 1325.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [483/800] Iter:[0/150], Time: 2.50, lr: 3.4056, Loss: 0.0206, pre: 669.2, gt: 646.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [483/800] Iter:[20/150], Time: 0.67, lr: 3.4031, Loss: 0.0259, pre: 2653.5, gt: 2518.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [483/800] Iter:[40/150], Time: 0.63, lr: 3.4006, Loss: 0.0259, pre: 1317.9, gt: 1307.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [483/800] Iter:[60/150], Time: 0.62, lr: 3.3982, Loss: 0.0254, pre: 1128.9, gt: 1147.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [483/800] Iter:[80/150], Time: 0.61, lr: 3.3957, Loss: 0.0252, pre: 1132.0, gt: 1098.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [483/800] Iter:[100/150], Time: 0.60, lr: 3.3932, Loss: 0.0251, pre: 1273.7, gt: 1386.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [483/800] Iter:[120/150], Time: 0.60, lr: 3.3907, Loss: 0.0253, pre: 554.6, gt: 593.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [483/800] Iter:[140/150], Time: 0.60, lr: 3.3883, Loss: 0.0254, pre: 1320.4, gt: 1301.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  87.91, Best_MAE:  81.0930 MSE:  147.6192,Best_MSE:  134.1343\n","Epoch: [484/800] Iter:[0/150], Time: 3.99, lr: 3.3870, Loss: 0.0301, pre: 1931.8, gt: 2103.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [484/800] Iter:[20/150], Time: 0.75, lr: 3.3846, Loss: 0.0249, pre: 2797.5, gt: 2517.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [484/800] Iter:[40/150], Time: 0.67, lr: 3.3821, Loss: 0.0268, pre: 6812.4, gt: 7459.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [484/800] Iter:[60/150], Time: 0.64, lr: 3.3796, Loss: 0.0289, pre: 2736.6, gt: 2442.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [484/800] Iter:[80/150], Time: 0.63, lr: 3.3771, Loss: 0.0283, pre: 1223.3, gt: 1354.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [484/800] Iter:[100/150], Time: 0.62, lr: 3.3747, Loss: 0.0274, pre: 2522.9, gt: 2687.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [484/800] Iter:[120/150], Time: 0.61, lr: 3.3722, Loss: 0.0270, pre: 531.8, gt: 641.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [484/800] Iter:[140/150], Time: 0.61, lr: 3.3697, Loss: 0.0271, pre: 1507.5, gt: 1353.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [485/800] Iter:[0/150], Time: 2.05, lr: 3.3685, Loss: 0.0210, pre: 1816.0, gt: 1883.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [485/800] Iter:[20/150], Time: 0.65, lr: 3.3660, Loss: 0.0253, pre: 1541.4, gt: 1592.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [485/800] Iter:[40/150], Time: 0.62, lr: 3.3635, Loss: 0.0245, pre: 669.5, gt: 685.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [485/800] Iter:[60/150], Time: 0.61, lr: 3.3611, Loss: 0.0247, pre: 1416.4, gt: 1524.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [485/800] Iter:[80/150], Time: 0.60, lr: 3.3586, Loss: 0.0246, pre: 1306.5, gt: 1332.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [485/800] Iter:[100/150], Time: 0.60, lr: 3.3561, Loss: 0.0255, pre: 611.5, gt: 564.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [485/800] Iter:[120/150], Time: 0.60, lr: 3.3537, Loss: 0.0255, pre: 1064.0, gt: 1301.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [485/800] Iter:[140/150], Time: 0.59, lr: 3.3512, Loss: 0.0260, pre: 1299.2, gt: 1282.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  93.47, Best_MAE:  81.0930 MSE:  160.3132,Best_MSE:  134.1343\n","Epoch: [486/800] Iter:[0/150], Time: 4.61, lr: 3.3500, Loss: 0.0499, pre: 3720.3, gt: 3934.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [486/800] Iter:[20/150], Time: 0.78, lr: 3.3475, Loss: 0.0306, pre: 378.0, gt: 550.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [486/800] Iter:[40/150], Time: 0.68, lr: 3.3450, Loss: 0.0275, pre: 2626.1, gt: 2362.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [486/800] Iter:[60/150], Time: 0.65, lr: 3.3426, Loss: 0.0279, pre: 2590.5, gt: 2498.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [486/800] Iter:[80/150], Time: 0.63, lr: 3.3401, Loss: 0.0273, pre: 2560.4, gt: 2438.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [486/800] Iter:[100/150], Time: 0.62, lr: 3.3376, Loss: 0.0272, pre: 3154.7, gt: 3676.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [486/800] Iter:[120/150], Time: 0.62, lr: 3.3352, Loss: 0.0272, pre: 4679.5, gt: 4937.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [486/800] Iter:[140/150], Time: 0.61, lr: 3.3327, Loss: 0.0266, pre: 2635.6, gt: 2310.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [487/800] Iter:[0/150], Time: 2.06, lr: 3.3315, Loss: 0.0345, pre: 2367.8, gt: 2361.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [487/800] Iter:[20/150], Time: 0.65, lr: 3.3290, Loss: 0.0242, pre: 394.9, gt: 351.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [487/800] Iter:[40/150], Time: 0.62, lr: 3.3265, Loss: 0.0266, pre: 1074.9, gt: 1112.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [487/800] Iter:[60/150], Time: 0.61, lr: 3.3241, Loss: 0.0271, pre: 812.2, gt: 993.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [487/800] Iter:[80/150], Time: 0.60, lr: 3.3216, Loss: 0.0273, pre: 1319.4, gt: 1351.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [487/800] Iter:[100/150], Time: 0.60, lr: 3.3192, Loss: 0.0272, pre: 777.2, gt: 797.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [487/800] Iter:[120/150], Time: 0.60, lr: 3.3167, Loss: 0.0271, pre: 2211.3, gt: 2387.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [487/800] Iter:[140/150], Time: 0.59, lr: 3.3142, Loss: 0.0266, pre: 934.5, gt: 947.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  84.81, Best_MAE:  81.0930 MSE:  149.1115,Best_MSE:  134.1343\n","Epoch: [488/800] Iter:[0/150], Time: 4.46, lr: 3.3130, Loss: 0.0379, pre: 2604.1, gt: 2325.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [488/800] Iter:[20/150], Time: 0.77, lr: 3.3105, Loss: 0.0272, pre: 892.8, gt: 802.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [488/800] Iter:[40/150], Time: 0.68, lr: 3.3081, Loss: 0.0280, pre: 730.6, gt: 780.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [488/800] Iter:[60/150], Time: 0.65, lr: 3.3056, Loss: 0.0275, pre: 1463.9, gt: 1535.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [488/800] Iter:[80/150], Time: 0.63, lr: 3.3032, Loss: 0.0266, pre: 2555.5, gt: 2456.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [488/800] Iter:[100/150], Time: 0.62, lr: 3.3007, Loss: 0.0269, pre: 608.2, gt: 385.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [488/800] Iter:[120/150], Time: 0.61, lr: 3.2982, Loss: 0.0264, pre: 502.0, gt: 509.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [488/800] Iter:[140/150], Time: 0.61, lr: 3.2958, Loss: 0.0263, pre: 1831.0, gt: 2024.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [489/800] Iter:[0/150], Time: 2.46, lr: 3.2946, Loss: 0.0195, pre: 900.1, gt: 809.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [489/800] Iter:[20/150], Time: 0.67, lr: 3.2921, Loss: 0.0268, pre: 1651.6, gt: 1893.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [489/800] Iter:[40/150], Time: 0.63, lr: 3.2896, Loss: 0.0235, pre: 1026.4, gt: 990.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [489/800] Iter:[60/150], Time: 0.61, lr: 3.2872, Loss: 0.0238, pre: 1841.4, gt: 1711.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [489/800] Iter:[80/150], Time: 0.61, lr: 3.2847, Loss: 0.0252, pre: 351.2, gt: 416.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [489/800] Iter:[100/150], Time: 0.60, lr: 3.2823, Loss: 0.0257, pre: 1803.2, gt: 2204.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [489/800] Iter:[120/150], Time: 0.60, lr: 3.2798, Loss: 0.0261, pre: 1284.0, gt: 1207.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [489/800] Iter:[140/150], Time: 0.60, lr: 3.2774, Loss: 0.0257, pre: 1313.8, gt: 1173.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  85.64, Best_MAE:  81.0930 MSE:  147.0271,Best_MSE:  134.1343\n","Epoch: [490/800] Iter:[0/150], Time: 4.66, lr: 3.2761, Loss: 0.0196, pre: 816.1, gt: 895.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [490/800] Iter:[20/150], Time: 0.78, lr: 3.2737, Loss: 0.0235, pre: 821.4, gt: 770.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [490/800] Iter:[40/150], Time: 0.68, lr: 3.2712, Loss: 0.0253, pre: 3049.7, gt: 2822.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [490/800] Iter:[60/150], Time: 0.65, lr: 3.2688, Loss: 0.0254, pre: 210.5, gt: 178.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [490/800] Iter:[80/150], Time: 0.63, lr: 3.2663, Loss: 0.0262, pre: 998.3, gt: 1040.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [490/800] Iter:[100/150], Time: 0.62, lr: 3.2639, Loss: 0.0262, pre: 1724.9, gt: 1934.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [490/800] Iter:[120/150], Time: 0.62, lr: 3.2614, Loss: 0.0256, pre: 1378.1, gt: 1544.0,acc:0.92, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [490/800] Iter:[140/150], Time: 0.61, lr: 3.2590, Loss: 0.0256, pre: 708.7, gt: 639.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [491/800] Iter:[0/150], Time: 2.01, lr: 3.2578, Loss: 0.0207, pre: 2179.6, gt: 2535.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [491/800] Iter:[20/150], Time: 0.65, lr: 3.2553, Loss: 0.0239, pre: 736.9, gt: 729.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [491/800] Iter:[40/150], Time: 0.62, lr: 3.2529, Loss: 0.0239, pre: 472.0, gt: 497.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [491/800] Iter:[60/150], Time: 0.61, lr: 3.2504, Loss: 0.0237, pre: 1378.0, gt: 1399.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [491/800] Iter:[80/150], Time: 0.60, lr: 3.2480, Loss: 0.0250, pre: 5599.9, gt: 5826.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [491/800] Iter:[100/150], Time: 0.60, lr: 3.2455, Loss: 0.0252, pre: 2843.8, gt: 2919.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [491/800] Iter:[120/150], Time: 0.59, lr: 3.2431, Loss: 0.0255, pre: 4884.2, gt: 4928.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [491/800] Iter:[140/150], Time: 0.59, lr: 3.2406, Loss: 0.0254, pre: 1755.9, gt: 1722.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  93.46, Best_MAE:  81.0930 MSE:  155.7110,Best_MSE:  134.1343\n","Epoch: [492/800] Iter:[0/150], Time: 4.42, lr: 3.2394, Loss: 0.0108, pre: 795.1, gt: 839.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [492/800] Iter:[20/150], Time: 0.77, lr: 3.2369, Loss: 0.0271, pre: 2252.7, gt: 2168.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [492/800] Iter:[40/150], Time: 0.68, lr: 3.2345, Loss: 0.0289, pre: 1467.8, gt: 1387.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [492/800] Iter:[60/150], Time: 0.65, lr: 3.2321, Loss: 0.0281, pre: 722.2, gt: 799.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [492/800] Iter:[80/150], Time: 0.63, lr: 3.2296, Loss: 0.0267, pre: 6937.0, gt: 6645.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [492/800] Iter:[100/150], Time: 0.62, lr: 3.2272, Loss: 0.0269, pre: 1730.2, gt: 1617.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [492/800] Iter:[120/150], Time: 0.61, lr: 3.2247, Loss: 0.0267, pre: 149.9, gt: 158.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [492/800] Iter:[140/150], Time: 0.61, lr: 3.2223, Loss: 0.0269, pre: 671.7, gt: 744.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [493/800] Iter:[0/150], Time: 2.36, lr: 3.2211, Loss: 0.0351, pre: 4756.3, gt: 4406.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [493/800] Iter:[20/150], Time: 0.67, lr: 3.2186, Loss: 0.0234, pre: 840.0, gt: 972.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [493/800] Iter:[40/150], Time: 0.63, lr: 3.2162, Loss: 0.0259, pre: 2051.5, gt: 2110.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [493/800] Iter:[60/150], Time: 0.61, lr: 3.2137, Loss: 0.0261, pre: 1284.3, gt: 1144.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [493/800] Iter:[80/150], Time: 0.60, lr: 3.2113, Loss: 0.0266, pre: 2535.8, gt: 2225.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [493/800] Iter:[100/150], Time: 0.60, lr: 3.2088, Loss: 0.0256, pre: 685.8, gt: 922.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [493/800] Iter:[120/150], Time: 0.60, lr: 3.2064, Loss: 0.0257, pre: 2710.7, gt: 2489.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [493/800] Iter:[140/150], Time: 0.59, lr: 3.2040, Loss: 0.0256, pre: 430.6, gt: 425.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  92.88, Best_MAE:  81.0930 MSE:  167.9423,Best_MSE:  134.1343\n","Epoch: [494/800] Iter:[0/150], Time: 4.38, lr: 3.2027, Loss: 0.0184, pre: 1130.8, gt: 1165.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [494/800] Iter:[20/150], Time: 0.77, lr: 3.2003, Loss: 0.0254, pre: 1224.5, gt: 1214.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [494/800] Iter:[40/150], Time: 0.68, lr: 3.1979, Loss: 0.0267, pre: 5156.8, gt: 6298.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [494/800] Iter:[60/150], Time: 0.64, lr: 3.1954, Loss: 0.0261, pre: 2923.7, gt: 2722.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [494/800] Iter:[80/150], Time: 0.63, lr: 3.1930, Loss: 0.0264, pre: 501.6, gt: 500.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [494/800] Iter:[100/150], Time: 0.62, lr: 3.1906, Loss: 0.0264, pre: 646.4, gt: 702.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [494/800] Iter:[120/150], Time: 0.61, lr: 3.1881, Loss: 0.0264, pre: 1629.8, gt: 1762.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [494/800] Iter:[140/150], Time: 0.61, lr: 3.1857, Loss: 0.0263, pre: 2144.3, gt: 2598.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [495/800] Iter:[0/150], Time: 1.96, lr: 3.1845, Loss: 0.0185, pre: 699.5, gt: 754.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [495/800] Iter:[20/150], Time: 0.65, lr: 3.1820, Loss: 0.0219, pre: 259.1, gt: 277.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [495/800] Iter:[40/150], Time: 0.62, lr: 3.1796, Loss: 0.0267, pre: 606.9, gt: 629.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [495/800] Iter:[60/150], Time: 0.61, lr: 3.1772, Loss: 0.0263, pre: 2653.4, gt: 2792.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [495/800] Iter:[80/150], Time: 0.60, lr: 3.1747, Loss: 0.0270, pre: 1791.7, gt: 1883.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [495/800] Iter:[100/150], Time: 0.60, lr: 3.1723, Loss: 0.0267, pre: 1217.9, gt: 1356.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [495/800] Iter:[120/150], Time: 0.59, lr: 3.1699, Loss: 0.0266, pre: 1135.6, gt: 1217.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [495/800] Iter:[140/150], Time: 0.59, lr: 3.1674, Loss: 0.0261, pre: 301.0, gt: 345.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  104.43, Best_MAE:  81.0930 MSE:  192.4199,Best_MSE:  134.1343\n","Epoch: [496/800] Iter:[0/150], Time: 3.92, lr: 3.1662, Loss: 0.0344, pre: 2352.9, gt: 2615.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [496/800] Iter:[20/150], Time: 0.75, lr: 3.1638, Loss: 0.0268, pre: 1105.6, gt: 1050.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [496/800] Iter:[40/150], Time: 0.67, lr: 3.1614, Loss: 0.0272, pre: 2083.1, gt: 1966.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [496/800] Iter:[60/150], Time: 0.64, lr: 3.1589, Loss: 0.0264, pre: 412.5, gt: 528.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [496/800] Iter:[80/150], Time: 0.62, lr: 3.1565, Loss: 0.0261, pre: 1100.8, gt: 1005.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [496/800] Iter:[100/150], Time: 0.62, lr: 3.1541, Loss: 0.0260, pre: 1271.5, gt: 1280.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [496/800] Iter:[120/150], Time: 0.61, lr: 3.1516, Loss: 0.0259, pre: 3551.3, gt: 3608.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [496/800] Iter:[140/150], Time: 0.61, lr: 3.1492, Loss: 0.0262, pre: 5072.1, gt: 4964.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [497/800] Iter:[0/150], Time: 2.58, lr: 3.1480, Loss: 0.0082, pre: 142.6, gt: 133.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [497/800] Iter:[20/150], Time: 0.68, lr: 3.1456, Loss: 0.0267, pre: 1428.6, gt: 1254.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [497/800] Iter:[40/150], Time: 0.63, lr: 3.1431, Loss: 0.0253, pre: 554.5, gt: 630.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [497/800] Iter:[60/150], Time: 0.62, lr: 3.1407, Loss: 0.0247, pre: 1159.2, gt: 1193.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [497/800] Iter:[80/150], Time: 0.61, lr: 3.1383, Loss: 0.0242, pre: 1104.7, gt: 1208.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [497/800] Iter:[100/150], Time: 0.60, lr: 3.1359, Loss: 0.0249, pre: 1255.7, gt: 1186.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [497/800] Iter:[120/150], Time: 0.60, lr: 3.1334, Loss: 0.0248, pre: 1063.5, gt: 1022.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [497/800] Iter:[140/150], Time: 0.60, lr: 3.1310, Loss: 0.0253, pre: 809.6, gt: 915.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  88.62, Best_MAE:  81.0930 MSE:  153.9234,Best_MSE:  134.1343\n","Epoch: [498/800] Iter:[0/150], Time: 4.66, lr: 3.1298, Loss: 0.0234, pre: 993.6, gt: 1079.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [498/800] Iter:[20/150], Time: 0.78, lr: 3.1274, Loss: 0.0261, pre: 681.3, gt: 778.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [498/800] Iter:[40/150], Time: 0.68, lr: 3.1250, Loss: 0.0273, pre: 2764.8, gt: 2547.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [498/800] Iter:[60/150], Time: 0.65, lr: 3.1225, Loss: 0.0264, pre: 1662.9, gt: 1740.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [498/800] Iter:[80/150], Time: 0.63, lr: 3.1201, Loss: 0.0256, pre: 583.6, gt: 575.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [498/800] Iter:[100/150], Time: 0.62, lr: 3.1177, Loss: 0.0258, pre: 2429.9, gt: 2391.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [498/800] Iter:[120/150], Time: 0.62, lr: 3.1153, Loss: 0.0262, pre: 1037.6, gt: 1151.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [498/800] Iter:[140/150], Time: 0.61, lr: 3.1128, Loss: 0.0260, pre: 568.9, gt: 646.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [499/800] Iter:[0/150], Time: 2.07, lr: 3.1116, Loss: 0.0343, pre: 995.4, gt: 1343.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [499/800] Iter:[20/150], Time: 0.66, lr: 3.1092, Loss: 0.0224, pre: 1675.8, gt: 1668.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [499/800] Iter:[40/150], Time: 0.62, lr: 3.1068, Loss: 0.0235, pre: 1180.7, gt: 1090.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [499/800] Iter:[60/150], Time: 0.61, lr: 3.1044, Loss: 0.0232, pre: 588.6, gt: 585.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [499/800] Iter:[80/150], Time: 0.60, lr: 3.1020, Loss: 0.0245, pre: 2870.6, gt: 2854.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.95,acc1:0.00\n","Epoch: [499/800] Iter:[100/150], Time: 0.60, lr: 3.0995, Loss: 0.0246, pre: 2355.1, gt: 2529.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [499/800] Iter:[120/150], Time: 0.60, lr: 3.0971, Loss: 0.0251, pre: 542.6, gt: 534.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [499/800] Iter:[140/150], Time: 0.59, lr: 3.0947, Loss: 0.0253, pre: 2206.2, gt: 2162.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  82.85, Best_MAE:  81.0930 MSE:  143.0177,Best_MSE:  134.1343\n","Epoch: [500/800] Iter:[0/150], Time: 4.52, lr: 3.0935, Loss: 0.0249, pre: 1476.9, gt: 1675.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [500/800] Iter:[20/150], Time: 0.77, lr: 3.0911, Loss: 0.0255, pre: 2610.5, gt: 2386.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [500/800] Iter:[40/150], Time: 0.68, lr: 3.0887, Loss: 0.0238, pre: 646.3, gt: 613.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [500/800] Iter:[60/150], Time: 0.65, lr: 3.0862, Loss: 0.0249, pre: 2046.1, gt: 2206.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [500/800] Iter:[80/150], Time: 0.63, lr: 3.0838, Loss: 0.0249, pre: 861.0, gt: 879.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [500/800] Iter:[100/150], Time: 0.62, lr: 3.0814, Loss: 0.0250, pre: 2134.4, gt: 2082.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [500/800] Iter:[120/150], Time: 0.61, lr: 3.0790, Loss: 0.0248, pre: 1297.9, gt: 1372.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [500/800] Iter:[140/150], Time: 0.61, lr: 3.0766, Loss: 0.0253, pre: 6250.6, gt: 6749.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [501/800] Iter:[0/150], Time: 2.31, lr: 3.0754, Loss: 0.0178, pre: 1566.5, gt: 1632.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [501/800] Iter:[20/150], Time: 0.67, lr: 3.0730, Loss: 0.0319, pre: 631.5, gt: 662.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [501/800] Iter:[40/150], Time: 0.63, lr: 3.0706, Loss: 0.0290, pre: 362.7, gt: 307.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [501/800] Iter:[60/150], Time: 0.61, lr: 3.0682, Loss: 0.0279, pre: 1171.8, gt: 1149.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [501/800] Iter:[80/150], Time: 0.60, lr: 3.0657, Loss: 0.0270, pre: 2594.5, gt: 2204.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [501/800] Iter:[100/150], Time: 0.60, lr: 3.0633, Loss: 0.0265, pre: 1375.0, gt: 1415.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [501/800] Iter:[120/150], Time: 0.60, lr: 3.0609, Loss: 0.0272, pre: 3721.3, gt: 3461.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [501/800] Iter:[140/150], Time: 0.59, lr: 3.0585, Loss: 0.0266, pre: 3138.2, gt: 3677.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  104.88, Best_MAE:  81.0930 MSE:  180.2684,Best_MSE:  134.1343\n","Epoch: [502/800] Iter:[0/150], Time: 4.50, lr: 3.0573, Loss: 0.0369, pre: 4326.3, gt: 3978.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [502/800] Iter:[20/150], Time: 0.77, lr: 3.0549, Loss: 0.0260, pre: 808.5, gt: 790.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [502/800] Iter:[40/150], Time: 0.68, lr: 3.0525, Loss: 0.0245, pre: 1414.9, gt: 1642.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [502/800] Iter:[60/150], Time: 0.65, lr: 3.0501, Loss: 0.0252, pre: 1160.4, gt: 1195.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [502/800] Iter:[80/150], Time: 0.63, lr: 3.0477, Loss: 0.0246, pre: 663.8, gt: 554.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [502/800] Iter:[100/150], Time: 0.62, lr: 3.0453, Loss: 0.0251, pre: 1505.4, gt: 1455.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [502/800] Iter:[120/150], Time: 0.62, lr: 3.0429, Loss: 0.0245, pre: 1055.3, gt: 1093.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [502/800] Iter:[140/150], Time: 0.61, lr: 3.0405, Loss: 0.0249, pre: 2641.3, gt: 2060.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [503/800] Iter:[0/150], Time: 2.05, lr: 3.0393, Loss: 0.0326, pre: 1589.9, gt: 1777.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [503/800] Iter:[20/150], Time: 0.65, lr: 3.0369, Loss: 0.0265, pre: 1111.7, gt: 992.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [503/800] Iter:[40/150], Time: 0.62, lr: 3.0345, Loss: 0.0261, pre: 6324.1, gt: 5686.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [503/800] Iter:[60/150], Time: 0.61, lr: 3.0321, Loss: 0.0252, pre: 1453.4, gt: 1637.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [503/800] Iter:[80/150], Time: 0.60, lr: 3.0297, Loss: 0.0252, pre: 996.2, gt: 974.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [503/800] Iter:[100/150], Time: 0.60, lr: 3.0272, Loss: 0.0248, pre: 576.6, gt: 617.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [503/800] Iter:[120/150], Time: 0.60, lr: 3.0248, Loss: 0.0250, pre: 2626.5, gt: 2704.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [503/800] Iter:[140/150], Time: 0.59, lr: 3.0224, Loss: 0.0248, pre: 401.4, gt: 401.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  99.89, Best_MAE:  81.0930 MSE:  187.7299,Best_MSE:  134.1343\n","Epoch: [504/800] Iter:[0/150], Time: 4.11, lr: 3.0212, Loss: 0.0276, pre: 1848.1, gt: 1965.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [504/800] Iter:[20/150], Time: 0.76, lr: 3.0188, Loss: 0.0267, pre: 1138.8, gt: 1312.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [504/800] Iter:[40/150], Time: 0.67, lr: 3.0164, Loss: 0.0261, pre: 1530.5, gt: 1450.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [504/800] Iter:[60/150], Time: 0.64, lr: 3.0140, Loss: 0.0257, pre: 440.5, gt: 458.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [504/800] Iter:[80/150], Time: 0.63, lr: 3.0116, Loss: 0.0258, pre: 1460.0, gt: 1376.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [504/800] Iter:[100/150], Time: 0.62, lr: 3.0093, Loss: 0.0258, pre: 681.3, gt: 797.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [504/800] Iter:[120/150], Time: 0.61, lr: 3.0069, Loss: 0.0251, pre: 2246.8, gt: 2358.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [504/800] Iter:[140/150], Time: 0.61, lr: 3.0045, Loss: 0.0251, pre: 6962.8, gt: 6764.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [505/800] Iter:[0/150], Time: 2.16, lr: 3.0033, Loss: 0.0416, pre: 4108.4, gt: 4245.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [505/800] Iter:[20/150], Time: 0.66, lr: 3.0009, Loss: 0.0254, pre: 1251.1, gt: 1294.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [505/800] Iter:[40/150], Time: 0.62, lr: 2.9985, Loss: 0.0247, pre: 903.0, gt: 858.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [505/800] Iter:[60/150], Time: 0.61, lr: 2.9961, Loss: 0.0252, pre: 1487.1, gt: 1498.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [505/800] Iter:[80/150], Time: 0.60, lr: 2.9937, Loss: 0.0249, pre: 542.9, gt: 545.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [505/800] Iter:[100/150], Time: 0.60, lr: 2.9913, Loss: 0.0246, pre: 856.3, gt: 838.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [505/800] Iter:[120/150], Time: 0.60, lr: 2.9889, Loss: 0.0248, pre: 4662.9, gt: 4564.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [505/800] Iter:[140/150], Time: 0.59, lr: 2.9865, Loss: 0.0255, pre: 1495.2, gt: 1717.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  97.46, Best_MAE:  81.0930 MSE:  170.3826,Best_MSE:  134.1343\n","Epoch: [506/800] Iter:[0/150], Time: 5.01, lr: 2.9853, Loss: 0.0288, pre: 789.1, gt: 811.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [506/800] Iter:[20/150], Time: 0.80, lr: 2.9829, Loss: 0.0246, pre: 2237.9, gt: 2355.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [506/800] Iter:[40/150], Time: 0.69, lr: 2.9805, Loss: 0.0239, pre: 2007.9, gt: 2256.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [506/800] Iter:[60/150], Time: 0.66, lr: 2.9781, Loss: 0.0252, pre: 4847.8, gt: 4792.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [506/800] Iter:[80/150], Time: 0.64, lr: 2.9757, Loss: 0.0249, pre: 826.5, gt: 814.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [506/800] Iter:[100/150], Time: 0.63, lr: 2.9734, Loss: 0.0253, pre: 2663.7, gt: 2755.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [506/800] Iter:[120/150], Time: 0.62, lr: 2.9710, Loss: 0.0256, pre: 977.9, gt: 906.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [506/800] Iter:[140/150], Time: 0.61, lr: 2.9686, Loss: 0.0258, pre: 434.8, gt: 436.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [507/800] Iter:[0/150], Time: 1.98, lr: 2.9674, Loss: 0.0271, pre: 870.9, gt: 1088.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [507/800] Iter:[20/150], Time: 0.65, lr: 2.9650, Loss: 0.0258, pre: 2103.7, gt: 2092.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [507/800] Iter:[40/150], Time: 0.62, lr: 2.9626, Loss: 0.0248, pre: 1239.1, gt: 1514.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [507/800] Iter:[60/150], Time: 0.61, lr: 2.9602, Loss: 0.0244, pre: 727.0, gt: 697.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [507/800] Iter:[80/150], Time: 0.60, lr: 2.9578, Loss: 0.0250, pre: 1134.5, gt: 1177.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [507/800] Iter:[100/150], Time: 0.60, lr: 2.9554, Loss: 0.0255, pre: 1950.6, gt: 2147.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [507/800] Iter:[120/150], Time: 0.60, lr: 2.9531, Loss: 0.0260, pre: 524.8, gt: 570.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [507/800] Iter:[140/150], Time: 0.59, lr: 2.9507, Loss: 0.0259, pre: 1817.7, gt: 1872.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  106.34, Best_MAE:  81.0930 MSE:  189.9001,Best_MSE:  134.1343\n","Epoch: [508/800] Iter:[0/150], Time: 4.21, lr: 2.9495, Loss: 0.0431, pre: 3574.4, gt: 3465.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [508/800] Iter:[20/150], Time: 0.76, lr: 2.9471, Loss: 0.0253, pre: 1399.0, gt: 1394.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [508/800] Iter:[40/150], Time: 0.67, lr: 2.9447, Loss: 0.0257, pre: 1361.0, gt: 1404.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [508/800] Iter:[60/150], Time: 0.64, lr: 2.9423, Loss: 0.0258, pre: 2227.8, gt: 2247.0,acc:0.93, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [508/800] Iter:[80/150], Time: 0.63, lr: 2.9400, Loss: 0.0258, pre: 333.5, gt: 387.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [508/800] Iter:[100/150], Time: 0.62, lr: 2.9376, Loss: 0.0257, pre: 7934.2, gt: 8660.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [508/800] Iter:[120/150], Time: 0.61, lr: 2.9352, Loss: 0.0259, pre: 797.5, gt: 861.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [508/800] Iter:[140/150], Time: 0.61, lr: 2.9328, Loss: 0.0253, pre: 350.2, gt: 307.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [509/800] Iter:[0/150], Time: 1.90, lr: 2.9316, Loss: 0.0209, pre: 1275.3, gt: 1349.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [509/800] Iter:[20/150], Time: 0.65, lr: 2.9292, Loss: 0.0275, pre: 946.1, gt: 871.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [509/800] Iter:[40/150], Time: 0.62, lr: 2.9269, Loss: 0.0275, pre: 2616.9, gt: 2668.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [509/800] Iter:[60/150], Time: 0.61, lr: 2.9245, Loss: 0.0262, pre: 1075.0, gt: 1072.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [509/800] Iter:[80/150], Time: 0.60, lr: 2.9221, Loss: 0.0259, pre: 1135.6, gt: 1020.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [509/800] Iter:[100/150], Time: 0.60, lr: 2.9197, Loss: 0.0257, pre: 507.4, gt: 506.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [509/800] Iter:[120/150], Time: 0.59, lr: 2.9174, Loss: 0.0251, pre: 1623.7, gt: 1622.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [509/800] Iter:[140/150], Time: 0.59, lr: 2.9150, Loss: 0.0248, pre: 1818.2, gt: 1979.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.010, MAE:  86.95, Best_MAE:  81.0930 MSE:  153.2864,Best_MSE:  134.1343\n","Epoch: [510/800] Iter:[0/150], Time: 4.65, lr: 2.9138, Loss: 0.0135, pre: 586.1, gt: 563.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [510/800] Iter:[20/150], Time: 0.78, lr: 2.9114, Loss: 0.0253, pre: 3086.5, gt: 3480.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [510/800] Iter:[40/150], Time: 0.68, lr: 2.9090, Loss: 0.0252, pre: 626.6, gt: 579.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [510/800] Iter:[60/150], Time: 0.65, lr: 2.9067, Loss: 0.0250, pre: 586.3, gt: 640.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [510/800] Iter:[80/150], Time: 0.63, lr: 2.9043, Loss: 0.0250, pre: 1541.1, gt: 1402.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [510/800] Iter:[100/150], Time: 0.62, lr: 2.9019, Loss: 0.0258, pre: 2112.5, gt: 2154.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [510/800] Iter:[120/150], Time: 0.62, lr: 2.8996, Loss: 0.0257, pre: 2777.1, gt: 3034.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [510/800] Iter:[140/150], Time: 0.61, lr: 2.8972, Loss: 0.0260, pre: 1480.4, gt: 1314.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [511/800] Iter:[0/150], Time: 2.36, lr: 2.8960, Loss: 0.0296, pre: 2386.7, gt: 2732.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [511/800] Iter:[20/150], Time: 0.67, lr: 2.8936, Loss: 0.0253, pre: 1343.1, gt: 1319.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [511/800] Iter:[40/150], Time: 0.63, lr: 2.8913, Loss: 0.0246, pre: 832.9, gt: 838.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [511/800] Iter:[60/150], Time: 0.61, lr: 2.8889, Loss: 0.0245, pre: 3709.3, gt: 3602.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [511/800] Iter:[80/150], Time: 0.61, lr: 2.8865, Loss: 0.0245, pre: 1612.8, gt: 1973.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [511/800] Iter:[100/150], Time: 0.60, lr: 2.8842, Loss: 0.0243, pre: 7501.8, gt: 7058.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [511/800] Iter:[120/150], Time: 0.60, lr: 2.8818, Loss: 0.0244, pre: 1802.4, gt: 2294.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [511/800] Iter:[140/150], Time: 0.60, lr: 2.8794, Loss: 0.0250, pre: 1088.0, gt: 1104.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","/content/drive/MyDrive/STEERER/STEERER/./lib/datasets/utils/collate.py:65: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = elem.storage()._new_shared(numel, device=elem.device)\n","=> saving checkpoint to exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22checkpoint.pth.tar\n","Loss: 0.011, MAE:  93.98, Best_MAE:  81.0930 MSE:  159.8216,Best_MSE:  134.1343\n","Epoch: [512/800] Iter:[0/150], Time: 4.80, lr: 2.8782, Loss: 0.0257, pre: 1132.8, gt: 1014.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [512/800] Iter:[20/150], Time: 0.79, lr: 2.8759, Loss: 0.0256, pre: 1996.2, gt: 2356.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [512/800] Iter:[40/150], Time: 0.69, lr: 2.8735, Loss: 0.0249, pre: 3035.0, gt: 2769.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [512/800] Iter:[60/150], Time: 0.65, lr: 2.8711, Loss: 0.0255, pre: 904.8, gt: 984.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [512/800] Iter:[80/150], Time: 0.63, lr: 2.8688, Loss: 0.0259, pre: 802.7, gt: 866.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [512/800] Iter:[100/150], Time: 0.62, lr: 2.8664, Loss: 0.0256, pre: 607.7, gt: 657.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [512/800] Iter:[120/150], Time: 0.62, lr: 2.8640, Loss: 0.0256, pre: 4989.2, gt: 4762.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [512/800] Iter:[140/150], Time: 0.61, lr: 2.8617, Loss: 0.0253, pre: 1453.3, gt: 1394.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [513/800] Iter:[0/150], Time: 2.01, lr: 2.8605, Loss: 0.0394, pre: 2882.0, gt: 3148.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [513/800] Iter:[20/150], Time: 0.65, lr: 2.8581, Loss: 0.0242, pre: 455.9, gt: 527.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [513/800] Iter:[40/150], Time: 0.62, lr: 2.8558, Loss: 0.0244, pre: 2830.6, gt: 3016.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [513/800] Iter:[60/150], Time: 0.61, lr: 2.8534, Loss: 0.0242, pre: 1648.5, gt: 1755.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [513/800] Iter:[80/150], Time: 0.60, lr: 2.8511, Loss: 0.0246, pre: 1289.1, gt: 1181.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [513/800] Iter:[100/150], Time: 0.60, lr: 2.8487, Loss: 0.0248, pre: 3081.1, gt: 3567.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [513/800] Iter:[120/150], Time: 0.59, lr: 2.8463, Loss: 0.0248, pre: 1600.8, gt: 1596.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Epoch: [513/800] Iter:[140/150], Time: 0.59, lr: 2.8440, Loss: 0.0246, pre: 2673.5, gt: 2592.0,acc:0.94, accx8:0.95,  accx16:0.96,accx32:0.96,acc1:0.00\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/STEERER/STEERER/tools/train_cc.py\", line 353, in <module>\n","    main()\n","  File \"/content/drive/MyDrive/STEERER/STEERER/tools/train_cc.py\", line 283, in main\n","    train(config, epoch, config.train.end_epoch,\n","  File \"/content/drive/MyDrive/STEERER/STEERER/./lib/core/cc_function.py\", line 88, in train\n","    loss.backward()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 581, in backward\n","    torch.autograd.backward(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n","    _engine_run_backward(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n","    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"code","source":["! python tools/test_loc.py --cfg=configs/QNRF_final.py --checkpoint=\"/content/drive/MyDrive/STEERER/STEERER/exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22/Ep_471_mae_81.09296779289932_mse_134.13431722945182.pth\" --launcher=\"pytorch\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6N8044937ejY","executionInfo":{"status":"ok","timestamp":1733836823168,"user_tz":-540,"elapsed":541424,"user":{"displayName":"박수연 (GREAT)","userId":"09302565313834136190"}},"outputId":"d2686816-624c-43f0-fcc8-68cab2104337"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n","  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n","=> creating exp/QNRF/test/QNRF_final\n","Namespace(cfg='configs/QNRF_final.py', checkpoint='/content/drive/MyDrive/STEERER/STEERER/exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22/Ep_471_mae_81.09296779289932_mse_134.13431722945182.pth', opts=[], launcher='pytorch', local_rank=0, cfg_options=None)\n","Config (path: configs/QNRF_final.py): {'gpus': (0, 1), 'log_dir': 'exp', 'workers': 6, 'print_freq': 20, 'seed': 3035, 'network': {'backbone': 'MocHRBackbone', 'sub_arch': 'hrnet48', 'counter_type': 'withMOE', 'resolution_num': [0, 1, 2, 3], 'loss_weight': [1.0, 0.5, 0.25, 0.125], 'sigma': [4], 'gau_kernel_size': 15, 'baseline_loss': False, 'pretrained_backbone': '../PretrainedModels/hrnetv2_w48_imagenet_pretrained.pth', 'head': {'type': 'CountingHead', 'fuse_method': 'cat', 'in_channels': 96, 'stages_channel': [384, 192, 96, 48], 'inter_layer': [64, 32, 16], 'out_channels': 1}}, 'dataset': {'name': 'QNRF', 'root': '../ProcessedData/', 'test_set': 'test.txt', 'train_set': 'train.txt', 'loc_gt': 'test_gt_loc.txt', 'num_classes': 4, 'den_factor': 100, 'extra_train_set': None}, 'optimizer': {'NAME': 'adamw', 'BASE_LR': 0.0001, 'BETAS': (0.9, 0.999), 'WEIGHT_DECAY': 0.0001, 'EPS': 1e-08, 'MOMENTUM': 0.9, 'AMSGRAD': False, 'NESTEROV': True}, 'lr_config': {'NAME': 'cosine', 'WARMUP_METHOD': 'linear', 'DECAY_EPOCHS': 250, 'DECAY_RATE': 0.1, 'WARMUP_EPOCHS': 10, 'WARMUP_LR': 5e-07, 'MIN_LR': 1e-07}, 'total_epochs': 210, 'log_config': {'interval': 50, 'hooks': [{'type': 'TextLoggerHook'}]}, 'train': {'counter': 'normal', 'image_size': (768, 768), 'route_size': (256, 256), 'base_size': None, 'batch_size_per_gpu': 8, 'shuffle': True, 'begin_epoch': 0, 'end_epoch': 800, 'extra_epoch': 0, 'extra_lr': 0, 'resume_path': None, 'flip': True, 'multi_scale': True, 'scale_factor': (0.5, 2.0), 'val_span': [-800, -600, -400, -200, -200, -100, -100], 'downsamplerate': 1, 'ignore_label': 255}, 'test': {'image_size': (1024, 2048), 'base_size': 3072, 'loc_base_size': 3072, 'loc_threshold': 0.15, 'batch_size_per_gpu': 1, 'patch_batch_size': 16, 'flip_test': False, 'multi_scale': False, 'model_file': './exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2023-10-28-13-44/QNRF_mae_78.4_mse_135.6.pth'}, 'CUDNN': {'BENCHMARK': True, 'DETERMINISTIC': False, 'ENABLED': True}}\n","GPU idx:0\n","=> init weights from normal distribution\n","=> loading model from /content/drive/MyDrive/STEERER/STEERER/exp/QNRF/MocHRBackbone_hrnet48/QNRF_final_2024-12-09-19-22/Ep_471_mae_81.09296779289932_mse_134.13431722945182.pth\n","/content/drive/MyDrive/STEERER/STEERER/tools/test_loc.py:120: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  pretrained_dict = torch.load(model_state_file)\n","  0% 0/334 [00:00<?, ?it/s]['1202']: gt:977.0 pre:1297.8905029296875\n","processing: 0 images\n","mae:  320.8905, mse:  320.8905,                        nae:  0.3284, Class IoU: \n","  0% 1/334 [00:07<42:28,  7.65s/it]['1203']: gt:923.0 pre:727.13037109375\n","  1% 2/334 [00:13<36:04,  6.52s/it]['1204']: gt:350.0 pre:376.56195068359375\n","  1% 3/334 [00:14<22:17,  4.04s/it]['1205']: gt:183.0 pre:157.43373107910156\n","  1% 4/334 [00:19<25:22,  4.61s/it]['1206']: gt:103.0 pre:117.5784912109375\n","  1% 5/334 [00:20<17:46,  3.24s/it]['1207']: gt:436.0 pre:479.634765625\n","  2% 6/334 [00:23<16:14,  2.97s/it]['1208']: gt:77.0 pre:84.0792465209961\n","  2% 7/334 [00:27<18:22,  3.37s/it]['1209']: gt:92.0 pre:104.89848327636719\n","  2% 8/334 [00:32<20:58,  3.86s/it]['1210']: gt:237.0 pre:251.32192993164062\n","  3% 9/334 [00:37<22:22,  4.13s/it]['1211']: gt:566.0 pre:538.5787353515625\n","  3% 10/334 [00:38<17:08,  3.17s/it]['1212']: gt:540.0 pre:543.051513671875\n","  3% 11/334 [00:39<14:47,  2.75s/it]['1213']: gt:434.0 pre:467.7980651855469\n","  4% 12/334 [00:40<10:34,  1.97s/it]['1214']: gt:1528.0 pre:1638.504638671875\n","  4% 13/334 [00:45<15:43,  2.94s/it]['1215']: gt:225.0 pre:248.21055603027344\n","  4% 14/334 [00:45<12:03,  2.26s/it]['1216']: gt:413.0 pre:421.79266357421875\n","  4% 15/334 [00:46<09:41,  1.82s/it]['1217']: gt:853.0 pre:774.6444702148438\n","  5% 16/334 [00:47<08:08,  1.54s/it]['1218']: gt:191.0 pre:190.48703002929688\n","  5% 17/334 [00:48<07:22,  1.40s/it]['1219']: gt:141.0 pre:131.4896240234375\n","  5% 18/334 [00:49<06:20,  1.20s/it]['1220']: gt:137.0 pre:177.1096649169922\n","  6% 19/334 [00:50<05:30,  1.05s/it]['1221']: gt:133.0 pre:131.8501739501953\n","  6% 20/334 [00:50<04:55,  1.06it/s]['1222']: gt:127.0 pre:125.55469512939453\n","  6% 21/334 [00:51<04:31,  1.15it/s]['1223']: gt:479.0 pre:701.7222900390625\n","  7% 22/334 [00:53<06:01,  1.16s/it]['1224']: gt:274.0 pre:324.07305908203125\n","  7% 23/334 [00:54<05:17,  1.02s/it]['1225']: gt:385.0 pre:411.7205505371094\n","  7% 24/334 [00:58<11:12,  2.17s/it]['1226']: gt:319.0 pre:328.111328125\n","  7% 25/334 [01:04<15:57,  3.10s/it]['1227']: gt:113.0 pre:155.78033447265625\n","  8% 26/334 [01:05<12:50,  2.50s/it]['1228']: gt:181.0 pre:230.5392608642578\n","  8% 27/334 [01:05<10:02,  1.96s/it]['1229']: gt:405.0 pre:362.9157409667969\n","  8% 28/334 [01:07<09:52,  1.94s/it]['1230']: gt:450.0 pre:469.9627685546875\n","  9% 29/334 [01:08<08:02,  1.58s/it]['1231']: gt:367.0 pre:370.0511474609375\n","  9% 30/334 [01:08<05:59,  1.18s/it]['1232']: gt:394.0 pre:427.5028076171875\n","  9% 31/334 [01:08<04:25,  1.14it/s]['1233']: gt:674.0 pre:711.8922119140625\n"," 10% 32/334 [01:09<04:15,  1.18it/s]['1234']: gt:129.0 pre:111.46700286865234\n"," 10% 33/334 [01:10<03:58,  1.26it/s]['1235']: gt:221.0 pre:220.58316040039062\n"," 10% 34/334 [01:11<03:48,  1.32it/s]['1236']: gt:1018.0 pre:1062.5238037109375\n"," 10% 35/334 [01:12<04:04,  1.22it/s]['1237']: gt:302.0 pre:284.9311218261719\n"," 11% 36/334 [01:12<03:57,  1.26it/s]['1238']: gt:2530.0 pre:2540.249267578125\n"," 11% 37/334 [01:15<06:55,  1.40s/it]['1239']: gt:297.0 pre:313.1966552734375\n"," 11% 38/334 [01:19<10:05,  2.04s/it]['1240']: gt:88.0 pre:85.01301574707031\n"," 12% 39/334 [01:20<09:03,  1.84s/it]['1241']: gt:201.0 pre:201.76528930664062\n"," 12% 40/334 [01:20<06:32,  1.34s/it]['1242']: gt:960.0 pre:1003.2745361328125\n"," 12% 41/334 [01:23<08:43,  1.79s/it]['1243']: gt:130.0 pre:178.78338623046875\n"," 13% 42/334 [01:24<07:07,  1.47s/it]['1244']: gt:155.0 pre:134.2823486328125\n"," 13% 43/334 [01:24<05:59,  1.23s/it]['1245']: gt:169.0 pre:183.9525604248047\n"," 13% 44/334 [01:25<04:25,  1.09it/s]['1246']: gt:153.0 pre:207.5492706298828\n"," 13% 45/334 [01:25<04:04,  1.18it/s]['1247']: gt:177.0 pre:168.72433471679688\n"," 14% 46/334 [01:29<07:51,  1.64s/it]['1248']: gt:100.0 pre:150.73838806152344\n"," 14% 47/334 [01:31<07:56,  1.66s/it]['1249']: gt:1211.0 pre:1292.4864501953125\n"," 14% 48/334 [01:32<07:11,  1.51s/it]['1250']: gt:2494.0 pre:2202.392578125\n"," 15% 49/334 [01:37<11:57,  2.52s/it]['1251']: gt:425.0 pre:427.5408020019531\n"," 15% 50/334 [01:37<09:27,  2.00s/it]['1252']: gt:187.0 pre:202.2940673828125\n"," 15% 51/334 [01:38<07:00,  1.49s/it]['1253']: gt:139.0 pre:120.83338928222656\n"," 16% 52/334 [01:38<05:53,  1.25s/it]['1254']: gt:954.0 pre:870.9814453125\n"," 16% 53/334 [01:42<09:25,  2.01s/it]['1255']: gt:597.0 pre:526.0833740234375\n"," 16% 54/334 [01:42<06:52,  1.47s/it]['1256']: gt:361.0 pre:445.70465087890625\n"," 16% 55/334 [01:43<05:49,  1.25s/it]['1257']: gt:194.0 pre:221.2144775390625\n"," 17% 56/334 [01:44<05:01,  1.09s/it]['1258']: gt:687.0 pre:613.40576171875\n"," 17% 57/334 [01:45<04:35,  1.01it/s]['1259']: gt:4535.0 pre:4347.6923828125\n"," 17% 58/334 [01:51<12:22,  2.69s/it]['1260']: gt:452.0 pre:370.0234375\n"," 18% 59/334 [01:52<09:40,  2.11s/it]['1261']: gt:227.0 pre:251.7679443359375\n"," 18% 60/334 [01:52<07:07,  1.56s/it]['1262']: gt:236.0 pre:167.28863525390625\n"," 18% 61/334 [01:53<06:00,  1.32s/it]['1263']: gt:2638.0 pre:3192.706298828125\n"," 19% 62/334 [01:56<07:38,  1.69s/it]['1264']: gt:1149.0 pre:688.8645629882812\n"," 19% 63/334 [01:56<06:35,  1.46s/it]['1265']: gt:1357.0 pre:1407.13818359375\n"," 19% 64/334 [02:02<11:57,  2.66s/it]['1266']: gt:490.0 pre:625.9666748046875\n"," 19% 65/334 [02:03<09:30,  2.12s/it]['1267']: gt:2980.0 pre:2961.8955078125\n"," 20% 66/334 [02:04<08:35,  1.92s/it]['1268']: gt:255.0 pre:270.49859619140625\n"," 20% 67/334 [02:05<06:57,  1.56s/it]['1269']: gt:363.0 pre:391.143310546875\n"," 20% 68/334 [02:06<06:27,  1.46s/it]['1270']: gt:547.0 pre:460.04058837890625\n"," 21% 69/334 [02:07<05:42,  1.29s/it]['1271']: gt:233.0 pre:231.14337158203125\n"," 21% 70/334 [02:10<07:20,  1.67s/it]['1272']: gt:1236.0 pre:1572.3050537109375\n"," 21% 71/334 [02:11<06:44,  1.54s/it]['1273']: gt:241.0 pre:304.1107482910156\n"," 22% 72/334 [02:15<09:35,  2.20s/it]['1274']: gt:481.0 pre:530.727294921875\n"," 22% 73/334 [02:19<12:45,  2.93s/it]['1275']: gt:704.0 pre:707.9273681640625\n"," 22% 74/334 [02:20<10:04,  2.32s/it]['1276']: gt:253.0 pre:206.77474975585938\n"," 22% 75/334 [02:21<08:05,  1.87s/it]['1277']: gt:489.0 pre:389.9147033691406\n"," 23% 76/334 [02:26<11:45,  2.74s/it]['1278']: gt:203.0 pre:187.44097900390625\n"," 23% 77/334 [02:30<13:29,  3.15s/it]['1279']: gt:1116.0 pre:1116.3521728515625\n"," 23% 78/334 [02:31<10:29,  2.46s/it]['1280']: gt:1974.0 pre:1878.920654296875\n"," 24% 79/334 [02:32<08:57,  2.11s/it]['1281']: gt:347.0 pre:411.2391357421875\n"," 24% 80/334 [02:33<07:44,  1.83s/it]['1282']: gt:121.0 pre:117.66317749023438\n"," 24% 81/334 [02:35<08:17,  1.96s/it]['1283']: gt:337.0 pre:233.00128173828125\n"," 25% 82/334 [02:36<06:12,  1.48s/it]['1284']: gt:693.0 pre:561.71484375\n"," 25% 83/334 [02:37<05:21,  1.28s/it]['1285']: gt:322.0 pre:316.2359313964844\n"," 25% 84/334 [02:37<03:57,  1.05it/s]['1286']: gt:283.0 pre:261.3218994140625\n"," 25% 85/334 [02:37<03:29,  1.19it/s]['1287']: gt:176.0 pre:200.7335205078125\n"," 26% 86/334 [02:38<03:19,  1.25it/s]['1288']: gt:626.0 pre:533.6428833007812\n"," 26% 87/334 [02:39<03:16,  1.26it/s]['1289']: gt:197.0 pre:169.41427612304688\n"," 26% 88/334 [02:40<03:11,  1.29it/s]['1290']: gt:1557.0 pre:1490.785400390625\n"," 27% 89/334 [02:41<03:48,  1.07it/s]['1291']: gt:792.0 pre:828.8816528320312\n"," 27% 90/334 [02:46<09:10,  2.26s/it]['1292']: gt:636.0 pre:563.9398803710938\n"," 27% 91/334 [02:50<10:26,  2.58s/it]['1293']: gt:645.0 pre:510.13275146484375\n"," 28% 92/334 [02:52<09:41,  2.40s/it]['1294']: gt:1929.0 pre:1403.3568115234375\n"," 28% 93/334 [02:54<09:51,  2.45s/it]['1295']: gt:146.0 pre:133.07748413085938\n"," 28% 94/334 [02:55<07:44,  1.94s/it]['1296']: gt:370.0 pre:393.4717712402344\n"," 28% 95/334 [02:56<06:25,  1.61s/it]['1297']: gt:107.0 pre:109.9569091796875\n"," 29% 96/334 [02:56<04:52,  1.23s/it]['1298']: gt:431.0 pre:31.72970199584961\n"," 29% 97/334 [02:57<04:23,  1.11s/it]['1299']: gt:249.0 pre:169.2218475341797\n"," 29% 98/334 [02:58<03:55,  1.00it/s]['1300']: gt:304.0 pre:203.29400634765625\n"," 30% 99/334 [02:58<02:54,  1.35it/s]['1301']: gt:232.0 pre:214.05935668945312\n"," 30% 100/334 [03:01<05:59,  1.54s/it]['1302']: gt:175.0 pre:196.66915893554688\n","processing: 100 images\n","mae:  69.5969, mse:  126.7835,                        nae:  0.1352, Class IoU: \n"," 30% 101/334 [03:04<07:18,  1.88s/it]['1303']: gt:264.0 pre:261.9244384765625\n"," 31% 102/334 [03:04<05:15,  1.36s/it]['1304']: gt:505.0 pre:610.026123046875\n"," 31% 103/334 [03:05<05:10,  1.34s/it]['1305']: gt:1387.0 pre:1570.9962158203125\n"," 31% 104/334 [03:11<09:57,  2.60s/it]['1306']: gt:166.0 pre:173.72317504882812\n"," 31% 105/334 [03:11<07:34,  1.99s/it]['1307']: gt:1443.0 pre:1244.074462890625\n"," 32% 106/334 [03:13<06:47,  1.79s/it]['1308']: gt:335.0 pre:329.69427490234375\n"," 32% 107/334 [03:13<05:36,  1.48s/it]['1309']: gt:188.0 pre:153.21920776367188\n"," 32% 108/334 [03:14<04:50,  1.28s/it]['1310']: gt:441.0 pre:289.3311767578125\n"," 33% 109/334 [03:15<04:10,  1.11s/it]['1311']: gt:460.0 pre:492.60443115234375\n"," 33% 110/334 [03:15<03:06,  1.20it/s]['1312']: gt:157.0 pre:135.511474609375\n"," 33% 111/334 [03:15<02:23,  1.55it/s]['1313']: gt:1166.0 pre:1281.7109375\n"," 34% 112/334 [03:17<02:56,  1.26it/s]['1314']: gt:1278.0 pre:1045.461669921875\n"," 34% 113/334 [03:21<06:41,  1.82s/it]['1315']: gt:800.0 pre:872.4894409179688\n"," 34% 114/334 [03:22<05:41,  1.55s/it]['1316']: gt:291.0 pre:321.5401611328125\n"," 34% 115/334 [03:22<04:08,  1.13s/it]['1317']: gt:760.0 pre:884.7027587890625\n"," 35% 116/334 [03:26<07:14,  1.99s/it]['1318']: gt:737.0 pre:731.2489624023438\n"," 35% 117/334 [03:27<06:01,  1.66s/it]['1319']: gt:964.0 pre:898.8458251953125\n"," 35% 118/334 [03:28<05:13,  1.45s/it]['1320']: gt:723.0 pre:833.6932373046875\n"," 36% 119/334 [03:28<03:54,  1.09s/it]['1321']: gt:763.0 pre:681.7158203125\n"," 36% 120/334 [03:28<03:03,  1.17it/s]['1322']: gt:150.0 pre:172.5247802734375\n"," 36% 121/334 [03:28<02:16,  1.56it/s]['1323']: gt:499.0 pre:562.8525390625\n"," 37% 122/334 [03:29<01:54,  1.85it/s]['1324']: gt:485.0 pre:371.1170654296875\n"," 37% 123/334 [03:29<02:08,  1.64it/s]['1325']: gt:757.0 pre:1025.5927734375\n"," 37% 124/334 [03:34<06:05,  1.74s/it]['1326']: gt:1256.0 pre:1157.249755859375\n"," 37% 125/334 [03:37<08:02,  2.31s/it]['1327']: gt:305.0 pre:288.6370544433594\n"," 38% 126/334 [03:38<06:25,  1.85s/it]['1328']: gt:408.0 pre:429.86846923828125\n"," 38% 127/334 [03:39<05:16,  1.53s/it]['1329']: gt:811.0 pre:764.10009765625\n"," 38% 128/334 [03:39<03:56,  1.15s/it]['1330']: gt:311.0 pre:310.43475341796875\n"," 39% 129/334 [03:40<03:35,  1.05s/it]['1331']: gt:456.0 pre:497.21441650390625\n"," 39% 130/334 [03:41<03:16,  1.04it/s]['1332']: gt:475.0 pre:499.5456848144531\n"," 39% 131/334 [03:45<06:54,  2.04s/it]['1333']: gt:294.0 pre:281.0853271484375\n"," 40% 132/334 [03:46<05:25,  1.61s/it]['1334']: gt:944.0 pre:1004.7218017578125\n"," 40% 133/334 [03:50<07:36,  2.27s/it]['1335']: gt:152.0 pre:159.65765380859375\n"," 40% 134/334 [03:50<05:40,  1.70s/it]['1336']: gt:314.0 pre:315.98443603515625\n"," 40% 135/334 [03:55<08:30,  2.57s/it]['1337']: gt:652.0 pre:710.8452758789062\n"," 41% 136/334 [03:56<06:46,  2.05s/it]['1338']: gt:751.0 pre:692.8348388671875\n"," 41% 137/334 [03:57<05:33,  1.69s/it]['1339']: gt:632.0 pre:614.6807250976562\n"," 41% 138/334 [03:57<04:40,  1.43s/it]['1340']: gt:428.0 pre:501.11199951171875\n"," 42% 139/334 [03:58<04:01,  1.24s/it]['1341']: gt:398.0 pre:433.6712951660156\n"," 42% 140/334 [03:59<03:32,  1.10s/it]['1342']: gt:171.0 pre:172.99493408203125\n"," 42% 141/334 [04:03<06:30,  2.02s/it]['1343']: gt:353.0 pre:324.00665283203125\n"," 43% 142/334 [04:04<05:16,  1.65s/it]['1344']: gt:810.0 pre:786.1600341796875\n"," 43% 143/334 [04:04<03:59,  1.25s/it]['1345']: gt:446.0 pre:483.21368408203125\n"," 43% 144/334 [04:05<03:30,  1.11s/it]['1346']: gt:161.0 pre:157.34378051757812\n"," 43% 145/334 [04:06<03:08,  1.00it/s]['1347']: gt:387.0 pre:370.15716552734375\n"," 44% 146/334 [04:06<02:54,  1.08it/s]['1348']: gt:135.0 pre:132.44113159179688\n"," 44% 147/334 [04:07<02:37,  1.19it/s]['1349']: gt:819.0 pre:827.5822143554688\n"," 44% 148/334 [04:13<07:35,  2.45s/it]['1350']: gt:390.0 pre:390.8050537109375\n"," 45% 149/334 [04:18<09:42,  3.15s/it]['1351']: gt:396.0 pre:416.78521728515625\n"," 45% 150/334 [04:19<07:09,  2.33s/it]['1352']: gt:648.0 pre:441.09576416015625\n"," 45% 151/334 [04:23<09:17,  3.04s/it]['1353']: gt:901.0 pre:664.3916015625\n"," 46% 152/334 [04:24<07:18,  2.41s/it]['1354']: gt:641.0 pre:472.45709228515625\n"," 46% 153/334 [04:25<05:48,  1.92s/it]['1355']: gt:354.0 pre:416.6121826171875\n"," 46% 154/334 [04:26<04:42,  1.57s/it]['1356']: gt:845.0 pre:746.0804443359375\n"," 46% 155/334 [04:26<03:32,  1.19s/it]['1357']: gt:2075.0 pre:2026.2291259765625\n"," 47% 156/334 [04:28<04:01,  1.36s/it]['1358']: gt:471.0 pre:374.21539306640625\n"," 47% 157/334 [04:28<03:28,  1.18s/it]['1359']: gt:247.0 pre:239.0852813720703\n"," 47% 158/334 [04:29<03:03,  1.04s/it]['1360']: gt:469.0 pre:374.0937194824219\n"," 48% 159/334 [04:30<02:42,  1.08it/s]['1361']: gt:1063.0 pre:668.63818359375\n"," 48% 160/334 [04:35<06:14,  2.15s/it]['1362']: gt:313.0 pre:337.92974853515625\n"," 48% 161/334 [04:36<04:59,  1.73s/it]['1363']: gt:279.0 pre:299.335693359375\n"," 49% 162/334 [04:36<04:07,  1.44s/it]['1364']: gt:372.0 pre:385.37322998046875\n"," 49% 163/334 [04:37<03:30,  1.23s/it]['1365']: gt:1586.0 pre:1616.874755859375\n"," 49% 164/334 [04:38<03:35,  1.27s/it]['1366']: gt:198.0 pre:195.38613891601562\n"," 49% 165/334 [04:39<03:06,  1.10s/it]['1367']: gt:2315.0 pre:2171.440185546875\n"," 50% 166/334 [04:41<03:47,  1.36s/it]['1368']: gt:4195.0 pre:4206.8349609375\n"," 50% 167/334 [04:45<05:57,  2.14s/it]['1369']: gt:138.0 pre:129.4484100341797\n"," 50% 168/334 [04:46<04:44,  1.72s/it]['1370']: gt:174.0 pre:230.10238647460938\n"," 51% 169/334 [04:46<03:49,  1.39s/it]['1371']: gt:148.0 pre:148.8829345703125\n"," 51% 170/334 [04:51<06:02,  2.21s/it]['1372']: gt:608.0 pre:755.9920654296875\n"," 51% 171/334 [04:52<04:57,  1.83s/it]['1373']: gt:110.0 pre:137.8648681640625\n"," 51% 172/334 [04:52<04:02,  1.50s/it]['1374']: gt:883.0 pre:650.8592529296875\n"," 52% 173/334 [04:53<03:30,  1.31s/it]['1375']: gt:259.0 pre:237.51715087890625\n"," 52% 174/334 [04:53<02:34,  1.04it/s]['1376']: gt:117.0 pre:107.36935424804688\n"," 52% 175/334 [04:53<01:53,  1.40it/s]['1377']: gt:326.0 pre:355.8252258300781\n"," 53% 176/334 [04:54<01:54,  1.38it/s]['1378']: gt:272.0 pre:255.1289825439453\n"," 53% 177/334 [04:56<02:22,  1.10it/s]['1379']: gt:400.0 pre:382.63006591796875\n"," 53% 178/334 [04:56<02:15,  1.15it/s]['1380']: gt:2021.0 pre:1904.3616943359375\n"," 54% 179/334 [04:58<02:52,  1.11s/it]['1381']: gt:1315.0 pre:1054.263671875\n"," 54% 180/334 [04:59<02:31,  1.01it/s]['1382']: gt:466.0 pre:446.34063720703125\n"," 54% 181/334 [05:04<05:44,  2.25s/it]['1383']: gt:269.0 pre:267.9295349121094\n"," 54% 182/334 [05:05<04:34,  1.80s/it]['1384']: gt:1758.0 pre:1610.9622802734375\n"," 55% 183/334 [05:06<04:10,  1.66s/it]['1385']: gt:2166.0 pre:2136.84619140625\n"," 55% 184/334 [05:08<04:17,  1.72s/it]['1386']: gt:507.0 pre:417.3062438964844\n"," 55% 185/334 [05:09<03:32,  1.43s/it]['1387']: gt:158.0 pre:190.76644897460938\n"," 56% 186/334 [05:14<06:07,  2.48s/it]['1388']: gt:403.0 pre:358.37744140625\n"," 56% 187/334 [05:14<04:53,  2.00s/it]['1389']: gt:275.0 pre:271.5399169921875\n"," 56% 188/334 [05:18<06:02,  2.48s/it]['1390']: gt:122.0 pre:134.18572998046875\n"," 57% 189/334 [05:19<04:39,  1.93s/it]['1391']: gt:732.0 pre:698.2080078125\n"," 57% 190/334 [05:19<03:51,  1.61s/it]['1392']: gt:532.0 pre:604.476318359375\n"," 57% 191/334 [05:21<03:43,  1.56s/it]['1393']: gt:195.0 pre:191.49581909179688\n"," 57% 192/334 [05:22<03:07,  1.32s/it]['1394']: gt:210.0 pre:224.74874877929688\n"," 58% 193/334 [05:25<04:33,  1.94s/it]['1395']: gt:159.0 pre:176.5955047607422\n"," 58% 194/334 [05:25<03:17,  1.41s/it]['1396']: gt:211.0 pre:205.82925415039062\n"," 58% 195/334 [05:25<02:24,  1.04s/it]['1397']: gt:287.0 pre:276.73675537109375\n"," 59% 196/334 [05:26<02:16,  1.01it/s]['1398']: gt:165.0 pre:200.76480102539062\n"," 59% 197/334 [05:30<04:22,  1.92s/it]['1399']: gt:104.0 pre:101.70333099365234\n"," 59% 198/334 [05:31<03:34,  1.58s/it]['1400']: gt:263.0 pre:187.25442504882812\n"," 60% 199/334 [05:32<02:58,  1.32s/it]['1401']: gt:299.0 pre:281.3817138671875\n"," 60% 200/334 [05:33<02:34,  1.15s/it]['1402']: gt:719.0 pre:634.4130249023438\n","processing: 200 images\n","mae:  65.5006, mse:  112.2218,                        nae:  0.1198, Class IoU: \n"," 60% 201/334 [05:33<01:59,  1.11it/s]['1403']: gt:864.0 pre:835.0755004882812\n"," 60% 202/334 [05:33<01:34,  1.39it/s]['1404']: gt:368.0 pre:341.313232421875\n"," 61% 203/334 [05:36<02:42,  1.24s/it]['1405']: gt:522.0 pre:458.5186767578125\n"," 61% 204/334 [05:36<02:06,  1.03it/s]['1406']: gt:778.0 pre:698.3857421875\n"," 61% 205/334 [05:36<01:42,  1.25it/s]['1407']: gt:2870.0 pre:2721.1494140625\n"," 62% 206/334 [05:39<02:33,  1.20s/it]['1408']: gt:463.0 pre:536.3639526367188\n"," 62% 207/334 [05:43<04:53,  2.31s/it]['1409']: gt:204.0 pre:179.3553924560547\n"," 62% 208/334 [05:48<06:22,  3.03s/it]['1410']: gt:143.0 pre:229.59130859375\n"," 63% 209/334 [05:48<04:31,  2.18s/it]['1411']: gt:421.0 pre:494.466552734375\n"," 63% 210/334 [05:49<03:39,  1.77s/it]['1412']: gt:434.0 pre:489.52557373046875\n"," 63% 211/334 [05:50<03:00,  1.47s/it]['1413']: gt:218.0 pre:203.62100219726562\n"," 63% 212/334 [05:52<03:29,  1.72s/it]['1414']: gt:266.0 pre:285.307373046875\n"," 64% 213/334 [05:58<05:35,  2.78s/it]['1415']: gt:514.0 pre:451.1446533203125\n"," 64% 214/334 [05:58<04:21,  2.18s/it]['1416']: gt:1048.0 pre:1136.980712890625\n"," 64% 215/334 [06:01<04:21,  2.19s/it]['1417']: gt:593.0 pre:607.4334716796875\n"," 65% 216/334 [06:01<03:30,  1.78s/it]['1418']: gt:1775.0 pre:1297.6043701171875\n"," 65% 217/334 [06:03<03:07,  1.60s/it]['1419']: gt:712.0 pre:761.404296875\n"," 65% 218/334 [06:03<02:29,  1.29s/it]['1420']: gt:535.0 pre:537.873046875\n"," 66% 219/334 [06:05<02:51,  1.49s/it]['1421']: gt:2746.0 pre:2420.577880859375\n"," 66% 220/334 [06:07<03:21,  1.77s/it]['1422']: gt:1709.0 pre:1711.97119140625\n"," 66% 221/334 [06:09<03:05,  1.65s/it]['1423']: gt:1890.0 pre:1861.7039794921875\n"," 66% 222/334 [06:10<03:02,  1.63s/it]['1424']: gt:1826.0 pre:2045.709228515625\n"," 67% 223/334 [06:12<03:00,  1.63s/it]['1425']: gt:379.0 pre:416.1941833496094\n"," 67% 224/334 [06:13<02:29,  1.36s/it]['1426']: gt:1191.0 pre:1531.812744140625\n"," 67% 225/334 [06:14<02:15,  1.25s/it]['1427']: gt:1665.0 pre:1926.6053466796875\n"," 68% 226/334 [06:15<02:18,  1.28s/it]['1428']: gt:612.0 pre:410.7321472167969\n"," 68% 227/334 [06:16<01:59,  1.12s/it]['1429']: gt:172.0 pre:161.5933837890625\n"," 68% 228/334 [06:17<01:46,  1.00s/it]['1430']: gt:699.0 pre:920.89111328125\n"," 69% 229/334 [06:17<01:41,  1.04it/s]['1431']: gt:1454.0 pre:1694.716552734375\n"," 69% 230/334 [06:19<01:52,  1.08s/it]['1432']: gt:682.0 pre:748.2491455078125\n"," 69% 231/334 [06:19<01:34,  1.09it/s]['1433']: gt:419.0 pre:389.94464111328125\n"," 69% 232/334 [06:20<01:28,  1.15it/s]['1434']: gt:332.0 pre:237.61624145507812\n"," 70% 233/334 [06:21<01:23,  1.21it/s]['1435']: gt:244.0 pre:247.00718688964844\n"," 70% 234/334 [06:21<01:05,  1.52it/s]['1436']: gt:125.0 pre:136.2386474609375\n"," 70% 235/334 [06:21<00:49,  1.99it/s]['1437']: gt:267.0 pre:297.91656494140625\n"," 71% 236/334 [06:21<00:38,  2.53it/s]['1438']: gt:178.0 pre:159.63296508789062\n"," 71% 237/334 [06:22<00:44,  2.19it/s]['1439']: gt:170.0 pre:176.91371154785156\n"," 71% 238/334 [06:22<00:34,  2.79it/s]['1440']: gt:306.0 pre:299.738037109375\n"," 72% 239/334 [06:22<00:27,  3.39it/s]['1441']: gt:329.0 pre:314.7730712890625\n"," 72% 240/334 [06:23<00:41,  2.28it/s]['1442']: gt:207.0 pre:190.72225952148438\n"," 72% 241/334 [06:24<00:51,  1.81it/s]['1443']: gt:238.0 pre:244.42999267578125\n"," 72% 242/334 [06:24<00:39,  2.32it/s]['1444']: gt:289.0 pre:265.5340270996094\n"," 73% 243/334 [06:24<00:31,  2.91it/s]['1445']: gt:228.0 pre:197.3071746826172\n"," 73% 244/334 [06:25<00:41,  2.16it/s]['1446']: gt:308.0 pre:334.34820556640625\n"," 73% 245/334 [06:29<02:13,  1.50s/it]['1447']: gt:1036.0 pre:997.197265625\n"," 74% 246/334 [06:30<02:00,  1.37s/it]['1448']: gt:214.0 pre:257.134765625\n"," 74% 247/334 [06:31<01:40,  1.15s/it]['1449']: gt:205.0 pre:205.9887237548828\n"," 74% 248/334 [06:31<01:28,  1.02s/it]['1450']: gt:83.0 pre:82.2001953125\n"," 75% 249/334 [06:32<01:19,  1.07it/s]['1451']: gt:65.0 pre:64.60576629638672\n"," 75% 250/334 [06:32<01:03,  1.33it/s]['1452']: gt:184.0 pre:242.70083618164062\n"," 75% 251/334 [06:33<01:04,  1.29it/s]['1453']: gt:340.0 pre:467.44158935546875\n"," 75% 252/334 [06:33<00:48,  1.69it/s]['1454']: gt:163.0 pre:216.78314208984375\n"," 76% 253/334 [06:34<00:49,  1.64it/s]['1455']: gt:829.0 pre:934.0681762695312\n"," 76% 254/334 [06:35<00:56,  1.41it/s]['1456']: gt:3970.0 pre:3986.693603515625\n"," 76% 255/334 [06:42<03:28,  2.64s/it]['1457']: gt:2240.0 pre:1834.592529296875\n"," 77% 256/334 [06:44<03:04,  2.37s/it]['1458']: gt:2371.0 pre:1707.6766357421875\n"," 77% 257/334 [06:44<02:23,  1.86s/it]['1459']: gt:994.0 pre:903.8045654296875\n"," 77% 258/334 [06:45<02:00,  1.59s/it]['1460']: gt:338.0 pre:379.3868713378906\n"," 78% 259/334 [06:46<01:40,  1.34s/it]['1461']: gt:2116.0 pre:2360.018310546875\n"," 78% 260/334 [06:48<01:53,  1.54s/it]['1462']: gt:343.0 pre:317.2666015625\n"," 78% 261/334 [06:49<01:35,  1.30s/it]['1463']: gt:550.0 pre:802.7584228515625\n"," 78% 262/334 [06:54<02:56,  2.45s/it]['1464']: gt:258.0 pre:269.73681640625\n"," 79% 263/334 [06:54<02:05,  1.76s/it]['1465']: gt:225.0 pre:267.3084411621094\n"," 79% 264/334 [06:59<03:11,  2.74s/it]['1466']: gt:245.0 pre:255.61669921875\n"," 79% 265/334 [06:59<02:16,  1.98s/it]['1467']: gt:3653.0 pre:3690.02880859375\n"," 80% 266/334 [07:03<02:38,  2.33s/it]['1468']: gt:1103.0 pre:1163.9822998046875\n"," 80% 267/334 [07:03<01:59,  1.79s/it]['1469']: gt:1400.0 pre:1203.1474609375\n"," 80% 268/334 [07:07<02:32,  2.30s/it]['1470']: gt:3304.0 pre:2842.638671875\n"," 81% 269/334 [07:09<02:27,  2.27s/it]['1471']: gt:276.0 pre:336.94195556640625\n"," 81% 270/334 [07:09<01:46,  1.67s/it]['1472']: gt:916.0 pre:775.5471801757812\n"," 81% 271/334 [07:09<01:20,  1.27s/it]['1473']: gt:1798.0 pre:1963.959716796875\n"," 81% 272/334 [07:11<01:20,  1.29s/it]['1474']: gt:948.0 pre:1102.8536376953125\n"," 82% 273/334 [07:17<02:47,  2.74s/it]['1475']: gt:457.0 pre:457.22454833984375\n"," 82% 274/334 [07:17<01:58,  1.98s/it]['1476']: gt:1070.0 pre:867.3355712890625\n"," 82% 275/334 [07:17<01:29,  1.52s/it]['1477']: gt:302.0 pre:259.6727600097656\n"," 83% 276/334 [07:22<02:13,  2.30s/it]['1478']: gt:259.0 pre:308.30303955078125\n"," 83% 277/334 [07:22<01:44,  1.83s/it]['1479']: gt:518.0 pre:537.2670288085938\n"," 83% 278/334 [07:23<01:15,  1.34s/it]['1480']: gt:560.0 pre:734.774169921875\n"," 84% 279/334 [07:25<01:32,  1.67s/it]['1481']: gt:558.0 pre:514.1826171875\n"," 84% 280/334 [07:25<01:07,  1.24s/it]['1482']: gt:871.0 pre:974.0761108398438\n"," 84% 281/334 [07:26<00:52,  1.02it/s]['1483']: gt:574.0 pre:524.95263671875\n"," 84% 282/334 [07:27<00:53,  1.04s/it]['1484']: gt:241.0 pre:208.3293914794922\n"," 85% 283/334 [07:32<01:50,  2.16s/it]['1485']: gt:376.0 pre:500.6970520019531\n"," 85% 284/334 [07:32<01:27,  1.74s/it]['1486']: gt:582.0 pre:717.0038452148438\n"," 85% 285/334 [07:33<01:02,  1.29s/it]['1487']: gt:937.0 pre:889.4000244140625\n"," 86% 286/334 [07:33<00:48,  1.02s/it]['1488']: gt:229.0 pre:165.9631805419922\n"," 86% 287/334 [07:34<00:52,  1.13s/it]['1489']: gt:216.0 pre:192.24217224121094\n"," 86% 288/334 [07:35<00:46,  1.01s/it]['1490']: gt:251.0 pre:253.93507385253906\n"," 87% 289/334 [07:35<00:33,  1.33it/s]['1491']: gt:556.0 pre:487.1003723144531\n"," 87% 290/334 [07:36<00:37,  1.18it/s]['1492']: gt:357.0 pre:414.07965087890625\n"," 87% 291/334 [07:38<00:52,  1.23s/it]['1493']: gt:260.0 pre:345.80120849609375\n"," 87% 292/334 [07:39<00:38,  1.10it/s]['1494']: gt:1433.0 pre:1813.931640625\n"," 88% 293/334 [07:40<00:41,  1.01s/it]['1495']: gt:791.0 pre:966.143798828125\n"," 88% 294/334 [07:46<01:41,  2.55s/it]['1496']: gt:1477.0 pre:1380.6578369140625\n"," 88% 295/334 [07:47<01:23,  2.14s/it]['1497']: gt:1341.0 pre:1183.424560546875\n"," 89% 296/334 [07:48<01:10,  1.85s/it]['1498']: gt:429.0 pre:394.85540771484375\n"," 89% 297/334 [07:49<00:57,  1.55s/it]['1499']: gt:284.0 pre:337.19061279296875\n"," 89% 298/334 [07:50<00:47,  1.31s/it]['1500']: gt:165.0 pre:154.12191772460938\n"," 90% 299/334 [07:50<00:33,  1.04it/s]['1501']: gt:236.0 pre:210.44288635253906\n"," 90% 300/334 [07:51<00:31,  1.09it/s]['1502']: gt:207.0 pre:213.29214477539062\n","processing: 300 images\n","mae:  75.1106, mse:  126.4076,                        nae:  0.1241, Class IoU: \n"," 90% 301/334 [07:51<00:22,  1.46it/s]['1503']: gt:315.0 pre:331.8419189453125\n"," 90% 302/334 [07:51<00:16,  1.90it/s]['1504']: gt:2154.0 pre:2337.762451171875\n"," 91% 303/334 [07:53<00:30,  1.03it/s]['1505']: gt:2593.0 pre:2799.624755859375\n"," 91% 304/334 [07:57<00:58,  1.94s/it]['1506']: gt:654.0 pre:747.7734985351562\n"," 91% 305/334 [07:58<00:41,  1.43s/it]['1507']: gt:2702.0 pre:2744.082763671875\n"," 92% 306/334 [08:00<00:50,  1.82s/it]['1508']: gt:1077.0 pre:1140.2904052734375\n"," 92% 307/334 [08:01<00:40,  1.49s/it]['1509']: gt:3568.0 pre:4089.173828125\n"," 92% 308/334 [08:05<00:58,  2.25s/it]['1510']: gt:663.0 pre:691.8988037109375\n"," 93% 309/334 [08:06<00:49,  1.98s/it]['1511']: gt:642.0 pre:710.6534423828125\n"," 93% 310/334 [08:08<00:42,  1.78s/it]['1512']: gt:909.0 pre:997.3479614257812\n"," 93% 311/334 [08:09<00:35,  1.55s/it]['1513']: gt:270.0 pre:305.71905517578125\n"," 93% 312/334 [08:09<00:24,  1.12s/it]['1514']: gt:465.0 pre:643.8187255859375\n"," 94% 313/334 [08:10<00:21,  1.02s/it]['1515']: gt:820.0 pre:1048.51171875\n"," 94% 314/334 [08:11<00:19,  1.02it/s]['1516']: gt:383.0 pre:373.04547119140625\n"," 94% 315/334 [08:11<00:17,  1.10it/s]['1517']: gt:973.0 pre:1010.96923828125\n"," 95% 316/334 [08:12<00:16,  1.07it/s]['1518']: gt:811.0 pre:894.5882568359375\n"," 95% 317/334 [08:17<00:34,  2.05s/it]['1519']: gt:1616.0 pre:1757.9718017578125\n"," 95% 318/334 [08:18<00:29,  1.86s/it]['1520']: gt:922.0 pre:1030.0091552734375\n"," 96% 319/334 [08:24<00:42,  2.86s/it]['1521']: gt:2414.0 pre:2686.216796875\n"," 96% 320/334 [08:31<00:57,  4.12s/it]['1522']: gt:2472.0 pre:2456.17138671875\n"," 96% 321/334 [08:32<00:43,  3.31s/it]['1523']: gt:1613.0 pre:2051.692138671875\n"," 96% 322/334 [08:34<00:33,  2.76s/it]['1524']: gt:2033.0 pre:2086.4541015625\n"," 97% 323/334 [08:35<00:27,  2.48s/it]['1525']: gt:650.0 pre:604.86328125\n"," 97% 324/334 [08:36<00:18,  1.82s/it]['1526']: gt:1659.0 pre:2009.84716796875\n"," 97% 325/334 [08:37<00:14,  1.57s/it]['1527']: gt:165.0 pre:153.98487854003906\n"," 98% 326/334 [08:37<00:09,  1.21s/it]['1528']: gt:1408.0 pre:1915.521240234375\n"," 98% 327/334 [08:38<00:08,  1.24s/it]['1529']: gt:426.0 pre:473.6982421875\n"," 98% 328/334 [08:40<00:07,  1.33s/it]['1530']: gt:962.0 pre:772.6638793945312\n"," 99% 329/334 [08:40<00:05,  1.03s/it]['1531']: gt:1668.0 pre:1775.400634765625\n"," 99% 330/334 [08:45<00:08,  2.15s/it]['1532']: gt:2607.0 pre:3110.0166015625\n"," 99% 331/334 [08:48<00:07,  2.34s/it]['1533']: gt:770.0 pre:847.5916748046875\n"," 99% 332/334 [08:48<00:03,  1.74s/it]['1534']: gt:601.0 pre:812.599365234375\n","100% 333/334 [08:50<00:01,  1.77s/it]['1535']: gt:1508.0 pre:1618.13427734375\n","100% 334/334 [08:51<00:00,  1.59s/it]\n","-----Localization performance with box annotations-----\n","AP_small: 0.7057346716878293\n","AR_small: 0.6298083930586731\n","F1m_small: 0.6656133092733595\n","AR_small_category: [0.48723559 0.26038965 0.67249281 0.78645271 0.7560271  0.77308294]\n","    avg: 0.6226134657213758\n","AP_large: 0.7708604574111146\n","AR_large: 0.6879276382914041\n","F1m_large: 0.7270366621187447\n","AR_large_category: [0.60466813 0.35456286 0.73681887 0.82410494 0.78342299 0.80594679]\n","    avg: 0.6849207619264374\n","-----Localization performance with points annotations-----\n","avg precision_overall:0.0\n","avg recall_overall:0.0\n","avg F1_overall:0.0\n","Mean Loclization Error:12.679470983743878\n","-----Counting performance-----\n","MAE: 82.89751172779563\n","MSE: 137.66506038740278\n","NAE: 0.12446150005583391\n","mae:  82.8975, mse:  137.6651,                nae:  0.1245, Class IoU: \n","Mins: 8\n","Done\n"]}]},{"cell_type":"code","source":["\n","!#  bash test.sh configs/QNRF_final.py ../PretrainedModels/SHHB.pth 1"],"metadata":{"id":"JESkr64CfqRK"},"execution_count":null,"outputs":[]}]}